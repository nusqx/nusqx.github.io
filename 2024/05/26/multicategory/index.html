<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="分类器,CNN"><meta name="description" content="多标签分类"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="baidu-site-verification" content="codeva-fVFbpHJJO8"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="referrer" content="no-referrer"><title>多标签分类 | SQX BLOG</title><link rel="icon" type="image/png" href="../../../../favicon.png"><link rel="stylesheet" type="text/css" href="../../../../libs/awesome/css/all.min.css"><link rel="stylesheet" type="text/css" href="../../../../libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="../../../../libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="../../../../libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="../../../../libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="../../../../css/matery.css"><link rel="stylesheet" type="text/css" href="../../../../css/my.css"><link rel="stylesheet" type="text/css" href="../../../../css/dark.css" media="none" onload='"all"!=media&&(media="all")'><link rel="stylesheet" href="../../../../libs/tocbot/tocbot.css"><link rel="stylesheet" href="../../../../css/post.css"><link rel="stylesheet" type="text/css" href="../../../../css/reward.css"><script src="../../../../libs/jquery/jquery-3.6.0.min.js"></script><meta name="generator" content="Hexo 6.3.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="../../../../index.html" class="waves-effect waves-light"><div><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">SQX BLOG</span></div></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="../../../../index.html" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../friends" class="waves-effect waves-light"><i class="fas fa-address-book" style="zoom:.6"></i> <span>友情链接</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li><li><a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式"><i id="sum-moon-icon" class="fas fa-sun" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">SQX BLOG</div><div class="logo-desc">Technical writer | Life adventurer</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="../../../../index.html" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="../../../../tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="../../../../categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="../../../../archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="../../../../about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="../../../../friends" class="waves-effect waves-light"><i class="fa-fw fas fa-address-book"></i> 友情链接</a></li></ul></div></div></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(../../../medias/featureimages/2.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">多标签分类</h1></div></div></div></div></div><main class="post-container content"><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="../../../../tags/%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB/"><span class="chip bg-color">多标签分类</span> </a><a href="../../../../tags/CV/"><span class="chip bg-color">CV</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="../../../../categories/CV/" class="post-category">CV</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2024-05-26</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 4.6k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 17 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><link rel="stylesheet" href="../../../../libs/prism/prism.min.css"><div class="card-content article-card-content"><div id="articleContent"><h1 id="多标签分类"><a href="#多标签分类" class="headerlink" title="多标签分类"></a>多标签分类</h1><h2 id="构建数据块"><a href="#构建数据块" class="headerlink" title="构建数据块"></a>构建数据块</h2><p>数据集中DataFrame对象转变为一个DataLoaders对象：</p><p>PyTorch和fastai有两个用来表示和访问数据集和训练集的主要类：</p><ul><li>Dataset：能为单个数据返回自变量和因变量的元组集合。</li><li>DataLoader：能提供一个小批次的处理流（每个小批次是成对的一批自变量和因变量）的迭代器。</li></ul><p>以上面类为基础，fastai提供两个类将训练集和验证集结合在一起：</p><ul><li>Datasets：包含一个训练Dataset和一个验证Dataset的迭代器。</li><li>DataLoaders：包含一个训练DataLoader和验证DataLoader的对象。</li></ul><p>由于DataLoader基于Dataset构建，并且向Dataset添加了额外的功能（将多个数据项整合成一个批次），因此通常最简单的做法是创建并测试Datasets，测试完成后再查看DataLoaders。</p><blockquote><p>创建一个DataBlock时，逐步进行，在notebook中检查数据，能确保在编程过程中保持顺畅并避免出错。</p></blockquote><p>访问DataFrame，查看中间数据，当成矩阵</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment">#按所有行，第0列</span>
df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token comment">#按所有行，第1列</span>
df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment">#按第0行，所有列</span>
<span class="token comment">#   so this is equivalent:</span>
<span class="token comment"># df.iloc[0]</span>
<span class="token comment"># 也可通过索引DataFrame中某列名字来获取某列：</span>
df<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 可以创建新列，并用列计算</span>
tmp_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'a'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
tmp_df<span class="token punctuation">[</span><span class="token string">'c'</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp_df<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">]</span><span class="token operator">+</span>tmp_df<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以数据集PASCAL为例：开始构建数据块</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> fastai<span class="token punctuation">.</span>vision<span class="token punctuation">.</span><span class="token builtin">all</span> <span class="token keyword">import</span> <span class="token operator">*</span>
path <span class="token operator">=</span> untar_data<span class="token punctuation">(</span>URLs<span class="token punctuation">.</span>PASCAL_2007<span class="token punctuation">)</span>
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>path<span class="token operator">/</span><span class="token string">'train.csv'</span><span class="token punctuation">)</span>
dblock <span class="token operator">=</span> DataBlock<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 无参初始化</span>
dsets <span class="token operator">=</span> dblock<span class="token punctuation">.</span>datasets<span class="token punctuation">(</span>df<span class="token punctuation">)</span> <span class="token comment"># 创建Datasets对象，数据源df做参数</span>
<span class="token comment"># len(dsets.train),len(dsets.valid)</span>
x<span class="token punctuation">,</span>y <span class="token operator">=</span> dsets<span class="token punctuation">.</span>train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># 返回了同一行两次，因为DataBlock假设有两样东西：输入和目标；要从df中选择合适的字段，用get_x和get_y函数。</span>
<span class="token comment"># dblock = DataBlock(get_x = lambda r: r['fname'], get_y = lambda r: r['labels'])</span>
<span class="token comment"># dsets = dblock.datasets(df)</span>
<span class="token comment"># dsets.train[0]此时数据为 名称+标签 ('005620.jpg', 'aeroplane')</span>
<span class="token comment"># python中的lambda函数定义引用函数与下面同效果</span>
<span class="token keyword">def</span> <span class="token function">get_x</span><span class="token punctuation">(</span>r<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">return</span> r<span class="token punctuation">[</span><span class="token string">'fname'</span><span class="token punctuation">]</span>
<span class="token keyword">def</span> <span class="token function">get_y</span><span class="token punctuation">(</span>r<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">return</span> r<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span>
dblock <span class="token operator">=</span> DataBlock<span class="token punctuation">(</span>get_x <span class="token operator">=</span> get_x<span class="token punctuation">,</span> get_y <span class="token operator">=</span> get_y<span class="token punctuation">)</span>
dsets <span class="token operator">=</span> dblock<span class="token punctuation">.</span>datasets<span class="token punctuation">(</span>df<span class="token punctuation">)</span>
<span class="token comment"># lambda非常适合快速迭代，但与序列化操作不兼容，如果想在训练后导出Learner，建议用自定义的详细函数</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>自变量需要被转换为一个完整的路径才能以图像方式打开；因变量需要以空格为分隔进行字符串分割</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_x</span><span class="token punctuation">(</span>r<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">return</span> path<span class="token operator">/</span><span class="token string">'train'</span><span class="token operator">/</span>r<span class="token punctuation">[</span><span class="token string">'fname'</span><span class="token punctuation">]</span>
<span class="token keyword">def</span> <span class="token function">get_y</span><span class="token punctuation">(</span>r<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">return</span> r<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
dblock <span class="token operator">=</span> DataBlock<span class="token punctuation">(</span>get_x <span class="token operator">=</span> get_x<span class="token punctuation">,</span> get_y <span class="token operator">=</span> get_y<span class="token punctuation">)</span>
dsets <span class="token operator">=</span> dblock<span class="token punctuation">.</span>datasets<span class="token punctuation">(</span>df<span class="token punctuation">)</span>
<span class="token comment"># dsets.train[0]为(Path('/home/sunqx/.fastai/data/pascal_2007/train/006162.jpg'), ['aeroplane'])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>为了打开图像并转换为张量，需要一系列转换，使用block类型。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dblock <span class="token operator">=</span> DataBlock<span class="token punctuation">(</span>blocks<span class="token operator">=</span><span class="token punctuation">(</span>ImageBlock<span class="token punctuation">,</span> MultiCategoryBlock<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">#CategoryBlock只返回一个整数，这里每个数据项能有多个标签</span>
                   get_x <span class="token operator">=</span> get_x<span class="token punctuation">,</span> get_y <span class="token operator">=</span> get_y<span class="token punctuation">)</span>
dsets <span class="token operator">=</span> dblock<span class="token punctuation">.</span>datasets<span class="token punctuation">(</span>df<span class="token punctuation">)</span>
<span class="token comment"># (PILImage mode=RGB size=500x333,</span>
<span class="token comment"># TensorMultiCategory([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里使用到<code>独热编码</code>：在一个全0向量中，把存在数据的位置的数值置为1，通过这种方式，对一个整数列表进行编码。</p><p>查看这个例子中的类别代表什么：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">idxs <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>dsets<span class="token punctuation">.</span>train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">==</span><span class="token number">1.</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
dsets<span class="token punctuation">.</span>train<span class="token punctuation">.</span>vocab<span class="token punctuation">[</span>idxs<span class="token punctuation">]</span>
<span class="token comment"># (#1) ['bird']</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>那数据集如何划分训练集和验证集呢？</p><p>前面是DataBlock随机划分的，自定义如下，使用到<code>is_valid</code>字段：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">splitter</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>
    train <span class="token operator">=</span> df<span class="token punctuation">.</span>index<span class="token punctuation">[</span><span class="token operator">~</span>df<span class="token punctuation">[</span><span class="token string">'is_valid'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
    valid <span class="token operator">=</span> df<span class="token punctuation">.</span>index<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'is_valid'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> train<span class="token punctuation">,</span>valid

dblock <span class="token operator">=</span> DataBlock<span class="token punctuation">(</span>blocks<span class="token operator">=</span><span class="token punctuation">(</span>ImageBlock<span class="token punctuation">,</span> MultiCategoryBlock<span class="token punctuation">)</span><span class="token punctuation">,</span>
                   splitter<span class="token operator">=</span>splitter<span class="token punctuation">,</span>
                   get_x<span class="token operator">=</span>get_x<span class="token punctuation">,</span> 
                   get_y<span class="token operator">=</span>get_y<span class="token punctuation">)</span>

dsets <span class="token operator">=</span> dblock<span class="token punctuation">.</span>datasets<span class="token punctuation">(</span>df<span class="token punctuation">)</span>
dsets<span class="token punctuation">.</span>train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>DataLoader将数据集中的数据整合为一个小批次，这是一个张量元组，每个张量都只是将来自数据集中对应位置的数据堆叠起来。要确保每个数据有相同的大小，才可以创建DataLoaders。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dblock <span class="token operator">=</span> DataBlock<span class="token punctuation">(</span>blocks<span class="token operator">=</span><span class="token punctuation">(</span>ImageBlock<span class="token punctuation">,</span> MultiCategoryBlock<span class="token punctuation">)</span><span class="token punctuation">,</span>
                   splitter<span class="token operator">=</span>splitter<span class="token punctuation">,</span>
                   get_x<span class="token operator">=</span>get_x<span class="token punctuation">,</span> 
                   get_y<span class="token operator">=</span>get_y<span class="token punctuation">,</span>
                   item_tfms <span class="token operator">=</span> RandomResizedCrop<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> min_scale<span class="token operator">=</span><span class="token number">0.35</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
dls <span class="token operator">=</span> dblock<span class="token punctuation">.</span>dataloaders<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token comment">#fastai批大小默认64</span>
<span class="token comment"># dls = dblock.dataloaders(df,bs=32) 可自定义</span>
<span class="token comment">#dls.show_batch(nrows=1, ncols=3) #展示</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果从DataBlock创建DataLoaders的过程中出错了，或者如果想查看你的DataBlock，可以使用<code>summary</code>方法。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 使用summary方法</span>
dblock<span class="token punctuation">.</span>summary<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="创建Learner"><a href="#创建Learner" class="headerlink" title="创建Learner"></a>创建Learner</h2><p>Learner主要包含4项：模型、一个DataLoaders对象，一个优化器和损失函数。</p><h3 id="损失函数：二元交叉熵"><a href="#损失函数：二元交叉熵" class="headerlink" title="损失函数：二元交叉熵"></a>损失函数：二元交叉熵</h3><p>已有数据块，模型使用深度残差神经网络resnet，使用SGD优化器。</p><p>创建Learner：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn <span class="token operator">=</span> vision_learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> resnet18<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>Learner中的模型通常是一个继承自<code>nn.Module</code>的类的对象，可以用圆括号调用它，它返回一个模型的激活值。</p><p>把自变量作为一个小批次的处理数据传给它。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">,</span>y <span class="token operator">=</span> to_cpu<span class="token punctuation">(</span>dls<span class="token punctuation">.</span>train<span class="token punctuation">.</span>one_batch<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#将一个训练批次的数据从 GPU（如果正在使用）转移到 CPU。</span>
activs <span class="token operator">=</span> learn<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment">#这批数据被传递给模型以获取激活值（或预测）</span>
activs<span class="token punctuation">.</span>shape <span class="token comment">#通过 activs.shape 查询激活值的形状</span>
<span class="token comment"># torch.Size([64, 20])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>activs形状？因为批大小是64，而我们需要计算20个类别中的每个类别的概率。</p><p>查看激活值：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">activs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token comment"># TensorImage([-2.5563, -0.1716,  3.3514, -1.9079, -1.0211,  1.9026,  0.3355,  1.1839,  0.1848, -0.9886, -0.7055,  1.3745, -1.2583,  0.9657,  4.8114, -1.4315, -2.9368,  3.2201, -1.7628,  3.3106],grad_fn=&lt;AliasBackward0&gt;)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>可以通过sigmoid函数将概率缩放到0到1之间。</p><p>损失函数：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">binary_cross_entropy</span><span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span>
    inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#模型的输出</span>
    <span class="token keyword">return</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>targets<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">-</span>inputs<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#targets标签</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>在二分类问题中，我们通常将概率分布表示为<code>y = sigmoid(x)</code>，其中<code>x</code>是模型输出的 logits（未归一化的概率），<code>y</code>是预测的类别概率（0到1之间的实数）。</p><p>函数的输入参数包括<code>inputs</code>和<code>targets</code>。<code>inputs</code>是一个张量，表示模型输出的 logits；<code>targets</code>是一个张量，表示真实标签（0或1）。</p><p>函数首先使用<code>sigmoid</code>函数激活<code>inputs</code>张量，使其表示为概率分布。然后，使用<code>torch.where</code>函数根据<code>targets</code>张量中的值计算损失。<code>torch.where</code>函数的输入是一个条件表达式，这里我们使用<code>targets==1</code>作为条件表达式。如果<code>targets</code>中的值等于1，那么损失等于<code>1-inputs</code>；否则，损失等于<code>inputs</code>。最后，使用<code>log</code>函数计算损失的 log 值，并使用<code>mean</code>函数计算损失的平均值。</p><p>总之，这个函数计算了二分类问题中模型预测的概率分布与真实标签之间的交叉熵损失。</p><blockquote><p>因为有一个独热编码的因变量，所以不能直接使用nll_loss或softmax（也因此不能使用cross_entropy）</p></blockquote><p><strong>Softmax</strong>函数要求所有预测值的和为1，并且由于使用了指数函数，它倾向于使一个激活值远大于其他值；然而，我们可能确信在一幅图像中出现了多个对象，因此限制激活值的最大和为1并不是一个好主意。同样的道理，如果我们认为图像中没有任何类别出现，我们可能希望激活值的和小于1。</p><p>我们看到的<strong>nll_loss</strong>只返回一个激活值：与单个项目的单个标签相对应的激活值。当我们有多个标签时，这种做法没有意义。</p><p>另一方面，<strong>binary_cross_entropy</strong>函数，它只是<code>mnist_loss</code>与<code>log</code>对数结合，正好提供了我们所需要的，这要归功于PyTorch的逐元素层面操作的魔力。每个激活值将与每列的每个目标进行比较，所以我们不必做任何事情就能让这个函数作用于多列。</p><p>PyTorch确实为我们提供了这个函数。事实上，它提供了许多版本，名称有些令人困惑！</p><p><code>F.binary_cross_entropy</code> 及其模块等效 <code>nn.BCELoss</code> 计算的是对独热编码（one-hot-encoded）目标的交叉熵，但不包括初始的sigmoid。通常对于独热编码的目标，你会想要使用 <code>F.binary_cross_entropy_with_logits</code>（或 <code>nn.BCEWithLogitsLoss</code>），它在单个函数中同时完成sigmoid和二元交叉熵的计算，就像前面的例子一样。</p><p>对于单标签数据集（如MNIST或宠物数据集），其中目标被编码为单个整数，没有初始softmax的版本是 <code>F.nll_loss</code> 或 <code>nn.NLLLoss</code>，有初始softmax的版本是 <code>F.cross_entropy</code> 或 <code>nn.CrossEntropyLoss</code>。</p><p>由于我们有一个独热编码的目标，我们将使用 <code>BCEWithLogitsLoss</code>。</p><p>现在，让我解释一下这些函数的作用：</p><ul><li><code>F.binary_cross_entropy</code> 和 <code>nn.BCELoss</code>：这两个函数用于计算独热编码目标的二元交叉熵损失，但它们不包括sigmoid激活函数。这意味着在使用这些函数之前，你需要手动应用sigmoid函数来获取预测概率。</li><li><code>F.binary_cross_entropy_with_logits</code> 和 <code>nn.BCEWithLogitsLoss</code>：这些函数结合了sigmoid激活和二元交叉熵损失的计算。它们适用于独热编码的目标，并且在内部自动应用sigmoid函数，这使得它们在数值上更稳定，尤其是在处理极端预测值时。</li><li><code>F.nll_loss</code> 和 <code>nn.NLLLoss</code>：这些函数用于没有初始softmax的单标签数据集。它们计算的是负对数似然损失，适用于分类任务中每个实例只有一个正确类别的情况。</li><li><code>F.cross_entropy</code> 和 <code>nn.CrossEntropyLoss</code>：这些函数结合了softmax激活和负对数似然损失的计算。它们适用于单标签数据集，其中目标被编码为单个整数。</li></ul><p>在多标签分类任务中，我们通常会选择 <code>BCEWithLogitsLoss</code>，因为它能够处理每个类别独立的概率，并且在计算损失时考虑到了每个类别的预测概率。这对于那些可能有多个正确标签的情况非常有用。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">activs <span class="token operator">=</span> activs<span class="token punctuation">.</span>as_subclass<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span>
y <span class="token operator">=</span> y<span class="token punctuation">.</span>as_subclass<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span><span class="token comment"># 确保这些变量具有 Tensor 类型，以便可以对它们应用 PyTorch 的操作和函数</span>
loss_func <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCEWithLogitsLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>activs<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token comment"># tensor(1.0336, grad_fn=&lt;BinaryCrossEntropyWithLogitsBackward0&gt;)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>然而，不必告诉fastai使用哪个损失函数（也可以这么做），因为它会自动选择合适的损失函数。fastai知道DataLoaders有多个类别标签，所以使用默认的nn.BCEWithLogitsLoss。</p></blockquote><p>计算准确率，但是这里不使用准确率</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>inp<span class="token punctuation">,</span> targ<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    pred <span class="token operator">=</span> inp<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span>axis<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>pred <span class="token operator">==</span> targ<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><code>argmax</code>被预测的类别是激活值最高的那一个。但这里不起作用，因为要求一张图像能有不止一个预测类别。</p><p>在将sigmoid操作应用到激活值上（令它们介于0与1之间）之后，我们需要选择一个阈值来决定哪些是0、哪些是1。每个高于阈值的值被认为是1，低于阈值的值被认为是0。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">accuracy_multi</span><span class="token punctuation">(</span>inp<span class="token punctuation">,</span> targ<span class="token punctuation">,</span> thresh<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> sigmoid<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> sigmoid<span class="token punctuation">:</span> inp <span class="token operator">=</span> inp<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>inp<span class="token operator">&gt;</span>thresh<span class="token punctuation">)</span><span class="token operator">==</span>targ<span class="token punctuation">.</span><span class="token builtin">bool</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>可以调整默认阈值0.5，创建不同默认值的<code>accuracy_multi</code>版本。为了实现这一点可以使用<code>partial</code>函数，它可以将一个函数与一些参数或关键字绑定在一起，从而使得新版本的函数无论何时被调用，都能始终包含这些参数。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">say_hello</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> say_what<span class="token operator">=</span><span class="token string">"Hello"</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>say_what<span class="token punctuation">}</span></span><span class="token string"> </span><span class="token interpolation"><span class="token punctuation">{</span>name<span class="token punctuation">}</span></span><span class="token string">."</span></span>
say_hello<span class="token punctuation">(</span><span class="token string">'Jeremy'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>say_hello<span class="token punctuation">(</span><span class="token string">'Jeremy'</span><span class="token punctuation">,</span> <span class="token string">'Ahoy!'</span><span class="token punctuation">)</span>
<span class="token comment"># ('Hello Jeremy.', 'Ahoy! Jeremy.')</span>

f <span class="token operator">=</span> partial<span class="token punctuation">(</span>say_hello<span class="token punctuation">,</span> say_what<span class="token operator">=</span><span class="token string">"Bonjour"</span><span class="token punctuation">)</span>
f<span class="token punctuation">(</span><span class="token string">"Jeremy"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>f<span class="token punctuation">(</span><span class="token string">"Sylvain"</span><span class="token punctuation">)</span>
<span class="token comment"># 'Bonjour Jeremy.', 'Bonjour Sylvain.')</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><p>这里多分类指标的阈值设为0.2</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn <span class="token operator">=</span> vision_learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> resnet50<span class="token punctuation">,</span> metrics<span class="token operator">=</span>partial<span class="token punctuation">(</span>accuracy_multi<span class="token punctuation">,</span> thresh<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fine_tune<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> base_lr<span class="token operator">=</span><span class="token number">3e-3</span><span class="token punctuation">,</span> freeze_epochs<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li><p><code>learn.fine_tune(3, base_lr=3e-3, freeze_epochs=4)</code></p></li><li><p><code>fine_tune</code> 方法用于微调模型。首先，它冻结预训练模型的大部分层，只训练最后几层以适应新的数据集。然后，它解冻所有层并继续训练整个模型。</p></li><li><p>第一个参数 <code>3</code> 指定在解冻所有层后训练的周期数（epochs）。</p></li><li><p><code>base_lr=3e-3</code> 设置了学习率。这是在微调过程中使用的基础学习率。</p></li><li><p><code>freeze_epochs=4</code> 指定在开始微调之前，只训练最后几层时使用的周期数。在这个阶段，模型的大部分层都是冻结的。</p></li><li><p>在 <code>fastai</code> 库中，当使用 <code>fine_tune</code> 方法对模型进行微调时，”解冻” 的具体层取决于模型的架构和 <code>fine_tune</code> 方法的实现细节。对于大多数预训练模型，如 <code>resnet50</code>，<code>fine_tune</code> 方法的工作流程大致如下：</p><ol><li><strong>初始阶段</strong>（冻结状态）：在第一阶段，模型的大部分预训练层都被冻结，只有模型的最后几层（通常是头部的几层，这些层负责将预训练模型的特征转换为特定任务的输出）是可训练的。这意味着在这个阶段，只有这些最后的层的权重会被更新。</li><li><strong>解冻并微调</strong>：在第二阶段，<code>fine_tune</code> 方法会解冻模型的所有层，使得整个网络的权重都可以更新。这个阶段通常使用更小的学习率，以避免破坏预训练层学到的有用特征。</li></ol><p>具体到 <code>resnet50</code> 或其他类似的 CNN 架构，”解冻” 的层包括：</p><ul><li><strong>卷积层</strong>：这些层负责从输入图像中提取特征。在微调的第二阶段，所有卷积层都会被解冻，允许模型调整这些层以更好地适应新的数据集。</li><li><strong>批归一化层</strong>（如果有的话）：这些层用于标准化前一层的输出，有助于加速训练过程并提高模型的稳定性。在微调过程中，这些层的参数也可以被更新。</li><li><strong>全连接层</strong>：这是模型的最后几层，通常直接负责生成最终的预测输出。在初始阶段，这些层就已经是可训练的，微调的第二阶段会继续调整它们的权重。</li></ul></li></ul><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406200952550.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">训练模型</div></center><p>如果阈值过低，经常无法得到正确的标记对象。可以通过调整指标，然后调用能够返回验证集上的损失值和所设置的指标的验证函数validate来观察是否得到了正确标记的对象。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn<span class="token punctuation">.</span>metrics <span class="token operator">=</span> partial<span class="token punctuation">(</span>accuracy_multi<span class="token punctuation">,</span> thresh<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>validate<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># (#2) [0.10325726121664047,0.932948112487793]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>如果阈值设置过高，则只能选出模型十分确信的对象。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn<span class="token punctuation">.</span>metrics <span class="token operator">=</span> partial<span class="token punctuation">(</span>accuracy_multi<span class="token punctuation">,</span> thresh<span class="token operator">=</span><span class="token number">0.99</span><span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>validate<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># (#2) [0.10325726121664047,0.9447012543678284]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>通过调整 <code>thresh</code> 参数，可以控制将预测概率转换为类别标签的灵敏度，进而影响模型性能的评估。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">preds<span class="token punctuation">,</span>targs <span class="token operator">=</span> learn<span class="token punctuation">.</span>get_preds<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># preds.shape #torch.Size([2510, 20])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><code>learn.get_preds()</code> 方法被用于获取模型在验证集上的预测结果和真实目标（标签）。<code>learn</code> 是一个 <code>Learner</code> 对象，它封装了模型、数据以及训练过程中使用的其他配置。<code>get_preds</code> 方法默认在模型的验证集上执行，并返回两个元素：</p><ol><li>**<code>preds</code>**：一个张量（Tensor），包含了对每个样本的预测概率。在多标签分类问题中，这个张量的形状通常是 <code>(N, C)</code>，其中 <code>N</code> 是样本数量，<code>C</code> 是类别数量。每个元素的值表示模型预测相应样本属于特定类别的概率。</li><li>**<code>targs</code>**：一个张量（Tensor），包含了每个样本的真实标签。在多标签分类问题中，这通常也是一个 <code>(N, C)</code> 形状的张量，采用独热编码表示，即如果样本属于某个类别，则对应位置的值为1，否则为0。</li></ol><p>这个方法非常有用，因为它允许你直接获取模型的预测结果和真实标签，进而可以用于计算各种评估指标，如准确率、召回率、F1 分数等，或者进行进一步的分析和可视化。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">accuracy_multi<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> targs<span class="token punctuation">,</span> thresh<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> sigmoid<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token comment"># TensorBase(0.9579)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><code>get_preds</code>函数在默认输出时调用激活函数，所以这里<code>accuracy_multi</code>函数不再调用激活函数。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">xs <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0.05</span><span class="token punctuation">,</span><span class="token number">0.95</span><span class="token punctuation">,</span><span class="token number">29</span><span class="token punctuation">)</span><span class="token comment"># 0.05到0.95的等差为阈值，共设29个点</span>
accs <span class="token operator">=</span> <span class="token punctuation">[</span>accuracy_multi<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> targs<span class="token punctuation">,</span> thresh<span class="token operator">=</span>i<span class="token punctuation">,</span> sigmoid<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> xs<span class="token punctuation">]</span>
max_acc_index <span class="token operator">=</span> accs<span class="token punctuation">.</span>index<span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>accs<span class="token punctuation">)</span><span class="token punctuation">)</span>
max_acc_thresh <span class="token operator">=</span> xs<span class="token punctuation">[</span>max_acc_index<span class="token punctuation">]</span>

<span class="token comment"># 绘制精确度曲线</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>xs<span class="token punctuation">,</span> accs<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Accuracy'</span><span class="token punctuation">)</span>
<span class="token comment"># 标记最大精确度点</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span><span class="token punctuation">[</span>max_acc_thresh<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token builtin">max</span><span class="token punctuation">(</span>accs<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">)</span>
<span class="token comment"># 添加文本说明</span>
plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span>max_acc_thresh<span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token punctuation">(</span>accs<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'(</span><span class="token interpolation"><span class="token punctuation">{</span>max_acc_thresh<span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string">, </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">max</span><span class="token punctuation">(</span>accs<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string">)'</span></span><span class="token punctuation">,</span> ha<span class="token operator">=</span><span class="token string">'left'</span><span class="token punctuation">,</span> va<span class="token operator">=</span><span class="token string">'bottom'</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Threshold'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Accuracy'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Accuracy vs. Threshold'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406201033213.png" width="500"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">阈值vs精确度</div></center><p>本例中使用验证集来选择超参数（阈值），正是验证集的目的。</p><blockquote><p>如上改变阈值产生的是一个平滑的曲线，所以不用担心这样做会使验证集过拟合。</p><p>当阈值改变导致的准确率变化呈现出平滑曲线时，意味着模型对于阈值的选择具有一定的鲁棒性，即小幅度调整阈值不会导致准确率发生剧烈变化。这种情况下，选择一个最优阈值不太可能是因为偶然地在验证集上表现良好（即过拟合验证集），而是因为模型本身对于不同的阈值具有稳定的泛化能力。理论上，频繁尝试大量超参数值可能会导致模型在验证集上过拟合，因为可能恰好找到了某个特定的超参数值，使得模型在验证集上表现异常良好，但这并不意味着模型在未见过的数据上也能保持同样的表现。</p><p>然而，在实践中，如果超参数调整导致的性能变化呈现出平滑的趋势，这表明模型的性能对于超参数的变化不是特别敏感，因此找到的最优超参数值更有可能是因为模型本身的泛化能力，而不是过度拟合了验证集的特定特征。这种情况下，即使尝试了多个超参数值，也不太可能导致过拟合验证集的问题，因为模型表现的变化是平滑且稳定的，反映了模型对于超参数变化的真实反应，而不是随机波动或偶然误差。</p><p>总结来说，平滑的性能变化曲线意味着模型对超参数的选择具有一定的容错性，这减少了因选择了特定超参数值而导致的验证集过拟合的风险。这是理论与实践之间的一个重要区别，实践中观察到的平滑变化趋势表明了模型的稳定性和泛化能力，而不是过拟合。</p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css"></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="../../../../about" rel="external nofollow noreferrer">nusqx</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://nusqx.top">https://nusqx.top</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="../../../../about" target="_blank">nusqx</a> !</span></div></div><script async defer>document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="../../../../tags/%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB/"><span class="chip bg-color">多标签分类</span> </a><a href="../../../../tags/CV/"><span class="chip bg-color">CV</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="../../../../libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="../../../../libs/share/js/social-share.min.js"></script></div></div></div><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close"><i class="fas fa-times"></i></a><h4 class="reward-title">你的赏识是我前进的动力</h4><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><script>$(function(){$(".tabs").tabs()})</script></div></div><style>.valine-card{margin:1.5rem auto}.valine-card .card-content{padding:20px 20px 5px 20px}#vcomments textarea{box-sizing:border-box;background:url(../../../medias/comment_bg.png) 100% 100% no-repeat}#vcomments p{margin:2px 2px 10px;font-size:1.05rem;line-height:1.78rem}#vcomments blockquote p{text-indent:.2rem}#vcomments a{padding:0 2px;color:#4cbf30;font-weight:500;text-decoration:none}#vcomments img{max-width:100%;height:auto;cursor:pointer}#vcomments ol li{list-style-type:decimal}#vcomments ol,ul{display:block;padding-left:2em;word-spacing:.05rem}#vcomments ul li,ol li{display:list-item;line-height:1.8rem;font-size:1rem}#vcomments ul li{list-style-type:disc}#vcomments ul ul li{list-style-type:circle}#vcomments table,td,th{padding:12px 13px;border:1px solid #dfe2e5}#vcomments table,td,th{border:0}table tr:nth-child(2n),thead{background-color:#fafafa}#vcomments table th{background-color:#f2f2f2;min-width:80px}#vcomments table td{min-width:80px}#vcomments h1{font-size:1.85rem;font-weight:700;line-height:2.2rem}#vcomments h2{font-size:1.65rem;font-weight:700;line-height:1.9rem}#vcomments h3{font-size:1.45rem;font-weight:700;line-height:1.7rem}#vcomments h4{font-size:1.25rem;font-weight:700;line-height:1.5rem}#vcomments h5{font-size:1.1rem;font-weight:700;line-height:1.4rem}#vcomments h6{font-size:1rem;line-height:1.3rem}#vcomments p{font-size:1rem;line-height:1.5rem}#vcomments hr{margin:12px 0;border:0;border-top:1px solid #ccc}#vcomments blockquote{margin:15px 0;border-left:5px solid #42b983;padding:1rem .8rem .3rem .8rem;color:#666;background-color:rgba(66,185,131,.1)}#vcomments pre{font-family:monospace,monospace;padding:1.2em;margin:.5em 0;background:#272822;overflow:auto;border-radius:.3em;tab-size:4}#vcomments code{font-family:monospace,monospace;padding:1px 3px;font-size:.92rem;color:#e96900;background-color:#f8f8f8;border-radius:2px}#vcomments pre code{font-family:monospace,monospace;padding:0;color:#e8eaf6;background-color:#272822}#vcomments pre[class*=language-]{padding:1.2em;margin:.5em 0}#vcomments code[class*=language-],pre[class*=language-]{color:#e8eaf6}#vcomments [type=checkbox]:not(:checked),[type=checkbox]:checked{position:inherit;margin-left:-1.3rem;margin-right:.4rem;margin-top:-1px;vertical-align:middle;left:unset;visibility:visible}#vcomments b,strong{font-weight:700}#vcomments dfn{font-style:italic}#vcomments small{font-size:85%}#vcomments cite{font-style:normal}#vcomments mark{background-color:#fcf8e3;padding:.2em}#vcomments table,td,th{padding:12px 13px;border:1px solid #dfe2e5}table tr:nth-child(2n),thead{background-color:#fafafa}#vcomments table th{background-color:#f2f2f2;min-width:80px}#vcomments table td{min-width:80px}#vcomments [type=checkbox]:not(:checked),[type=checkbox]:checked{position:inherit;margin-left:-1.3rem;margin-right:.4rem;margin-top:-1px;vertical-align:middle;left:unset;visibility:visible}</style><div class="card valine-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="vcomments" class="card-content" style="display:grid"></div></div><script src="../../../../libs/valine/av-min.js"></script><script src="../../../../libs/valine/Valine.min.js"></script><script>new Valine({el:"#vcomments",appId:"GOX0XlpzLZat5ANucw5j9zjl-gzGzoHsz",appKey:"fha9hT9W6BxJDz7eBYQEPBvc",serverURLs:"",notify:!0,verify:!0,visitor:!1,avatar:"wavatar",pageSize:"10",lang:"zh-cn",placeholder:"What do you say?"})</script><div id="to_comment" class="comment-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#vcomments" title="直达评论"><i class="fas fa-comments"></i></a></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="../../28/springboot-2/"><div class="card-image"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/banner/3.jpg" class="responsive-img" alt="SpringBoot实战篇(二)"> <span class="card-title">SpringBoot实战篇(二)</span></div></a><div class="card-content article-content"><div class="summary block-with-text">SpringBoot实战项目</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-05-28 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="../../../../categories/SpringBoot/" class="post-category">SpringBoot</a></span></div></div><div class="card-action article-tags"><a href="../../../../tags/Java/"><span class="chip bg-color">Java</span> </a><a href="../../../../tags/SpringBoot/"><span class="chip bg-color">SpringBoot</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="../../18/springboot-1/"><div class="card-image"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/banner/1.jpg" class="responsive-img" alt="SpringBoot3实战篇(一)"> <span class="card-title">SpringBoot3实战篇(一)</span></div></a><div class="card-content article-content"><div class="summary block-with-text">SpringBoot实战项目</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-05-18 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="../../../../categories/SpringBoot/" class="post-category">SpringBoot</a></span></div></div><div class="card-action article-tags"><a href="../../../../tags/Java/"><span class="chip bg-color">Java</span> </a><a href="../../../../tags/SpringBoot/"><span class="chip bg-color">SpringBoot</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0!==window.getSelection&&((""+(n=window.getSelection())).length<Number.parseInt("240")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"!==n.getRangeAt(0).commonAncestorContainer.nodeName&&"CODE"!==n.getRangeAt(0).commonAncestorContainer.nodeName||(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: SQX BLOG<br />文章作者: NUS QX<br />文章链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200)))})</script><script type="text/javascript" src="../../../../libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="../../../../libs/prism/prism.min.js"></script><script type="text/javascript" src="../../../../libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="../../../../libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="../../../../libs/codeBlock/codeShrink.js"></script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget card" style="background-color:#fff"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="../../../../libs/tocbot/tocbot.min.js"></script><script>$(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });</script></main><script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]]}})</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:15px!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2018-2025</span> <a href="../../../../about" target="_blank">NUS QX</a><br><span id="sitetime"></span><span class="my-face"></span><br>&nbsp;|&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">118.2k</span> <span id="busuanzi_container_site_pv" style="display:none"></span> &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span> <span id="busuanzi_container_site_uv" style="display:none"></span> 次&nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;访客人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span> 人 <span id="busuanzi_value_site_uv" class="white-color"></span></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/nusqx" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:1976490928@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fa-solid fa-envelope"></i> </a><a href="https://gitee.com/nusqx" class="tooltipped" target="_blank" data-tooltip="访问我的Gitee: https://gitee.com/nusqx" data-position="top" data-delay="50"><i class="fa-brands fa-square-git"></i> </a><a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1976490928" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1976490928" data-position="top" data-delay="50"><i class="fab fa-qq"></i></a></div></div></footer><div class="progress-bar"></div><script language="javascript">function siteTime(){window.setTimeout("siteTime()",1e3);var e=36e5,t=24*e,o=new Date,i=o.getFullYear(),a=o.getMonth()+1,n=o.getDate(),r=o.getHours(),l=o.getMinutes(),s=o.getSeconds(),M=Date.UTC(2018,9,24,0,0,0),g=Date.UTC(i,a,n,r,l,s)-M,m=Math.floor(g/31536e6),T=Math.floor(g/t-365*m),f=Math.floor((g-(365*m+T)*t)/e),h=Math.floor((g-(365*m+T)*t-f*e)/6e4),u=Math.floor((g-(365*m+T)*t-f*e-6e4*h)/1e3);document.getElementById("sitetime").innerHTML="本站已运行 "+m+" 年 "+T+" 天 "+f+" 小时 "+h+" 分钟 "+u+" 秒"}siteTime()</script><script>$(document).ready(function(){var e=setInterval(function(){"none"!=document.getElementById("busuanzi_container_site_pv").style.display&&($("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html())+n),clearInterval(e));"none"!=$("#busuanzi_container_site_pv").css("display")&&($("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html())+t),clearInterval(e))},50),n=8e4,t=2e4})</script><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script type="text/javascript">$(function(){!function(t,s,i){"use strict";$.ajax({url:t,dataType:"xml",success:function(t){var e=$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),n=document.getElementById(s),r=document.getElementById(i);n.addEventListener("input",function(){var f='<ul class="search-result-list">',m=this.value.trim().toLowerCase().split(/[\s\-]+/);r.innerHTML="",this.value.trim().length<=0||(e.forEach(function(t){var n,e,r,s,i,l=!0,a=t.title.trim().toLowerCase(),c=t.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),u=0===(u=t.url).indexOf("/")?t.url:"/"+u,o=-1,h=-1;""!==a&&""!==c&&m.forEach(function(t,e){n=a.indexOf(t),o=c.indexOf(t),n<0&&o<0?l=!1:(o<0&&(o=0),0===e&&(h=o))}),l&&(f+="<li><a href='"+u+"' class='search-result-title'>"+a+"</a>",e=t.content.trim().replace(/<[^>]+>/g,""),0<=h&&(s=h+80,(r=h-20)<0&&(r=0),0===r&&(s=100),s>e.length&&(s=e.length),i=e.substr(r,s),m.forEach(function(t){var e=new RegExp(t,"gi");i=i.replace(e,'<em class="search-keyword">'+t+"</em>")}),f+='<p class="search-result">'+i+"...</p>"),f+="</li>")}),f+="</ul>",r.innerHTML=f)})}})}("../../../../search.xml","searchInput","searchResult")})</script><div class="stars-con"><div id="stars"></div><div id="stars2"></div><div id="stars3"></div></div><script>function switchNightMode(){$('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($("body")),setTimeout(function(){$("body").hasClass("DarkMode")?($("body").removeClass("DarkMode"),localStorage.setItem("isDark","0"),$("#sum-moon-icon").removeClass("fa-sun").addClass("fa-moon")):($("body").addClass("DarkMode"),localStorage.setItem("isDark","1"),$("#sum-moon-icon").addClass("fa-sun").removeClass("fa-moon")),setTimeout(function(){$(".Cuteen_DarkSky").fadeOut(1e3,function(){$(this).remove()})},2e3)})}</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="../../../../libs/materialize/materialize.min.js"></script><script src="../../../../libs/masonry/masonry.pkgd.min.js"></script><script src="../../../../libs/aos/aos.js"></script><script src="../../../../libs/scrollprogress/scrollProgress.min.js"></script><script src="../../../../libs/lightGallery/js/lightgallery-all.min.js"></script><script src="../../../../js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="../../../../libs/others/clicklove.js" async></script><script async src="../../../../libs/others/busuanzi.pure.mini.js"></script><script type="text/javascript" src="../../../../libs/background/ribbon-dynamic.js" async></script><script src="../../../../libs/instantpage/instantpage.js" type="module"></script><style>[bg-lazy]{background-image:none!important;background-color:#eee!important}</style><script>window.imageLazyLoadSetting={isSPA:!1,preloadRatio:1,processImages:null}</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})})</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a=c[o],i=function(){c=c.filter(function(t){return a!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(a)};(t=a).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),i()):(e=new Image,n=t.getAttribute("data-original"),e.onload=function(){t.src=n,t.removeAttribute("data-original"),i()},t.src!==n&&(e.src=n))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this)</script><script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>