<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="渐进式数据增强,Mixup,标签平滑"><meta name="description" content="高阶训练技术"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="baidu-site-verification" content="codeva-fVFbpHJJO8"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="referrer" content="no-referrer"><title>高阶训练技术 | SQX BLOG</title><link rel="icon" type="image/png" href="../../../../favicon.png"><link rel="stylesheet" type="text/css" href="../../../../libs/awesome/css/all.min.css"><link rel="stylesheet" type="text/css" href="../../../../libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="../../../../libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="../../../../libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="../../../../libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="../../../../css/matery.css"><link rel="stylesheet" type="text/css" href="../../../../css/my.css"><link rel="stylesheet" type="text/css" href="../../../../css/dark.css" media="none" onload='"all"!=media&&(media="all")'><link rel="stylesheet" href="../../../../libs/tocbot/tocbot.css"><link rel="stylesheet" href="../../../../css/post.css"><link rel="stylesheet" type="text/css" href="../../../../css/reward.css"><script src="../../../../libs/jquery/jquery-3.6.0.min.js"></script><meta name="generator" content="Hexo 6.3.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="../../../../index.html" class="waves-effect waves-light"><div><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">SQX BLOG</span></div></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="../../../../index.html" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../friends" class="waves-effect waves-light"><i class="fas fa-address-book" style="zoom:.6"></i> <span>友情链接</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li><li><a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式"><i id="sum-moon-icon" class="fas fa-sun" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">SQX BLOG</div><div class="logo-desc">Technical writer | Life adventurer</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="../../../../index.html" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="../../../../tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="../../../../categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="../../../../archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="../../../../about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="../../../../friends" class="waves-effect waves-light"><i class="fa-fw fas fa-address-book"></i> 友情链接</a></li></ul></div></div></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(../../../medias/featureimages/18.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">高阶训练技术</h1></div></div></div></div></div><main class="post-container content"><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="../../../../tags/%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/"><span class="chip bg-color">训练技术</span> </a><a href="../../../../tags/%E6%A8%A1%E5%9E%8B/"><span class="chip bg-color">模型</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="../../../../categories/%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" class="post-category">训练模型</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2024-06-10</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 5.4k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 19 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><link rel="stylesheet" href="../../../../libs/prism/prism.min.css"><div class="card-content article-card-content"><div id="articleContent"><h1 id="高阶训练技术"><a href="#高阶训练技术" class="headerlink" title="高阶训练技术"></a>高阶训练技术</h1><h2 id="Imagenette"><a href="#Imagenette" class="headerlink" title="Imagenette"></a>Imagenette</h2><p>Fast.ai的团队在创建Imagenette数据集时，是基于一个核心理念：<strong>迭代速度</strong>对于机器学习模型的开发至关重要。他们注意到，虽然ImageNet、MNIST和CIFAR10是当时常用的数据集，但它们在规模和复杂性上存在差异，这影响了模型的泛化能力和开发者的迭代速度。</p><ul><li><strong>ImageNet</strong> 数据集包含约130万张不同大小的图片，分布在1000个类别中。训练一个模型通常需要几天的时间。</li><li><strong>MNIST</strong> 数据集包含50000张28×28像素的灰度手写数字图片。</li><li><strong>CIFAR10</strong> 数据集包含60000张32×32像素的彩色图片，分为10个类别。</li></ul><p>小型数据集（如MNIST和CIFAR10）在ImageNet这样的大型数据集上的表现并不理想。有效的方法往往需要直接在ImageNet上开发和训练，这导致许多人认为只有拥有大量计算资源的研究人员才能有效地贡献图像分类算法的发展。</p><p>Fast.ai的团队质疑这一观点，并认为没有证据表明ImageNet就是唯一合适的数据集大小。因此，他们决定尝试创建一个新的数据集——<strong>Imagenette</strong>。他们从ImageNet中选择了10个外观差异很大的类别，以便快速、低成本地创建能够识别这些类别的分类器。通过在Imagenette上测试算法调整，他们发现了一些有效的方法，并将这些方法应用到ImageNet上，结果发现这些调整在ImageNet上也表现良好。</p><p>这个案例强调了一个重要的信息：给定的数据集不一定是你想要的数据集，尤其不太可能是你进行开发和原型设计时想要的数据集。你应该追求的是迭代速度不超过几分钟——也就是说，当你想尝试一个新想法时，你应该能够在几分钟内训练一个模型并看到结果。如果实验花费的时间更长，你应该考虑如何缩小数据集或简化模型来提高实验速度。你能做的实验越多，结果越好！</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> fastai<span class="token punctuation">.</span>vision<span class="token punctuation">.</span><span class="token builtin">all</span> <span class="token keyword">import</span> <span class="token operator">*</span>
path <span class="token operator">=</span> untar_data<span class="token punctuation">(</span>URLs<span class="token punctuation">.</span>IMAGENETTE<span class="token punctuation">)</span>

dblock <span class="token operator">=</span> DataBlock<span class="token punctuation">(</span>blocks<span class="token operator">=</span><span class="token punctuation">(</span>ImageBlock<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> CategoryBlock<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                   get_items<span class="token operator">=</span>get_image_files<span class="token punctuation">,</span>
                   get_y<span class="token operator">=</span>parent_label<span class="token punctuation">,</span>
                   item_tfms<span class="token operator">=</span>Resize<span class="token punctuation">(</span><span class="token number">460</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                   batch_tfms<span class="token operator">=</span>aug_transforms<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span> min_scale<span class="token operator">=</span><span class="token number">0.75</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
dls <span class="token operator">=</span> dblock<span class="token punctuation">.</span>dataloaders<span class="token punctuation">(</span>path<span class="token punctuation">,</span> bs<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>

<span class="token comment"># 进行一次训练作为基准</span>
model <span class="token operator">=</span> xresnet50<span class="token punctuation">(</span>n_out<span class="token operator">=</span>dls<span class="token punctuation">.</span>c<span class="token punctuation">)</span>
learn <span class="token operator">=</span> Learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token operator">=</span>CrossEntropyLossFlat<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> metrics<span class="token operator">=</span>accuracy<span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3e-3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406201741606.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">训练基准</div></center><p><code>n_out=dls.c</code> 指定了模型输出层的神经元数量，应与数据集中的类别数量相匹配。这里，<code>dls.c</code> 从 <code>DataLoaders</code> 对象 <code>dls</code> 中获取类别数。</p><p>这是一个不错的基准，因为没有使用预训练模型，也可以表现很好。</p><p>使用从头开始训练的模型，或对预训练模型进行微调，使其能够很好地泛化到一个差异很大的数据集时，一些额外的技术非常重要。</p><h2 id="数据标准化"><a href="#数据标准化" class="headerlink" title="数据标准化"></a>数据标准化</h2><p>训练模型时，如果输入的数据是标准化的——即均值为0、标准差为1——会对之后的训练有很大帮助。但大多数图像和计算机视觉的像素值在0-255或0-1，在这两种情况下，数据都不是均值为0、标准差为1的。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">,</span>y <span class="token operator">=</span> dls<span class="token punctuation">.</span>one_batch<span class="token punctuation">(</span><span class="token punctuation">)</span>
x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>std<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 对所有维度做均值化处理（除了通道数这一维度，索引1）</span>
<span class="token comment"># (TensorImage([0.4715, 0.4795, 0.4579], device='cuda:0'),</span>
<span class="token comment"># TensorImage([0.2759, 0.2758, 0.3021], device='cuda:0'))</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以在数据块的数据增强部分添加<code>Normalize</code>转换。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_dls</span><span class="token punctuation">(</span>bs<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    dblock <span class="token operator">=</span> DataBlock<span class="token punctuation">(</span>blocks<span class="token operator">=</span><span class="token punctuation">(</span>ImageBlock<span class="token punctuation">,</span> CategoryBlock<span class="token punctuation">)</span><span class="token punctuation">,</span>
                   get_items<span class="token operator">=</span>get_image_files<span class="token punctuation">,</span>
                   get_y<span class="token operator">=</span>parent_label<span class="token punctuation">,</span>
                   item_tfms<span class="token operator">=</span>Resize<span class="token punctuation">(</span><span class="token number">460</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                   batch_tfms<span class="token operator">=</span><span class="token punctuation">[</span><span class="token operator">*</span>aug_transforms<span class="token punctuation">(</span>size<span class="token operator">=</span>size<span class="token punctuation">,</span> min_scale<span class="token operator">=</span><span class="token number">0.75</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Normalize<span class="token punctuation">.</span>from_stats<span class="token punctuation">(</span><span class="token operator">*</span>imagenet_stats<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> dblock<span class="token punctuation">.</span>dataloaders<span class="token punctuation">(</span>path<span class="token punctuation">,</span> bs<span class="token operator">=</span>bs<span class="token punctuation">)</span>

dls <span class="token operator">=</span> get_dls<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span>
x<span class="token punctuation">,</span>y <span class="token operator">=</span> dls<span class="token punctuation">.</span>one_batch<span class="token punctuation">(</span><span class="token punctuation">)</span>
x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>std<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 查看标准化处理后的均值和标准差</span>
<span class="token comment"># (TensorImage([-0.0150,  0.0287,  0.1145], device='cuda:0'),</span>
<span class="token comment"># TensorImage([1.3090, 1.3218, 1.3806], device='cuda:0'))</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>imagenet_stats</code> 是预定义的 ImageNet 数据集的均值和标准差，用于将图像数据标准化。</p><p>标准化后对训练模型的影响</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> xresnet50<span class="token punctuation">(</span>n_out<span class="token operator">=</span>dls<span class="token punctuation">.</span>c<span class="token punctuation">)</span>
learn <span class="token operator">=</span> Learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token operator">=</span>CrossEntropyLossFlat<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> metrics<span class="token operator">=</span>accuracy<span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3e-3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406201912898.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">标准化后的训练结果</div></center><p>😅，似乎看不出什么明显的效果。但在处理预训练的模型时，标准化会变得尤为重要，因为预训练模型只知道如何处理它以前见过的数据类型。如果预训练数据的平均像素值为0，但所用数据像素可能是最小值为0，那么模型和预期的结果会有很大差异！</p><p>这意味着当构建模型时，需要设定用于标准化的规则，因为用于推理和迁移学习的人都要使用相同的规则。</p><p>在使用预训练模型通过<code>vision_learner</code>进行训练时，fastai库会自动添加适当的<code>Normalize</code>变换。这是因为预训练模型是用特定的统计数据（通常来自ImageNet数据集）进行训练的，所以库能够为你填充这些统计数据。这就是为什么在使用预训练模型时，我们不需要手动处理标准化（normalization）。但是，当我们从头开始训练模型时，我们需要手动添加这些标准化信息。这是因为模型尚未学习到任何数据的分布，所以我们需要指定如何对输入数据进行标准化以匹配模型的预期输入。</p><p><strong>渐进式调整尺寸</strong>（progressive resizing），这是一种训练技巧，其中我们首先以较小的图像尺寸开始训练，然后逐步增加图像尺寸。这样做的好处是可以加快训练的初期阶段，因为小尺寸的图像计算量更小。一旦模型在小尺寸上学习到了有用的特征，我们再逐步增加图像尺寸，以提高模型的准确性和泛化能力。这种方法可以看作是一种计算效率和性能之间的折中。</p><p>这种方法不仅可以提高训练速度，还可以帮助模型学习到从低分辨率到高分辨率的特征，这对于最终模型的性能是有益的。总的来说，渐进式调整尺寸是一种有效的策略，可以在保持较快迭代速度的同时，逐步提升模型的性能。</p><h2 id="渐进式调整尺寸"><a href="#渐进式调整尺寸" class="headerlink" title="渐进式调整尺寸"></a>渐进式调整尺寸</h2><blockquote><p>开始训练时使用小图像，结束训练时使用大图像。花费大部分时间用小图像进行训练，有助于更快地完成训练。使用大图像完成训练，这让最终的准确率更高。</p></blockquote><p>卷积神经网络（CNN）学习的特征与图像大小无关。确实，CNN的早期层次会学习到边缘和梯度等基本特征，而后期层次则可能识别出鼻子、日落等更复杂的特征。这意味着，即使在训练过程中改变图像大小，我们也不需要为模型找到完全不同的参数。</p><p>当我们从小尺寸图像转向大尺寸图像时，模型确实需要一些调整，因为大图像包含更多的细节和可能的特征。这与<strong>迁移学习</strong>（transfer learning）有些相似，我们利用已经学习到的知识来帮助模型学习新的任务。在这种情况下，我们可以使用<code>fine_tune</code>方法来调整模型参数，使其适应新的图像大小。</p><p><strong>渐进式调整尺寸</strong>（progressive resizing）不仅可以提高训练效率，还是一种数据增强的形式。通过这种方式，模型在不同尺寸的图像上训练，可以学习到更多样化的特征，从而提高模型对新数据的泛化能力。因此，使用渐进式调整尺寸训练的模型通常会有更好的泛化表现。</p><p>构建一个小尺寸的DataLoaders进行训练</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dls <span class="token operator">=</span> get_dls<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span> <span class="token comment">#128批次大小，128*128像素</span>
learn <span class="token operator">=</span> Learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> xresnet50<span class="token punctuation">(</span>n_out<span class="token operator">=</span>dls<span class="token punctuation">.</span>c<span class="token punctuation">)</span><span class="token punctuation">,</span> loss_func<span class="token operator">=</span>CrossEntropyLossFlat<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
                metrics<span class="token operator">=</span>accuracy<span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3e-3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406202047898.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">标准化后小尺寸的训练结果</div></center><p>image/image-20240620194230901.png</p><p>然后可以换掉Learner内部的DataLoaders，并进行微调：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn<span class="token punctuation">.</span>dls <span class="token operator">=</span> get_dls<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fine_tune<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1e-3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406202047292.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">渐进放大尺寸的训练结果</div></center><p>可以反复增加图像大小并训练更多周期，但是不要不原始图像大。</p><p>对于<strong>迁移学习</strong>，如果预训练模型与迁移学习任务非常相似，并且使用了类似大小的图像，那么使用较小的图像进行训练可能会损害预训练好的权重，因为这些权重已经针对特定尺寸的图像进行了优化。但如果迁移学习任务使用的图像与预训练任务中的图像在大小、形状或风格上有所不同，那么渐进式调整图像大小可能会有所帮助，因为它允许模型适应新的图像特征。</p><h2 id="测试期的数据增强"><a href="#测试期的数据增强" class="headerlink" title="测试期的数据增强"></a>测试期的数据增强</h2><p><strong>随机裁剪</strong>是一种有效的数据增强方法，它通过从图像中裁剪出不同的部分来增加模型训练的多样性，从而提高模型的泛化能力。然而，使用<strong>中心裁剪</strong>作为验证集的处理方式可能会导致一些问题，尤其是当图像边缘有重要特征时，这些特征可能会被裁剪掉，从而影响模型的准确性。</p><p>为了解决这个问题，您可以考虑以下几种方法：</p><ol><li><strong>避免随机裁剪</strong>：直接使用原始图像的比例，但这样会失去数据增强的好处。</li><li><strong>调整图像比例</strong>：将矩形图像压缩或拉伸以适应正方形空间，但这可能会使模型难以识别因变形而失去原有比例的图像。</li><li><strong>测试时增强（TTA）</strong>：不仅仅使用中心裁剪，而是从原始矩形图像中选择多个区域进行裁剪，将每个裁剪区域通过模型进行预测，并取最大值或平均值作为最终结果。这种方法不仅可以用于不同的裁剪，还可以用于测试时增强的所有参数，从而提高模型在实际应用中的表现。</li></ol><p>总的来说，<strong>测试时增强（TTA）</strong>是一个强大的技术，它通过在测试时应用多种数据增强策略来提高模型的性能。这种方法可以通过多次预测并综合结果来减少单次预测误差的影响。</p><blockquote><p>“测试时增强（TTA）”的概念是指在推理或验证阶段，通过数据增强创建每张图像的多个版本，然后对每个增强版本的图像的预测结果取平均值或最大值。这是一种提高模型性能的技术，特别是在图像识别任务中。它可以帮助模型更好地泛化到未见过的数据，从而提高其准确性。</p></blockquote><p><strong>测试时增强（TTA）</strong>可以根据数据集的不同，显著提高模型的准确性。这种方法不会改变训练所需的时间，但会根据请求的测试时增强图像的数量增加验证或推理所需的时间。默认情况下，fastai 会使用未增强的中心裁剪图像加上四个随机增强的图像。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">preds<span class="token punctuation">,</span>targs <span class="token operator">=</span> learn<span class="token punctuation">.</span>tta<span class="token punctuation">(</span><span class="token punctuation">)</span>
accuracy<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> targs<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 0.8539955019950867</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>使用<strong>测试时增强（TTA）</strong>确实可以在不需要额外训练的情况下提高模型的性能。但是，这确实会使推理过程变慢。例如，如果您在 TTA 中平均使用五张图像，那么推理速度将会是原来的五倍慢。</p><p>这是一个权衡的问题，您需要根据实际应用场景来决定是否使用 TTA。如果模型的准确性是首要考虑的因素，而推理时间较长是可以接受的，那么 TTA 是一个很好的选择。但如果您需要快速的推理速度，那么可能需要寻找其他方法来提高性能，或者接受不使用 TTA 的准确性水平。</p><h2 id="Mixup"><a href="#Mixup" class="headerlink" title="Mixup"></a>Mixup</h2><p>Mixup 是一种数据增强技术，由 Hongyi Zhang 等人在 2017 年的论文 “mixup: Beyond Empirical Risk Minimization” 中介绍。这种技术可以显著提高准确性，<strong>特别是当您没有大量数据，且没有在与您的数据集相似的数据上训练过的预训练模型时</strong>。论文解释说：“虽然数据增强始终能够改善泛化，但该过程依赖于数据集，因此需要使用专家知识。”例如，翻转图像是数据增强的常见部分，但您应该只水平翻转，还是也垂直翻转？答案取决于您的数据集。此外，如果翻转（例如）没有为您提供足够的数据增强，您不能“更多地翻转”。拥有可以“增大”或“减小”变化量的数据增强技术很有帮助，以便查看哪种最适合您。</p><p>对于每张图像，Mixup 的工作方式如下：</p><ol><li>从数据集中随机选择另一张图像。</li><li>随机选择一个权重。</li><li>使用步骤 2 中的权重对选定的图像与自己的图像进行加权平均；这将是自变量。</li><li>使用相同的权重对这张图像的标签与自己的图像的标签进行加权平均；这将是因变量。</li></ol><p>在伪代码中，我们正在做这个（其中 t 是我们加权平均的权重）：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">image2<span class="token punctuation">,</span> target2 <span class="token operator">=</span> dataset<span class="token punctuation">[</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
t <span class="token operator">=</span> random_float<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
new_image <span class="token operator">=</span> t <span class="token operator">*</span> image1 <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>t<span class="token punctuation">)</span> <span class="token operator">*</span> image2
new_target <span class="token operator">=</span> t <span class="token operator">*</span> target1 <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>t<span class="token punctuation">)</span> <span class="token operator">*</span> target2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>为了使这个起作用，我们的目标需要是独热编码的。</p><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406202043977.png" width="700"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Mixup论文摘录</div></center><blockquote><p>维基百科数学符号表：<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Glossary_of_mathematical_symbols">https://en.wikipedia.org/wiki/Glossary_of_mathematical_symbols</a></p></blockquote><p>使用Mixup对图像进行线性组合时的效果。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">church <span class="token operator">=</span> PILImage<span class="token punctuation">.</span>create<span class="token punctuation">(</span>get_image_files_sorted<span class="token punctuation">(</span>path<span class="token operator">/</span><span class="token string">'train'</span><span class="token operator">/</span><span class="token string">'n03028079'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
gas <span class="token operator">=</span> PILImage<span class="token punctuation">.</span>create<span class="token punctuation">(</span>get_image_files_sorted<span class="token punctuation">(</span>path<span class="token operator">/</span><span class="token string">'train'</span><span class="token operator">/</span><span class="token string">'n03425413'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
church <span class="token operator">=</span> church<span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
gas <span class="token operator">=</span> gas<span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tchurch <span class="token operator">=</span> tensor<span class="token punctuation">(</span>church<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.</span>
tgas <span class="token operator">=</span> tensor<span class="token punctuation">(</span>gas<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.</span>

_<span class="token punctuation">,</span>axs <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
show_image<span class="token punctuation">(</span>tchurch<span class="token punctuation">,</span> ax<span class="token operator">=</span>axs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
show_image<span class="token punctuation">(</span>tgas<span class="token punctuation">,</span> ax<span class="token operator">=</span>axs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
show_image<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.3</span><span class="token operator">*</span>tchurch <span class="token operator">+</span> <span class="token number">0.7</span><span class="token operator">*</span>tgas<span class="token punctuation">)</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>axs<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406202053926.png" width="700"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">混合一座教堂和加油站</div></center><p>如果第三张图像是通过将第一张图像的0.3倍与第二张图像的0.7倍相加构建的，模型应该预测“教堂”还是“加油站”？正确的答案是30%的教堂和70%的加油站，因为如果我们取独热编码目标的线性组合，就会得到这个结果。例如，假设我们有10个类别，“教堂”由索引2表示，“加油站”由索引7表示，独热编码的表示分别是：</p><p>[0,0,1,0,0,0,0,0,0,0]和[0,0,0,0,0,0,0,1,0,0]</p><p>所以我们的<strong>最终目标</strong>是：[0,0,0.3,0,0,0,0,0.7,0,0]</p><p>这意味着模型应该预测图像是30%的教堂和70%的加油站。这种方法允许模型学习从图像的混合中预测多个类别的概率，这是Mixup数据增强技术的核心思想。</p><p>通过给Learner添加一个<code>回调函数</code>，它时fastai内用于在训练循环中添加自定义行为的操作。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> xresnet50<span class="token punctuation">(</span>n_out<span class="token operator">=</span>dls<span class="token punctuation">.</span>c<span class="token punctuation">)</span>
learn <span class="token operator">=</span> Learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token operator">=</span>CrossEntropyLossFlat<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
                metrics<span class="token operator">=</span>accuracy<span class="token punctuation">,</span> cbs<span class="token operator">=</span>MixUp<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3e-3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>当我们以这种方式混合数据训练模型时，确实会更难训练，因为很难看清每张图片中的内容。模型必须预测每张图片的两个标签，而不仅仅是一个，同时还要弄清楚每个标签的权重。然而，过拟合似乎不太可能成为问题，因为我们在每个周期展示的不是同一张图片，而是两张图片的随机组合。</p><p>与我们见过的其他增强方法相比，Mixup 需要更多的周期来训练以获得更好的准确性。</p><p>对于超过 80 个周期的训练，所有领先结果都使用了 Mixup，而对于更少的周期，则没有使用 Mixup。这也符合我们使用 Mixup 的经验。</p><ol><li><p>Mixup的应用广泛性：Mixup不仅可以用于图像数据，还可以用于其他类型的数据，如自然语言处理（NLP）。这是因为Mixup的核心思想是将两个数据点混合在一起，这个过程不限于任何特定类型的数据。</p></li><li><p>完美损失的问题：在传统模型中，我们追求的是使损失函数尽可能接近完美，即标签值为1或0。但是，由于softmax和sigmoid函数的输出永远不会达到1或0，这导致在训练过程中，模型的激活值会越来越极端，以接近这些理想值。</p></li><li><p>Mixup解决的问题：使用Mixup时，我们不再追求完美的1或0标签。除非两个混合的图像属于同一类别，否则我们得到的标签将是两个类别标签的线性组合，例如0.7和0.3。这减少了模型激活值变得极端的情况。</p></li><li><p>Mixup的一个副作用：Mixup在混合标签时可能会不小心使标签值大于0或小于1。这意味着我们没有直接告诉模型以这种方式改变标签。如果我们想要控制标签值更接近或远离0和1，我们需要调整Mixup的比例，但这也会影响数据增强的程度，可能会带来我们不想要的结果。</p></li></ol><p>标签平滑的解决方案：为了更直接地处理标签值的问题，我们可以使用标签平滑技术。标签平滑是一种正则化技术，它通过为标签引入噪声来使模型更加健壮，从而更好地泛化。它通过替换硬分类目标（0和1）为柔性目标，来解决数据集中可能存在的错误标签问题。</p><h2 id="标签平滑"><a href="#标签平滑" class="headerlink" title="标签平滑"></a>标签平滑</h2><p>在分类问题中，理论上我们的目标是进行独热编码，即对于每个实例，我们有一个长度等于类别数的数组，其中一个类别对应的位置是1，其余都是0。这种编码方式意味着模型被训练为对除了正确类别之外的所有类别返回0，对正确类别返回1。然而，即使是0.999这样接近1的值也不被视为“足够好”，因为模型会得到梯度并学习预测更高置信度的激活值。这会鼓励过拟合，并且在推理时给出一个不会提供有意义概率的模型：它总是对预测类别说1，即使它不太确定，只是因为它是这样训练的。</p><p>如果数据标签不完美，这种情况会变得非常有害。例如，在我们研究的熊分类器中，一些图像被错误标记，或者包含两种不同类型的熊。通常情况下，你的数据永远不会是完美的。即使标签是人工制作的，人们也可能会犯错误，或者对难以标记的图像有不同的看法。</p><p><strong>为了解决这个问题，我们可以将所有的1替换为略小于1的数字，将所有的0替换为略大于0的数字，然后进行训练。这就是所谓的标签平滑。</strong>通过鼓励模型不要过于自信，标签平滑将使训练更加稳健，即使存在标记错误的数据。结果将是一个泛化能力更强的模型。</p><p>标签平滑在实践中是这样工作的：我们从独热编码标签开始，然后将所有的0替换为 𝜖/𝑁 ，其中N是类别的数量，ε是一个参数（通常是0.1，这意味着我们对我们的标签有10%的不确定性）。由于我们希望标签总和为1，所以将1替换为 1−𝜖+𝜖/𝑁。这样，我们就不会鼓励模型过度自信地预测。在我们有10个类别的Imagenette示例中，目标可能变成如下（这里是对应于索引3的目标）：</p><p>[0.01, 0.01, 0.01, 0.91, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]</p><p>在实践中，我们不希望对标签进行独热编码，幸运的是我们也不需要这样做（独热编码只是用来解释标签平滑是什么并将其可视化的一个好方法）。</p><p>只需在调用Learner时修改损失函数：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> xresnet50<span class="token punctuation">(</span>n_out<span class="token operator">=</span>dls<span class="token punctuation">.</span>c<span class="token punctuation">)</span>
learn <span class="token operator">=</span> Learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token operator">=</span>LabelSmoothingCrossEntropy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
                metrics<span class="token operator">=</span>accuracy<span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3e-3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406202137661.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">标签平滑</div></center><p>和Mixup一样，通常看不到标签平滑带来的显著改进，除非训练很多周期，那该训练多少个周期呢？</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>通过Mixup和/或标签平滑进行更长时间的训练是否可以避免过拟合并获得更好的结果。尝试渐进式调整尺寸和测试期的数据增强。</p><p>最重要的是，如果数据集很大，没有必要对整个数据集进行建模。找到一个能代表整体的小数据子集，就像这里使用Imagenette，并在其上进行实验。</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css"></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="../../../../about" rel="external nofollow noreferrer">nusqx</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://nusqx.top">https://nusqx.top</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="../../../../about" target="_blank">nusqx</a> !</span></div></div><script async defer>document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="../../../../tags/%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/"><span class="chip bg-color">训练技术</span> </a><a href="../../../../tags/%E6%A8%A1%E5%9E%8B/"><span class="chip bg-color">模型</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="../../../../libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="../../../../libs/share/js/social-share.min.js"></script></div></div></div><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close"><i class="fas fa-times"></i></a><h4 class="reward-title">你的赏识是我前进的动力</h4><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><script>$(function(){$(".tabs").tabs()})</script></div></div><style>.valine-card{margin:1.5rem auto}.valine-card .card-content{padding:20px 20px 5px 20px}#vcomments textarea{box-sizing:border-box;background:url(../../../medias/comment_bg.png) 100% 100% no-repeat}#vcomments p{margin:2px 2px 10px;font-size:1.05rem;line-height:1.78rem}#vcomments blockquote p{text-indent:.2rem}#vcomments a{padding:0 2px;color:#4cbf30;font-weight:500;text-decoration:none}#vcomments img{max-width:100%;height:auto;cursor:pointer}#vcomments ol li{list-style-type:decimal}#vcomments ol,ul{display:block;padding-left:2em;word-spacing:.05rem}#vcomments ul li,ol li{display:list-item;line-height:1.8rem;font-size:1rem}#vcomments ul li{list-style-type:disc}#vcomments ul ul li{list-style-type:circle}#vcomments table,td,th{padding:12px 13px;border:1px solid #dfe2e5}#vcomments table,td,th{border:0}table tr:nth-child(2n),thead{background-color:#fafafa}#vcomments table th{background-color:#f2f2f2;min-width:80px}#vcomments table td{min-width:80px}#vcomments h1{font-size:1.85rem;font-weight:700;line-height:2.2rem}#vcomments h2{font-size:1.65rem;font-weight:700;line-height:1.9rem}#vcomments h3{font-size:1.45rem;font-weight:700;line-height:1.7rem}#vcomments h4{font-size:1.25rem;font-weight:700;line-height:1.5rem}#vcomments h5{font-size:1.1rem;font-weight:700;line-height:1.4rem}#vcomments h6{font-size:1rem;line-height:1.3rem}#vcomments p{font-size:1rem;line-height:1.5rem}#vcomments hr{margin:12px 0;border:0;border-top:1px solid #ccc}#vcomments blockquote{margin:15px 0;border-left:5px solid #42b983;padding:1rem .8rem .3rem .8rem;color:#666;background-color:rgba(66,185,131,.1)}#vcomments pre{font-family:monospace,monospace;padding:1.2em;margin:.5em 0;background:#272822;overflow:auto;border-radius:.3em;tab-size:4}#vcomments code{font-family:monospace,monospace;padding:1px 3px;font-size:.92rem;color:#e96900;background-color:#f8f8f8;border-radius:2px}#vcomments pre code{font-family:monospace,monospace;padding:0;color:#e8eaf6;background-color:#272822}#vcomments pre[class*=language-]{padding:1.2em;margin:.5em 0}#vcomments code[class*=language-],pre[class*=language-]{color:#e8eaf6}#vcomments [type=checkbox]:not(:checked),[type=checkbox]:checked{position:inherit;margin-left:-1.3rem;margin-right:.4rem;margin-top:-1px;vertical-align:middle;left:unset;visibility:visible}#vcomments b,strong{font-weight:700}#vcomments dfn{font-style:italic}#vcomments small{font-size:85%}#vcomments cite{font-style:normal}#vcomments mark{background-color:#fcf8e3;padding:.2em}#vcomments table,td,th{padding:12px 13px;border:1px solid #dfe2e5}table tr:nth-child(2n),thead{background-color:#fafafa}#vcomments table th{background-color:#f2f2f2;min-width:80px}#vcomments table td{min-width:80px}#vcomments [type=checkbox]:not(:checked),[type=checkbox]:checked{position:inherit;margin-left:-1.3rem;margin-right:.4rem;margin-top:-1px;vertical-align:middle;left:unset;visibility:visible}</style><div class="card valine-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="vcomments" class="card-content" style="display:grid"></div></div><script src="../../../../libs/valine/av-min.js"></script><script src="../../../../libs/valine/Valine.min.js"></script><script>new Valine({el:"#vcomments",appId:"GOX0XlpzLZat5ANucw5j9zjl-gzGzoHsz",appKey:"fha9hT9W6BxJDz7eBYQEPBvc",serverURLs:"",notify:!0,verify:!0,visitor:!1,avatar:"wavatar",pageSize:"10",lang:"zh-cn",placeholder:"What do you say?"})</script><div id="to_comment" class="comment-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#vcomments" title="直达评论"><i class="fas fa-comments"></i></a></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="../../15/collab/"><div class="card-image"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/featureimages/27.jpg" class="responsive-img" alt="协同过滤"> <span class="card-title">协同过滤</span></div></a><div class="card-content article-content"><div class="summary block-with-text">协同过滤</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-06-15 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="../../../../categories/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4/" class="post-category">协同过滤</a></span></div></div><div class="card-action article-tags"><a href="../../../../tags/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4/"><span class="chip bg-color">协同过滤</span> </a><a href="../../../../tags/%E8%A1%A8%E6%A0%BC%E5%BB%BA%E6%A8%A1/"><span class="chip bg-color">表格建模</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="../../05/springboot-3/"><div class="card-image"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/featureimages/9.jpg" class="responsive-img" alt="SpringBoot项目部署与多环境开发"> <span class="card-title">SpringBoot项目部署与多环境开发</span></div></a><div class="card-content article-content"><div class="summary block-with-text">SpringBoot项目部署、多环境开发</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-06-05 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="../../../../categories/SpringBoot/" class="post-category">SpringBoot</a></span></div></div><div class="card-action article-tags"><a href="../../../../tags/Java/"><span class="chip bg-color">Java</span> </a><a href="../../../../tags/SpringBoot/"><span class="chip bg-color">SpringBoot</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0!==window.getSelection&&((""+(n=window.getSelection())).length<Number.parseInt("240")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"!==n.getRangeAt(0).commonAncestorContainer.nodeName&&"CODE"!==n.getRangeAt(0).commonAncestorContainer.nodeName||(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: SQX BLOG<br />文章作者: NUS QX<br />文章链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200)))})</script><script type="text/javascript" src="../../../../libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="../../../../libs/prism/prism.min.js"></script><script type="text/javascript" src="../../../../libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="../../../../libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="../../../../libs/codeBlock/codeShrink.js"></script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget card" style="background-color:#fff"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="../../../../libs/tocbot/tocbot.min.js"></script><script>$(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });</script></main><script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]]}})</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:15px!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2018-2025</span> <a href="../../../../about" target="_blank">NUS QX</a><br><span id="sitetime"></span><span class="my-face"></span><br>&nbsp;|&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">118.2k</span> <span id="busuanzi_container_site_pv" style="display:none"></span> &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span> <span id="busuanzi_container_site_uv" style="display:none"></span> 次&nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;访客人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span> 人 <span id="busuanzi_value_site_uv" class="white-color"></span></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/nusqx" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:1976490928@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fa-solid fa-envelope"></i> </a><a href="https://gitee.com/nusqx" class="tooltipped" target="_blank" data-tooltip="访问我的Gitee: https://gitee.com/nusqx" data-position="top" data-delay="50"><i class="fa-brands fa-square-git"></i> </a><a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1976490928" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1976490928" data-position="top" data-delay="50"><i class="fab fa-qq"></i></a></div></div></footer><div class="progress-bar"></div><script language="javascript">function siteTime(){window.setTimeout("siteTime()",1e3);var e=36e5,t=24*e,o=new Date,i=o.getFullYear(),a=o.getMonth()+1,n=o.getDate(),r=o.getHours(),l=o.getMinutes(),s=o.getSeconds(),M=Date.UTC(2018,9,24,0,0,0),g=Date.UTC(i,a,n,r,l,s)-M,m=Math.floor(g/31536e6),T=Math.floor(g/t-365*m),f=Math.floor((g-(365*m+T)*t)/e),h=Math.floor((g-(365*m+T)*t-f*e)/6e4),u=Math.floor((g-(365*m+T)*t-f*e-6e4*h)/1e3);document.getElementById("sitetime").innerHTML="本站已运行 "+m+" 年 "+T+" 天 "+f+" 小时 "+h+" 分钟 "+u+" 秒"}siteTime()</script><script>$(document).ready(function(){var e=setInterval(function(){"none"!=document.getElementById("busuanzi_container_site_pv").style.display&&($("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html())+n),clearInterval(e));"none"!=$("#busuanzi_container_site_pv").css("display")&&($("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html())+t),clearInterval(e))},50),n=8e4,t=2e4})</script><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script type="text/javascript">$(function(){!function(t,s,i){"use strict";$.ajax({url:t,dataType:"xml",success:function(t){var e=$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),n=document.getElementById(s),r=document.getElementById(i);n.addEventListener("input",function(){var f='<ul class="search-result-list">',m=this.value.trim().toLowerCase().split(/[\s\-]+/);r.innerHTML="",this.value.trim().length<=0||(e.forEach(function(t){var n,e,r,s,i,l=!0,a=t.title.trim().toLowerCase(),c=t.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),u=0===(u=t.url).indexOf("/")?t.url:"/"+u,o=-1,h=-1;""!==a&&""!==c&&m.forEach(function(t,e){n=a.indexOf(t),o=c.indexOf(t),n<0&&o<0?l=!1:(o<0&&(o=0),0===e&&(h=o))}),l&&(f+="<li><a href='"+u+"' class='search-result-title'>"+a+"</a>",e=t.content.trim().replace(/<[^>]+>/g,""),0<=h&&(s=h+80,(r=h-20)<0&&(r=0),0===r&&(s=100),s>e.length&&(s=e.length),i=e.substr(r,s),m.forEach(function(t){var e=new RegExp(t,"gi");i=i.replace(e,'<em class="search-keyword">'+t+"</em>")}),f+='<p class="search-result">'+i+"...</p>"),f+="</li>")}),f+="</ul>",r.innerHTML=f)})}})}("../../../../search.xml","searchInput","searchResult")})</script><div class="stars-con"><div id="stars"></div><div id="stars2"></div><div id="stars3"></div></div><script>function switchNightMode(){$('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($("body")),setTimeout(function(){$("body").hasClass("DarkMode")?($("body").removeClass("DarkMode"),localStorage.setItem("isDark","0"),$("#sum-moon-icon").removeClass("fa-sun").addClass("fa-moon")):($("body").addClass("DarkMode"),localStorage.setItem("isDark","1"),$("#sum-moon-icon").addClass("fa-sun").removeClass("fa-moon")),setTimeout(function(){$(".Cuteen_DarkSky").fadeOut(1e3,function(){$(this).remove()})},2e3)})}</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="../../../../libs/materialize/materialize.min.js"></script><script src="../../../../libs/masonry/masonry.pkgd.min.js"></script><script src="../../../../libs/aos/aos.js"></script><script src="../../../../libs/scrollprogress/scrollProgress.min.js"></script><script src="../../../../libs/lightGallery/js/lightgallery-all.min.js"></script><script src="../../../../js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="../../../../libs/others/clicklove.js" async></script><script async src="../../../../libs/others/busuanzi.pure.mini.js"></script><script type="text/javascript" src="../../../../libs/background/ribbon-dynamic.js" async></script><script src="../../../../libs/instantpage/instantpage.js" type="module"></script><style>[bg-lazy]{background-image:none!important;background-color:#eee!important}</style><script>window.imageLazyLoadSetting={isSPA:!1,preloadRatio:1,processImages:null}</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})})</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a=c[o],i=function(){c=c.filter(function(t){return a!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(a)};(t=a).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),i()):(e=new Image,n=t.getAttribute("data-original"),e.onload=function(){t.src=n,t.removeAttribute("data-original"),i()},t.src!==n&&(e.src=n))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this)</script><script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>