<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="协调过滤,推荐系统"><meta name="description" content="协同过滤"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="baidu-site-verification" content="codeva-fVFbpHJJO8"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="referrer" content="no-referrer"><title>协同过滤 | SQX BLOG</title><link rel="icon" type="image/png" href="../../../../favicon.png"><link rel="stylesheet" type="text/css" href="../../../../libs/awesome/css/all.min.css"><link rel="stylesheet" type="text/css" href="../../../../libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="../../../../libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="../../../../libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="../../../../libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="../../../../css/matery.css"><link rel="stylesheet" type="text/css" href="../../../../css/my.css"><link rel="stylesheet" type="text/css" href="../../../../css/dark.css" media="none" onload='"all"!=media&&(media="all")'><link rel="stylesheet" href="../../../../libs/tocbot/tocbot.css"><link rel="stylesheet" href="../../../../css/post.css"><link rel="stylesheet" type="text/css" href="../../../../css/reward.css"><script src="../../../../libs/jquery/jquery-3.6.0.min.js"></script><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="../../../../index.html" class="waves-effect waves-light"><div><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">SQX BLOG</span></div></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="../../../../index.html" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../friends" class="waves-effect waves-light"><i class="fas fa-address-book" style="zoom:.6"></i> <span>友情链接</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li><li><a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式"><i id="sum-moon-icon" class="fas fa-sun" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">SQX BLOG</div><div class="logo-desc">Technical writer | Life adventurer</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="../../../../index.html" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="../../../../tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="../../../../categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="../../../../archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="../../../../about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="../../../../friends" class="waves-effect waves-light"><i class="fa-fw fas fa-address-book"></i> 友情链接</a></li></ul></div></div></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(../../../medias/featureimages/27.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">协同过滤</h1></div></div></div></div></div><main class="post-container content"><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="../../../../tags/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4/"><span class="chip bg-color">协同过滤</span> </a><a href="../../../../tags/%E8%A1%A8%E6%A0%BC%E5%BB%BA%E6%A8%A1/"><span class="chip bg-color">表格建模</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="../../../../categories/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4/" class="post-category">协同过滤</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2024-06-15</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 5.5k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 20 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><link rel="stylesheet" href="../../../../libs/prism/prism.min.css"><div class="card-content article-card-content"><div id="articleContent"><h1 id="协同过滤"><a href="#协同过滤" class="headerlink" title="协同过滤"></a>协同过滤</h1><p>概率矩阵分解（PMF），另一种时深度学习方法</p><p>为用户推荐产品的一般解决方案：协同过滤，查看当前用户使用过或喜欢过哪些产品，找到使用过或喜欢类似产品的其他用户，然后推荐这些用户使用过或喜欢过的其他产品给当前用户。关键底层思想：潜在特征。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>电影推荐，使用MovieLens，包含千万条电影评分数据。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> fastai<span class="token punctuation">.</span>collab <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> fastai<span class="token punctuation">.</span>tabular<span class="token punctuation">.</span><span class="token builtin">all</span> <span class="token keyword">import</span> <span class="token operator">*</span>
path <span class="token operator">=</span> untar_data<span class="token punctuation">(</span>URLs<span class="token punctuation">.</span>ML_100k<span class="token punctuation">)</span>

ratings <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>path<span class="token operator">/</span><span class="token string">'u.data'</span><span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">'\t'</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">,</span><span class="token string">'movie'</span><span class="token punctuation">,</span><span class="token string">'rating'</span><span class="token punctuation">,</span><span class="token string">'timestamp'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
ratings<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406210902334.png" width="380"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">数据集</div></center><p>然而以交叉表的形式展示更直观</p><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406210903897.png" width="600"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">交叉表</div></center><p>如果我们可以清楚地知道每个用户喜欢每个重要的电影类别（如类型、年龄、最喜爱的导演和演员等）的程度，同时我们也清楚每个电影的这些类别信息，那么一个简单的方法就是将每部电影和每个用户的对应属性的特征值相乘后再求和。例如，如果我们使用-1到+1的数值来表示匹配程度，其中正数表示更强的匹配，负数表示更弱的匹配，并且我们有三个类别（科幻、动作和老电影）如下。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">last_skywalker <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.98</span><span class="token punctuation">,</span><span class="token number">0.9</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
user1 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.9</span><span class="token punctuation">,</span><span class="token number">0.8</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>user1<span class="token operator">*</span>last_skywalker<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 2.1420000000000003</span>
casablanca <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.99</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.3</span><span class="token punctuation">,</span><span class="token number">0.8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>user1<span class="token operator">*</span>casablanca<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># -1.611</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>点积（内积）：将两个向量的各元素分别相乘，然后将其结果进行求和的数学运算。</p></blockquote><h2 id="学习潜在特征"><a href="#学习潜在特征" class="headerlink" title="学习潜在特征"></a>学习潜在特征</h2><p><strong>步骤1</strong>：随机初始化一些参数。这些参数将是每个用户和电影的一组潜在特征。我们需要决定使用多少个潜在特征。为了说明目的，我们现在先使用5个。因为每个用户和每部电影都会有一组这样的特征，我们可以在交叉表中用户和电影旁边显示这些随机初始化的值，然后在中间填入每对组合的点积。</p><p><strong>步骤2</strong>：计算预测。可以通过取每部电影与每个用户的点积来实现这一点。例如，如果第一个潜在用户特征代表用户喜欢动作电影的程度，而第一个潜在电影特征代表电影是否包含大量动作场面，那么如果用户喜欢动作电影且电影确实包含大量动作场面，或者用户不喜欢动作电影且电影没有动作场面，这两个特征的乘积将会特别高。另一方面，如果有不匹配的情况（用户喜欢动作电影但电影不是动作片，或者用户不喜欢动作电影但它是一部动作片），乘积将会非常低。</p><p><strong>步骤3</strong>：计算损失。可以使用任何我们希望的损失函数；选择均方误差，因为这是表示预测准确性的一种合理方式。</p><p>有了这些，我们就可以使用随机梯度下降来优化我们的参数（即潜在特征），以最小化损失。在每一步，随机梯度下降优化器将使用点积计算每部电影和每个用户之间的匹配，并将其与每个用户给出的每部电影的实际评分进行比较。然后它将计算这个值的导数，并通过乘以学习率来调整权重。经过多次这样的操作，损失将会越来越小，推荐也会越来越好。</p><h2 id="创建DataLoaders"><a href="#创建DataLoaders" class="headerlink" title="创建DataLoaders"></a>创建DataLoaders</h2><p>希望展示时看见电影名而不是ID</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">movies <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>path<span class="token operator">/</span><span class="token string">'u.item'</span><span class="token punctuation">,</span>  delimiter<span class="token operator">=</span><span class="token string">'|'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'latin-1'</span><span class="token punctuation">,</span>
                     usecols<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'movie'</span><span class="token punctuation">,</span><span class="token string">'title'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
<span class="token comment"># movies.head()</span>
<span class="token comment"># 合并表格</span>
ratings <span class="token operator">=</span> ratings<span class="token punctuation">.</span>merge<span class="token punctuation">(</span>movies<span class="token punctuation">)</span>
ratings<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406210935524.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">电影评分表</div></center><p>根据此表构建一个DataLoaders对象。默认第一列表示用户，第二列表示项目（电影），第三列表示评级。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dls <span class="token operator">=</span> CollabDataLoaders<span class="token punctuation">.</span>from_df<span class="token punctuation">(</span>ratings<span class="token punctuation">,</span> item_name<span class="token operator">=</span><span class="token string">'title'</span><span class="token punctuation">,</span> bs<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>
dls<span class="token punctuation">.</span>show_batch<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406210941779.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">数据块</div></center><p>在深度学习模型中，我们通常不直接进行索引查找操作，因为这不是模型能够直接处理的。但是，我们可以通过将索引转换为<strong>独热编码（one-hot encoding）</strong>向量，然后使用矩阵乘法来间接实现这一点。</p><p>独热编码是一种将分类变量转换为可以提供给机器学习算法的格式的方法。在独热编码中，每个索引值都被转换为一个全是0的向量，除了代表索引的位置是1。</p><p>例如，如果我们有一个向量 $v=\begin{bmatrix}v_1,v_2,v_3,…,v_n\end{bmatrix}$</p><p>，并且我们想要通过独热编码来选择第三个元素，我们可以创建一个独热编码向量 $e_3=\begin{bmatrix}0,0,1,0,…,0\end{bmatrix}$ 。然后，我们可以通过矩阵乘法来获取 $v$ 的第三个元素：</p><p>$v\times e_3^T=\begin{bmatrix}v_1,v_2,v_3,…,v_n\end{bmatrix}\times\begin{bmatrix}0\0\1\0\\vdots\0\end{bmatrix}=v_3$</p><p>这样我们就可以执行矩阵乘法。结果是一个只包含 $v_3$ 的向量。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">n_users  <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dls<span class="token punctuation">.</span>classes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
n_movies <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dls<span class="token punctuation">.</span>classes<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
n_factors <span class="token operator">=</span> <span class="token number">5</span>

user_factors <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_factors<span class="token punctuation">)</span>
movie_factors <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_movies<span class="token punctuation">,</span> n_factors<span class="token punctuation">)</span>

one_hot_3 <span class="token operator">=</span> one_hot<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> n_users<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
user_factors<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> @ one_hot_3
<span class="token comment"># tensor([-0.4586, -0.9915, -0.4052, -0.3621, -0.5908])</span>
user_factors<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>
<span class="token comment"># tensor([-0.4586, -0.9915, -0.4052, -0.3621, -0.5908])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>嵌入（embedding）</strong>。在深度学习中，嵌入层是一种有效的方式来处理类别数据，特别是当类别数量很大时。</p><p>当我们使用独热编码来表示索引时，我们确实会得到一个由独热编码向量组成的矩阵，这样的操作本质上是一个矩阵乘法。这种方法在理论上是可行的，但它会消耗更多的内存和计算时间。这是因为独热编码向量大部分元素都是0，只有一个位置是1，这导致了大量的存储和计算浪费。</p><p>因此，深度学习库，如PyTorch，提供了一种特殊的层——<strong>嵌入层</strong>。嵌入层允许我们直接使用整数索引来查找数组中的元素，而不需要存储完整的独热编码向量。这样做的好处是显而易见的：</p><ul><li><strong>减少内存使用</strong>：不需要存储大量的独热编码向量。</li><li><strong>提高效率</strong>：直接索引比搜索整个独热编码向量要快得多。</li><li><strong>保持梯度计算的一致性</strong>：尽管使用整数索引，但嵌入层的梯度计算方式与使用独热编码进行矩阵乘法的方式相同。</li></ul><p>当我们用独热编码矩阵乘以嵌入矩阵时，实际上我们在做的是选择嵌入矩阵中对应的行。</p><p>在计算机视觉中，我们通过RGB值来获取像素的所有信息，这是一个直观的过程：每个彩色图像中的像素由三个数字表示，分别对应红色、绿色和蓝色的强度。这三个数值足以让我们的模型后续进行工作。</p><p>然而，对于用户或电影这样的实体，我们没有同样简单的方式来表征它们。可能存在与电影类型相关的关系：如果某个用户喜欢浪漫类型的电影，他们可能会给浪漫电影更高的评分。其他因素可能包括电影是更倾向于动作还是对话重，或者用户可能特别喜欢的某个特定演员的出现。</p><p>我们如何确定用来表征这些特征的数值呢？答案是，我们不需要自己确定。我们将让模型自己学习它们。通过分析用户和电影之间现有的关系，我们的模型可以自行发现哪些特征看起来重要或不重要。</p><p>这就是嵌入（embeddings）的含义。我们将为我们的每个用户和每部电影分配一个随机向量（这里的长度为n_factors=5），并将这些向量作为可学习的参数。这意味着在每一步，当我们通过比较我们的预测和目标来计算损失时，我们将计算损失相对于这些嵌入向量的梯度，并使用随机梯度下降（SGD）或其他优化器的规则来更新它们。</p><p>在训练开始时，这些数字没有任何意义，因为我们是随机选择的，但在训练结束时，它们将具有意义。通过在没有任何其他信息的情况下，学习关于用户和电影之间现有数据的关系，我们将看到它们仍然能够获取一些重要的特征，并能够区分大片和独立电影，动作电影和浪漫电影等等。</p><h2 id="从头开始进行协同过滤"><a href="#从头开始进行协同过滤" class="headerlink" title="从头开始进行协同过滤"></a>从头开始进行协同过滤</h2><p>在PyTorch中创建一个新的模块确实需要从<code>Module</code>类继承。当我们创建一个新的类时，我们可以通过继承来复用和扩展PyTorch的<code>Module</code>类的基础功能。在PyTorch中，<code>Module</code>类是所有神经网络模块的基类，它提供了一些基本的结构和方法，例如参数管理、模型保存和加载、设备转移（CPU/GPU）、钩子函数等。当我们定义自己的模块时，我们通过继承<code>Module</code>类来获得这些功能。</p><p>此外，当我们的模块被调用时，PyTorch会自动调用一个名为<code>forward</code>的方法。这个<code>forward</code>方法定义了模块的前向传播逻辑，即当我们对模块进行调用（例如<code>model(x)</code>）时，实际上是在调用<code>model.forward(x)</code>。在<code>forward</code>方法中，我们定义了输入数据如何通过模型流动并返回输出。</p><p>下面是一个定义点积模型的类的示例，它展示了如何从<code>Module</code>继承并实现<code>forward</code>方法：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DotProduct</span><span class="token punctuation">(</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_movies<span class="token punctuation">,</span> n_factors<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>user_factors <span class="token operator">=</span> Embedding<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_factors<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>movie_factors <span class="token operator">=</span> Embedding<span class="token punctuation">(</span>n_movies<span class="token punctuation">,</span> n_factors<span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        users <span class="token operator">=</span> self<span class="token punctuation">.</span>user_factors<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        movies <span class="token operator">=</span> self<span class="token punctuation">.</span>movie_factors<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>users <span class="token operator">*</span> movies<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于模型的输入，我们通常使用一个形状为<code>batch_size x 2</code>的张量，其中：</p><ul><li>第一列（<code>x[:, 0]</code>）包含用户ID。</li><li>第二列（<code>x[:, 1]</code>）包含电影ID。</li></ul><p>这里的<code>x</code>是一个批次的输入数据，<code>batch_size</code>是批次中的样本数量。每一行代表一个用户-电影对，模型将为这些对生成预测评分。</p><p>嵌入层（embedding layers）用于表示用户和电影的潜在特征矩阵。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">,</span>y <span class="token operator">=</span> dls<span class="token punctuation">.</span>one_batch<span class="token punctuation">(</span><span class="token punctuation">)</span>
x<span class="token punctuation">.</span>shape
<span class="token comment"># torch.Size([64, 2])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>这里不使用已经定义好的Learner，而是从头开始定义。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> DotProduct<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_movies<span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span>
learn <span class="token operator">=</span> Learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token operator">=</span>MSELossFlat<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5e-3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406211020777.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">拟合一下</div></center><p>为了让模型更好，将预测值设置在0到5之间。根据经验最好让范围超过5一点点，设为(0,5.5)区间。</p><blockquote><p>在构建模型时，确保预测值位于合理范围内（例如，0到5分的评分系统）是很重要的。使用<code>sigmoid_range</code>函数可以帮助我们将模型的输出限制在这个范围内。<code>sigmoid_range</code>函数通过应用Sigmoid函数来压缩输出，然后将其缩放到指定的范围。</p><p>将范围设置得稍微超过5（例如，使用(0, 5.5)）的原因是基于经验的发现。这样做有几个潜在的好处：</p><ol><li><strong>避免边界值问题</strong>：如果模型预测的值非常接近范围的上限或下限，使用稍微扩展的范围可以减少预测值被截断的情况。这意味着模型有更多的空间来表示那些接近极端评分的情况。</li><li><strong>提高学习效率</strong>：在训练过程中，如果预测值被限制在一个非常严格的范围内，模型可能会在训练早期就遇到梯度消失的问题，因为Sigmoid函数的梯度在其输入值非常大或非常小的时候会变得非常小。扩展范围可以在一定程度上缓解这个问题。</li><li><strong>更好的梯度流动</strong>：在优化过程中，扩展的范围可以提供更稳定的梯度，因为它避免了Sigmoid函数在极值附近的平坦区域，这有助于模型更有效地学习。</li><li><strong>灵活性和鲁棒性</strong>：在实际应用中，评分可能会受到多种因素的影响，包括噪声和偏差。允许模型预测略微超出实际评分范围的值可以提供额外的灵活性，使模型能够更好地适应这些因素。</li></ol><p>总的来说，将输出范围设置为略微超过实际评分的最大值，可以帮助模型在训练和预测时更加稳定和准确。这是一种基于实践的调整，旨在提高模型的整体性能。</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DotProduct</span><span class="token punctuation">(</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_movies<span class="token punctuation">,</span> n_factors<span class="token punctuation">,</span> y_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">5.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>user_factors <span class="token operator">=</span> Embedding<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_factors<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>movie_factors <span class="token operator">=</span> Embedding<span class="token punctuation">(</span>n_movies<span class="token punctuation">,</span> n_factors<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>y_range <span class="token operator">=</span> y_range
       
	<span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        users <span class="token operator">=</span> self<span class="token punctuation">.</span>user_factors<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        movies <span class="token operator">=</span> self<span class="token punctuation">.</span>movie_factors<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> sigmoid_range<span class="token punctuation">(</span><span class="token punctuation">(</span>users <span class="token operator">*</span> movies<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">*</span>self<span class="token punctuation">.</span>y_range<span class="token punctuation">)</span>
    
model <span class="token operator">=</span> DotProduct<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_movies<span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span>
learn <span class="token operator">=</span> Learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token operator">=</span>MSELossFlat<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5e-3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406211029556.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">重新拟合一下</div></center><p>😧</p><p>在目前的点积模型中，我们只考虑了用户和电影的潜在特征，这些特征通过点积来预测评分。然而，这种方法没有考虑到一些用户可能天生就更倾向于给出正面或负面的评价，或者某些电影可能普遍被认为是好或坏。</p><p>为了解决这个问题，我们可以为每个用户和每部电影添加一个偏置项。这样，我们的模型就不仅仅是学习用户和电影之间的相互作用，还能学习到它们各自的特性。具体来说：</p><ul><li><strong>用户偏置（User Bias）</strong>：每个用户都有一个偏置值，它代表了该用户评分的整体倾向性。例如，一些用户可能普遍给出较高的评分，而另一些用户可能普遍给出较低的评分。</li><li><strong>电影偏置（Movie Bias）</strong>：每部电影也有一个偏置值，它代表了电影的普遍受欢迎程度。例如，一些电影可能普遍受到好评，而另一些电影则可能不那么受欢迎。</li></ul><p>在模型中引入偏置项后，预测评分的计算将变为用户和电影潜在特征的点积加上相应的用户偏置和电影偏置。数学上，这可以表示为：</p><p>预测评分=(用户特征⋅电影特征)+用户偏置+电影偏置</p><p>这样，模型就能更准确地反映出用户和电影的个性化特征，从而提高推荐系统的准确性和个性化程度。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DotProductBias</span><span class="token punctuation">(</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_movies<span class="token punctuation">,</span> n_factors<span class="token punctuation">,</span> y_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">5.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>user_factors <span class="token operator">=</span> Embedding<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_factors<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>user_bias <span class="token operator">=</span> Embedding<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>movie_factors <span class="token operator">=</span> Embedding<span class="token punctuation">(</span>n_movies<span class="token punctuation">,</span> n_factors<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>movie_bias <span class="token operator">=</span> Embedding<span class="token punctuation">(</span>n_movies<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>y_range <span class="token operator">=</span> y_range
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        users <span class="token operator">=</span> self<span class="token punctuation">.</span>user_factors<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        movies <span class="token operator">=</span> self<span class="token punctuation">.</span>movie_factors<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        res <span class="token operator">=</span> <span class="token punctuation">(</span>users <span class="token operator">*</span> movies<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        res <span class="token operator">+=</span> self<span class="token punctuation">.</span>user_bias<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>movie_bias<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> sigmoid_range<span class="token punctuation">(</span>res<span class="token punctuation">,</span> <span class="token operator">*</span>self<span class="token punctuation">.</span>y_range<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406211033012.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">重新拟合一下</div></center><p>坏事了！</p><p>可以看到两次训练，验证集上的损失在中途停止改善。仿佛过拟合了。</p><p>对此，使用正则化技术——权重衰减（weight decay）。数据增强不适合。</p><h3 id="权重衰减"><a href="#权重衰减" class="headerlink" title="权重衰减"></a>权重衰减</h3><p>权重衰减（Weight Decay），也称为<code>L2正则化</code>，是在损失函数中加入所有权重的平方和。为什么要这样做呢？因为当我们计算梯度时，它会增加一个促使权重尽可能小的贡献。</p><p>为什么它能防止过拟合呢？这个想法是，系数越大，损失函数中的峡谷就会越尖锐。如果我们以抛物线为基本例子，$y=a⋅x^2$ ，a越大，抛物线就越窄。</p><blockquote><p>在数学上，L2正则化可以表示为在损失函数 $L$ 中加入一个正则项 $\lambda\sum_iw_i^2$ ，其中 $\text{λ}$ 是正则化参数， $w_{i}$ 是模型权重。整个损失函数变为：</p><p>$L_{\mathrm{total}}=L_{\mathrm{original}}+\lambda\sum_iw_i^2$</p><p>这个正则项会惩罚大的权重值，因为当权重值增大时，正则项也会增大，从而增加总损失。在训练过程中，模型会尝试最小化这个总损失，这自然会导致权重值尽量小。</p><p>权重衰减有助于防止过拟合，因为它限制了模型的复杂度。较小的权重值意味着模型的预测将不会对输入数据中的小波动过于敏感，这有助于提高模型在未见数据上的泛化能力。</p></blockquote><p>因此，让模型学习高参数据可能导致过拟合，模型用一个变化非常剧烈且过于复杂的函数来你和训练集中的所有数据点，最终导致过拟合。</p><p>过多限制权重增长，将会减慢模型的训练速度，当会形成一种泛化更好的状态。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss_with_wd <span class="token operator">=</span> loss <span class="token operator">+</span> wd <span class="token operator">*</span> <span class="token punctuation">(</span>parameters<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 为损失函数添加平方和，假设parameters是所有参数的张量</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>权重衰减是我们选择的一个参数。通常，我们会将其设置为一个较大的值，这样我们甚至不需要在方程中包含乘以2的部分。在fastai库中使用权重衰减非常简单，您只需要在调用<code>fit</code>或<code>fit_one_cycle</code>函数时传递<code>wd</code>参数即可。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> DotProductBias<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_movies<span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span>
learn <span class="token operator">=</span> Learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token operator">=</span>MSELossFlat<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5e-3</span><span class="token punctuation">,</span> wd<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406211054225.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">重新训练</div></center><p>舒服了😀</p><h3 id="创建自己的嵌入模块"><a href="#创建自己的嵌入模块" class="headerlink" title="创建自己的嵌入模块"></a>创建自己的嵌入模块</h3><p>尽管上面用到了<code>Embedding</code>，但是没有考虑实际工作原理，下面构造自己的<code>DotProductBias</code>这个类。</p><p>在PyTorch中，如果我们只是将一个张量作为属性添加到<code>Module</code>中，它不会自动包含在模型的参数中。为了让<code>Module</code>知道我们想将一个张量视为参数，我们需要将它包装在<code>nn.Parameter</code>类中。这个类实际上并没有添加任何功能（除了自动为我们调用<code>requires_grad_</code>），它仅仅用作一个“标记”，以显示哪些张量应该包含在参数中。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">T</span><span class="token punctuation">(</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>a <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

L<span class="token punctuation">(</span>T<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>当我们调用<code>T().parameters()</code>时，它会返回一个包含所有参数的列表。在这个例子中，一个包含三个元素的张量，并且每个元素都设置为1，并且具有梯度。</p><p>所有的PyTorch模块都使用<code>nn.Parameter</code>来定义可训练的参数，这就是为什么到目前为止我们没有需要显式使用这个包装器的原因。当我们定义自己的模型时，我们可以通过这种方式来创建可训练的参数。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 创建一个张量作为参数，并随机初始化</span>
<span class="token keyword">def</span> <span class="token function">create_params</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token operator">*</span>size<span class="token punctuation">)</span><span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>用张量创建DotProductBias类，而不使用Embedding：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DotProductBias</span><span class="token punctuation">(</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_movies<span class="token punctuation">,</span> n_factors<span class="token punctuation">,</span> y_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">5.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>user_factors <span class="token operator">=</span> create_params<span class="token punctuation">(</span><span class="token punctuation">[</span>n_users<span class="token punctuation">,</span> n_factors<span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>user_bias <span class="token operator">=</span> create_params<span class="token punctuation">(</span><span class="token punctuation">[</span>n_users<span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>movie_factors <span class="token operator">=</span> create_params<span class="token punctuation">(</span><span class="token punctuation">[</span>n_movies<span class="token punctuation">,</span> n_factors<span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>movie_bias <span class="token operator">=</span> create_params<span class="token punctuation">(</span><span class="token punctuation">[</span>n_movies<span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>y_range <span class="token operator">=</span> y_range
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        users <span class="token operator">=</span> self<span class="token punctuation">.</span>user_factors<span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
        movies <span class="token operator">=</span> self<span class="token punctuation">.</span>movie_factors<span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
        res <span class="token operator">=</span> <span class="token punctuation">(</span>users<span class="token operator">*</span>movies<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        res <span class="token operator">+=</span> self<span class="token punctuation">.</span>user_bias<span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>movie_bias<span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> sigmoid_range<span class="token punctuation">(</span>res<span class="token punctuation">,</span> <span class="token operator">*</span>self<span class="token punctuation">.</span>y_range<span class="token punctuation">)</span>
    
model <span class="token operator">=</span> DotProductBias<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_movies<span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span>
learn <span class="token operator">=</span> Learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token operator">=</span>MSELossFlat<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5e-3</span><span class="token punctuation">,</span> wd<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406211109151.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">重新训练一下</div></center><h2 id="嵌入和偏差"><a href="#嵌入和偏差" class="headerlink" title="嵌入和偏差"></a>嵌入和偏差</h2><p>直接解释嵌入矩阵并不容易，因为有太多的因素需要考虑。但有一种技术可以提取出这样一个矩阵中最重要的基本方向，称为主成分分析（PCA）。</p><blockquote><p>计算线性代数</p><p><a target="_blank" rel="noopener" href="https://github.com/fastai/numerical-linear-algebra">https://github.com/fastai/numerical-linear-algebra</a></p></blockquote><h3 id="使用fastai-collab"><a href="#使用fastai-collab" class="headerlink" title="使用fastai.collab"></a>使用fastai.collab</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 协同过滤模型</span>
learn <span class="token operator">=</span> collab_learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> n_factors<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> y_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5e-3</span><span class="token punctuation">,</span> wd<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202406211117401.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">fastai的模型训练</div></center><p>查看模型的所有层</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn<span class="token punctuation">.</span>model
<span class="token comment">#EmbeddingDotBias(</span>
<span class="token comment">#  (u_weight): Embedding(944, 50)</span>
<span class="token comment">#  (i_weight): Embedding(1665, 50)</span>
<span class="token comment">#  (u_bias): Embedding(944, 1)</span>
<span class="token comment">#  (i_bias): Embedding(1665, 1)</span>
<span class="token comment">#)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="嵌入距离"><a href="#嵌入距离" class="headerlink" title="嵌入距离"></a>嵌入距离</h3><p>在多维空间中，这种距离被称为欧几里得距离。通过计算电影嵌入向量之间的欧几里得距离，我们可以量化电影之间的相似性。如果两部电影的嵌入向量之间的距离很小，这表明它们在用户偏好的多维空间中是相似的。这种方法可以帮助我们发现与特定电影相似的其他电影，从而为用户提供个性化的推荐。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">movie_factors <span class="token operator">=</span> learn<span class="token punctuation">.</span>model<span class="token punctuation">.</span>i_weight<span class="token punctuation">.</span>weight
idx <span class="token operator">=</span> dls<span class="token punctuation">.</span>classes<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>o2i<span class="token punctuation">[</span><span class="token string">'Silence of the Lambs, The (1991)'</span><span class="token punctuation">]</span>
distances <span class="token operator">=</span> nn<span class="token punctuation">.</span>CosineSimilarity<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>movie_factors<span class="token punctuation">,</span> movie_factors<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
idx <span class="token operator">=</span> distances<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>descending<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
dls<span class="token punctuation">.</span>classes<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="为用户做推荐"><a href="#为用户做推荐" class="headerlink" title="为用户做推荐"></a>为用户做推荐</h2><h3 id="自助取样启动问题"><a href="#自助取样启动问题" class="headerlink" title="自助取样启动问题"></a>自助取样启动问题</h3><p>最极端的情况是没有用户，即不能从历史信息中学习，那向第一个用户推荐什么产品？</p><p>用户注册时，问一些喜好之类的问题。</p><h2 id="深度学习方法用于协同过滤"><a href="#深度学习方法用于协同过滤" class="headerlink" title="深度学习方法用于协同过滤"></a>深度学习方法用于协同过滤</h2><p>在将架构转换为深度学习模型时，首先要做的是取嵌入查找的结果，并将这些激活值拼接在一起。这样我们就得到了一个矩阵，然后可以像通常那样通过线性层和非线性函数进行处理。</p><p>由于我们将要拼接嵌入，而不是取它们的点积，两个嵌入矩阵可以有不同的大小（即不同数量的潜在因子）。fastai 提供了一个名为 <code>get_emb_sz</code> 的函数，该函数根据 fast.ai 发现在实践中往往效果不错的启发式规则，返回数据的嵌入矩阵推荐大小：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">embs <span class="token operator">=</span> get_emb_sz<span class="token punctuation">(</span>dls<span class="token punctuation">)</span>
embs
<span class="token comment"># [(944, 74), (1665, 102)]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>实现该类：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">CollabNN</span><span class="token punctuation">(</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> user_sz<span class="token punctuation">,</span> item_sz<span class="token punctuation">,</span> y_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">5.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n_act<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>user_factors <span class="token operator">=</span> Embedding<span class="token punctuation">(</span><span class="token operator">*</span>user_sz<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>item_factors <span class="token operator">=</span> Embedding<span class="token punctuation">(</span><span class="token operator">*</span>item_sz<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>user_sz<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">+</span>item_sz<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> n_act<span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_act<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>y_range <span class="token operator">=</span> y_range
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        embs <span class="token operator">=</span> self<span class="token punctuation">.</span>user_factors<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>item_factors<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>embs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> sigmoid_range<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token operator">*</span>self<span class="token punctuation">.</span>y_range<span class="token punctuation">)</span>

<span class="token comment"># 创建模型    </span>
model <span class="token operator">=</span> CollabNN<span class="token punctuation">(</span><span class="token operator">*</span>embs<span class="token punctuation">)</span>

learn <span class="token operator">=</span> Learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token operator">=</span>MSELossFlat<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5e-3</span><span class="token punctuation">,</span> wd<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token comment"># 使用use_nn，创建了2个隐藏层，大小分别是100，50</span>
learn <span class="token operator">=</span> collab_learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> use_nn<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> y_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> layers<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5e-3</span><span class="token punctuation">,</span> wd<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css"></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="../../../../about" rel="external nofollow noreferrer">nusqx</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://nusqx.top">https://nusqx.top</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="../../../../about" target="_blank">nusqx</a> !</span></div></div><script async defer>document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="../../../../tags/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4/"><span class="chip bg-color">协同过滤</span> </a><a href="../../../../tags/%E8%A1%A8%E6%A0%BC%E5%BB%BA%E6%A8%A1/"><span class="chip bg-color">表格建模</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="../../../../libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="../../../../libs/share/js/social-share.min.js"></script></div></div></div><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close"><i class="fas fa-times"></i></a><h4 class="reward-title">你的赏识是我前进的动力</h4><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><script>$(function(){$(".tabs").tabs()})</script></div></div><style>.valine-card{margin:1.5rem auto}.valine-card .card-content{padding:20px 20px 5px 20px}#vcomments textarea{box-sizing:border-box;background:url(../../../medias/comment_bg.png) 100% 100% no-repeat}#vcomments p{margin:2px 2px 10px;font-size:1.05rem;line-height:1.78rem}#vcomments blockquote p{text-indent:.2rem}#vcomments a{padding:0 2px;color:#4cbf30;font-weight:500;text-decoration:none}#vcomments img{max-width:100%;height:auto;cursor:pointer}#vcomments ol li{list-style-type:decimal}#vcomments ol,ul{display:block;padding-left:2em;word-spacing:.05rem}#vcomments ul li,ol li{display:list-item;line-height:1.8rem;font-size:1rem}#vcomments ul li{list-style-type:disc}#vcomments ul ul li{list-style-type:circle}#vcomments table,td,th{padding:12px 13px;border:1px solid #dfe2e5}#vcomments table,td,th{border:0}table tr:nth-child(2n),thead{background-color:#fafafa}#vcomments table th{background-color:#f2f2f2;min-width:80px}#vcomments table td{min-width:80px}#vcomments h1{font-size:1.85rem;font-weight:700;line-height:2.2rem}#vcomments h2{font-size:1.65rem;font-weight:700;line-height:1.9rem}#vcomments h3{font-size:1.45rem;font-weight:700;line-height:1.7rem}#vcomments h4{font-size:1.25rem;font-weight:700;line-height:1.5rem}#vcomments h5{font-size:1.1rem;font-weight:700;line-height:1.4rem}#vcomments h6{font-size:1rem;line-height:1.3rem}#vcomments p{font-size:1rem;line-height:1.5rem}#vcomments hr{margin:12px 0;border:0;border-top:1px solid #ccc}#vcomments blockquote{margin:15px 0;border-left:5px solid #42b983;padding:1rem .8rem .3rem .8rem;color:#666;background-color:rgba(66,185,131,.1)}#vcomments pre{font-family:monospace,monospace;padding:1.2em;margin:.5em 0;background:#272822;overflow:auto;border-radius:.3em;tab-size:4}#vcomments code{font-family:monospace,monospace;padding:1px 3px;font-size:.92rem;color:#e96900;background-color:#f8f8f8;border-radius:2px}#vcomments pre code{font-family:monospace,monospace;padding:0;color:#e8eaf6;background-color:#272822}#vcomments pre[class*=language-]{padding:1.2em;margin:.5em 0}#vcomments code[class*=language-],pre[class*=language-]{color:#e8eaf6}#vcomments [type=checkbox]:not(:checked),[type=checkbox]:checked{position:inherit;margin-left:-1.3rem;margin-right:.4rem;margin-top:-1px;vertical-align:middle;left:unset;visibility:visible}#vcomments b,strong{font-weight:700}#vcomments dfn{font-style:italic}#vcomments small{font-size:85%}#vcomments cite{font-style:normal}#vcomments mark{background-color:#fcf8e3;padding:.2em}#vcomments table,td,th{padding:12px 13px;border:1px solid #dfe2e5}table tr:nth-child(2n),thead{background-color:#fafafa}#vcomments table th{background-color:#f2f2f2;min-width:80px}#vcomments table td{min-width:80px}#vcomments [type=checkbox]:not(:checked),[type=checkbox]:checked{position:inherit;margin-left:-1.3rem;margin-right:.4rem;margin-top:-1px;vertical-align:middle;left:unset;visibility:visible}</style><div class="card valine-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="vcomments" class="card-content" style="display:grid"></div></div><script src="../../../../libs/valine/av-min.js"></script><script src="../../../../libs/valine/Valine.min.js"></script><script>new Valine({el:"#vcomments",appId:"GOX0XlpzLZat5ANucw5j9zjl-gzGzoHsz",appKey:"fha9hT9W6BxJDz7eBYQEPBvc",serverURLs:"",notify:!0,verify:!0,visitor:!1,avatar:"wavatar",pageSize:"10",lang:"zh-cn",placeholder:"What do you say?"})</script><div id="to_comment" class="comment-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#vcomments" title="直达评论"><i class="fas fa-comments"></i></a></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="../../../07/03/qian-duan-kai-fa-vue3/"><div class="card-image"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/featureimages/24.jpg" class="responsive-img" alt="前端开发-Vue3"> <span class="card-title">前端开发-Vue3</span></div></a><div class="card-content article-content"><div class="summary block-with-text">前端开发</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-07-03 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="../../../../categories/%E5%89%8D%E7%AB%AF/" class="post-category">前端</a></span></div></div><div class="card-action article-tags"><a href="../../../../tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/"><span class="chip bg-color">前端开发</span> </a><a href="../../../../tags/Vue3/"><span class="chip bg-color">Vue3</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="../../10/trainsoatmodel/"><div class="card-image"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/featureimages/18.jpg" class="responsive-img" alt="高阶训练技术"> <span class="card-title">高阶训练技术</span></div></a><div class="card-content article-content"><div class="summary block-with-text">高阶训练技术</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-06-10 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="../../../../categories/%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" class="post-category">训练模型</a></span></div></div><div class="card-action article-tags"><a href="../../../../tags/%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/"><span class="chip bg-color">训练技术</span> </a><a href="../../../../tags/%E6%A8%A1%E5%9E%8B/"><span class="chip bg-color">模型</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0!==window.getSelection&&((""+(n=window.getSelection())).length<Number.parseInt("240")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"!==n.getRangeAt(0).commonAncestorContainer.nodeName&&"CODE"!==n.getRangeAt(0).commonAncestorContainer.nodeName||(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: SQX BLOG<br />文章作者: NUS QX<br />文章链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200)))})</script><script type="text/javascript" src="../../../../libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="../../../../libs/prism/prism.min.js"></script><script type="text/javascript" src="../../../../libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="../../../../libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="../../../../libs/codeBlock/codeShrink.js"></script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget card" style="background-color:#fff"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="../../../../libs/tocbot/tocbot.min.js"></script><script>$(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });</script></main><script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]]}})</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:15px!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2018-2024</span> <a href="../../../../about" target="_blank">NUS QX</a><br><span id="sitetime"></span><span class="my-face"></span><br>&nbsp;|&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">114.1k</span> <span id="busuanzi_container_site_pv" style="display:none"></span> &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span> <span id="busuanzi_container_site_uv" style="display:none"></span> 次&nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;访客人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span> 人 <span id="busuanzi_value_site_uv" class="white-color"></span></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/nusqx" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:1976490928@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fa-solid fa-envelope"></i> </a><a href="https://gitee.com/nusqx" class="tooltipped" target="_blank" data-tooltip="访问我的Gitee: https://gitee.com/nusqx" data-position="top" data-delay="50"><i class="fa-brands fa-square-git"></i> </a><a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1976490928" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1976490928" data-position="top" data-delay="50"><i class="fab fa-qq"></i></a></div></div></footer><div class="progress-bar"></div><script language="javascript">function siteTime(){window.setTimeout("siteTime()",1e3);var e=36e5,t=24*e,o=new Date,i=o.getFullYear(),a=o.getMonth()+1,n=o.getDate(),r=o.getHours(),l=o.getMinutes(),s=o.getSeconds(),M=Date.UTC(2018,9,24,0,0,0),g=Date.UTC(i,a,n,r,l,s)-M,m=Math.floor(g/31536e6),T=Math.floor(g/t-365*m),f=Math.floor((g-(365*m+T)*t)/e),h=Math.floor((g-(365*m+T)*t-f*e)/6e4),u=Math.floor((g-(365*m+T)*t-f*e-6e4*h)/1e3);document.getElementById("sitetime").innerHTML="本站已运行 "+m+" 年 "+T+" 天 "+f+" 小时 "+h+" 分钟 "+u+" 秒"}siteTime()</script><script>$(document).ready(function(){var e=setInterval(function(){"none"!=document.getElementById("busuanzi_container_site_pv").style.display&&($("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html())+n),clearInterval(e));"none"!=$("#busuanzi_container_site_pv").css("display")&&($("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html())+t),clearInterval(e))},50),n=8e4,t=2e4})</script><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script type="text/javascript">$(function(){!function(t,s,i){"use strict";$.ajax({url:t,dataType:"xml",success:function(t){var e=$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),n=document.getElementById(s),r=document.getElementById(i);n.addEventListener("input",function(){var f='<ul class="search-result-list">',m=this.value.trim().toLowerCase().split(/[\s\-]+/);r.innerHTML="",this.value.trim().length<=0||(e.forEach(function(t){var n,e,r,s,i,l=!0,a=t.title.trim().toLowerCase(),c=t.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),u=0===(u=t.url).indexOf("/")?t.url:"/"+u,o=-1,h=-1;""!==a&&""!==c&&m.forEach(function(t,e){n=a.indexOf(t),o=c.indexOf(t),n<0&&o<0?l=!1:(o<0&&(o=0),0===e&&(h=o))}),l&&(f+="<li><a href='"+u+"' class='search-result-title'>"+a+"</a>",e=t.content.trim().replace(/<[^>]+>/g,""),0<=h&&(s=h+80,(r=h-20)<0&&(r=0),0===r&&(s=100),s>e.length&&(s=e.length),i=e.substr(r,s),m.forEach(function(t){var e=new RegExp(t,"gi");i=i.replace(e,'<em class="search-keyword">'+t+"</em>")}),f+='<p class="search-result">'+i+"...</p>"),f+="</li>")}),f+="</ul>",r.innerHTML=f)})}})}("../../../../search.xml","searchInput","searchResult")})</script><div class="stars-con"><div id="stars"></div><div id="stars2"></div><div id="stars3"></div></div><script>function switchNightMode(){$('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($("body")),setTimeout(function(){$("body").hasClass("DarkMode")?($("body").removeClass("DarkMode"),localStorage.setItem("isDark","0"),$("#sum-moon-icon").removeClass("fa-sun").addClass("fa-moon")):($("body").addClass("DarkMode"),localStorage.setItem("isDark","1"),$("#sum-moon-icon").addClass("fa-sun").removeClass("fa-moon")),setTimeout(function(){$(".Cuteen_DarkSky").fadeOut(1e3,function(){$(this).remove()})},2e3)})}</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="../../../../libs/materialize/materialize.min.js"></script><script src="../../../../libs/masonry/masonry.pkgd.min.js"></script><script src="../../../../libs/aos/aos.js"></script><script src="../../../../libs/scrollprogress/scrollProgress.min.js"></script><script src="../../../../libs/lightGallery/js/lightgallery-all.min.js"></script><script src="../../../../js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="../../../../libs/others/clicklove.js" async></script><script async src="../../../../libs/others/busuanzi.pure.mini.js"></script><script type="text/javascript" src="../../../../libs/background/ribbon-dynamic.js" async></script><script src="../../../../libs/instantpage/instantpage.js" type="module"></script>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a,i=c[o];e=function(){c=c.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(n=new Image,a=t.getAttribute("data-original"),n.onload=function(){t.src=a,t.removeAttribute("data-original"),e&&e()},t.src!==a&&(n.src=a))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this);</script><script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>