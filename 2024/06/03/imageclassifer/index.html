<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="图像分类器,迁移学习"><meta name="description" content="预处理、交叉熵损失、微调"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="baidu-site-verification" content="codeva-fVFbpHJJO8"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="referrer" content="no-referrer"><title>图像分类器 | SQX BLOG</title><link rel="icon" type="image/png" href="../../../../favicon.png"><link rel="stylesheet" type="text/css" href="../../../../libs/awesome/css/all.min.css"><link rel="stylesheet" type="text/css" href="../../../../libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="../../../../libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="../../../../libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="../../../../libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="../../../../css/matery.css"><link rel="stylesheet" type="text/css" href="../../../../css/my.css"><link rel="stylesheet" type="text/css" href="../../../../css/dark.css" media="none" onload='"all"!=media&&(media="all")'><link rel="stylesheet" href="../../../../libs/tocbot/tocbot.css"><link rel="stylesheet" href="../../../../css/post.css"><link rel="stylesheet" type="text/css" href="../../../../css/reward.css"><script src="../../../../libs/jquery/jquery-3.6.0.min.js"></script><meta name="generator" content="Hexo 6.3.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="../../../../index.html" class="waves-effect waves-light"><div><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">SQX BLOG</span></div></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="../../../../index.html" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../friends" class="waves-effect waves-light"><i class="fas fa-address-book" style="zoom:.6"></i> <span>友情链接</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li><li><a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式"><i id="sum-moon-icon" class="fas fa-sun" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">SQX BLOG</div><div class="logo-desc">Technical writer | Life adventurer</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="../../../../index.html" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="../../../../tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="../../../../categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="../../../../archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="../../../../about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="../../../../friends" class="waves-effect waves-light"><i class="fa-fw fas fa-address-book"></i> 友情链接</a></li></ul></div></div></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(../../../medias/featureimages/21.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">图像分类器</h1></div></div></div></div></div><main class="post-container content"><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="../../../../tags/fastai/"><span class="chip bg-color">fastai</span> </a><a href="../../../../tags/cv/"><span class="chip bg-color">cv</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2024-06-03</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 6.6k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 26 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><link rel="stylesheet" href="../../../../libs/prism/prism.min.css"><div class="card-content article-card-content"><div id="articleContent"><h1 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h1><p>让模型效果更好</p><p>将模型应用到更广泛的数据类型</p><h2 id="从猫狗识别到宠物分类"><a href="#从猫狗识别到宠物分类" class="headerlink" title="从猫狗识别到宠物分类"></a>从猫狗识别到宠物分类</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> fastai<span class="token punctuation">.</span>vision<span class="token punctuation">.</span><span class="token builtin">all</span> <span class="token keyword">import</span> <span class="token operator">*</span>
path <span class="token operator">=</span> untar_data<span class="token punctuation">(</span>URLs<span class="token punctuation">.</span>PETS<span class="token punctuation">)</span> <span class="token comment"># 使用PETS数据集</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>提供数据的常见方式：</p><ul><li>每一个文件就代表一个数据</li><li>与数据相关的表格中，每一行都代表一个数据</li></ul><p>数据集中有哪些内容：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">Path<span class="token punctuation">.</span>BASE_PATH <span class="token operator">=</span> path
path<span class="token punctuation">.</span>ls<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># (#2) [Path('annotations'),Path('images')]两个目录</span>
<span class="token punctuation">(</span>path<span class="token operator">/</span><span class="token string">"images"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>ls<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># (#7393 [Path('images/Abyssinian_1.jpg'),Path('images/Abyssinian_10.jpg'),Path('images/Abyssinian_100.jpg'),Path('images/Abyssinian_100.mat'),Path('images/Abyssinian_101.jpg'),Path('images/Abyssinian_101.mat'),Path('images/Abyssinian_102.jpg'),Path('images/Abyssinian_102.mat'),Path('images/Abyssinian_103.jpg'),Path('images/Abyssinian_104.jpg')...]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>#为前缀，集合中数据的项数，要提取文件名中宠物类别，不能单纯的以第一个下划线区分，因为有的名字较复杂。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">fname <span class="token operator">=</span> <span class="token punctuation">(</span>path<span class="token operator">/</span><span class="token string">"images"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>ls<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>使用<code>正则表达式（regex）</code>，它指定了一个通用规则，用于确定另一个字符串是否能通过测试（即“匹配”正则表达式），也可以用于从另一个字符串中提取一个或多个特定部分。</p><p>此时，需要一个正则表达式从文件名中提取宠物品种。<code>findall</code>函数。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span><span class="token string">r'(.+)_\d+.jpg$'</span><span class="token punctuation">,</span> fname<span class="token punctuation">.</span>name<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>fastai中如果用正则表达式标注数据，可以使用<code>RegexLabeller</code>类达到这一目的。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">pets <span class="token operator">=</span> DataBlock<span class="token punctuation">(</span>blocks <span class="token operator">=</span> <span class="token punctuation">(</span>ImageBlock<span class="token punctuation">,</span> CategoryBlock<span class="token punctuation">)</span><span class="token punctuation">,</span>
                 get_items<span class="token operator">=</span>get_image_files<span class="token punctuation">,</span> 
                 splitter<span class="token operator">=</span>RandomSplitter<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                 get_y<span class="token operator">=</span>using_attr<span class="token punctuation">(</span>RegexLabeller<span class="token punctuation">(</span><span class="token string">r'(.+)_\d+.jpg$'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'name'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                 item_tfms<span class="token operator">=</span>Resize<span class="token punctuation">(</span><span class="token number">460</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                 batch_tfms<span class="token operator">=</span>aug_transforms<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span> min_scale<span class="token operator">=</span><span class="token number">0.75</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 尺寸预处理的数据增强策略，最大限度地减少数据被损坏的情况，同时保持良好的性能</span>
dls <span class="token operator">=</span> pets<span class="token punctuation">.</span>dataloaders<span class="token punctuation">(</span>path<span class="token operator">/</span><span class="token string">"images"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="图像尺寸的预处理"><a href="#图像尺寸的预处理" class="headerlink" title="图像尺寸的预处理"></a>图像尺寸的预处理</h2><p>数据清洗，数据增强等。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#id interpolations</span>
<span class="token comment">#caption A comparison of fastai's data augmentation strategy (left) and the traditional approach (right).</span>
dblock1 <span class="token operator">=</span> DataBlock<span class="token punctuation">(</span>blocks<span class="token operator">=</span><span class="token punctuation">(</span>ImageBlock<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> CategoryBlock<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                   get_y<span class="token operator">=</span>parent_label<span class="token punctuation">,</span>
                   item_tfms<span class="token operator">=</span>Resize<span class="token punctuation">(</span><span class="token number">460</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># Place an image in the 'images/grizzly.jpg' subfolder where this notebook is located before running this</span>
dls1 <span class="token operator">=</span> dblock1<span class="token punctuation">.</span>dataloaders<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>Path<span class="token punctuation">.</span>cwd<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token string">'images'</span><span class="token operator">/</span><span class="token string">'grizzly.jpg'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">,</span> bs<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>
dls1<span class="token punctuation">.</span>train<span class="token punctuation">.</span>get_idxs <span class="token operator">=</span> <span class="token keyword">lambda</span><span class="token punctuation">:</span> Inf<span class="token punctuation">.</span>ones
x<span class="token punctuation">,</span>y <span class="token operator">=</span> dls1<span class="token punctuation">.</span>valid<span class="token punctuation">.</span>one_batch<span class="token punctuation">(</span><span class="token punctuation">)</span>
_<span class="token punctuation">,</span>axs <span class="token operator">=</span> subplots<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

x1 <span class="token operator">=</span> TensorImage<span class="token punctuation">(</span>x<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
x1 <span class="token operator">=</span> x1<span class="token punctuation">.</span>affine_coord<span class="token punctuation">(</span>sz<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">)</span>
x1 <span class="token operator">=</span> x1<span class="token punctuation">.</span>rotate<span class="token punctuation">(</span>draw<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">1.</span><span class="token punctuation">)</span>
x1 <span class="token operator">=</span> x1<span class="token punctuation">.</span>zoom<span class="token punctuation">(</span>draw<span class="token operator">=</span><span class="token number">1.2</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">1.</span><span class="token punctuation">)</span>
x1 <span class="token operator">=</span> x1<span class="token punctuation">.</span>warp<span class="token punctuation">(</span>draw_x<span class="token operator">=</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> draw_y<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">1.</span><span class="token punctuation">)</span>

tfms <span class="token operator">=</span> setup_aug_tfms<span class="token punctuation">(</span><span class="token punctuation">[</span>Rotate<span class="token punctuation">(</span>draw<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Zoom<span class="token punctuation">(</span>draw<span class="token operator">=</span><span class="token number">1.2</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">1.</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                       Warp<span class="token punctuation">(</span>draw_x<span class="token operator">=</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> draw_y<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">1.</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span>tfms<span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment">#x.affine_coord(coord_tfm=coord_tfm, sz=size, mode=mode, pad_mode=pad_mode)</span>
TensorImage<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span>ctx<span class="token operator">=</span>axs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
TensorImage<span class="token punctuation">(</span>x1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span>ctx<span class="token operator">=</span>axs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405282138913.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">fastai数据增强效果与传统方法对比</div></center><p>fastai的数据增强策略比传统的好。</p><h3 id="检查和调试数据块"><a href="#检查和调试数据块" class="headerlink" title="检查和调试数据块"></a>检查和调试数据块</h3><p><code>show_batch</code>方法</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dls<span class="token punctuation">.</span>show_batch<span class="token punctuation">(</span>nrows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ncols<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>summary</code>方法，这里没有使用Resize转换，产生了不同大小的图像</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">pets1 <span class="token operator">=</span> DataBlock<span class="token punctuation">(</span>blocks <span class="token operator">=</span> <span class="token punctuation">(</span>ImageBlock<span class="token punctuation">,</span> CategoryBlock<span class="token punctuation">)</span><span class="token punctuation">,</span>
                 get_items<span class="token operator">=</span>get_image_files<span class="token punctuation">,</span> 
                 splitter<span class="token operator">=</span>RandomSplitter<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                 get_y<span class="token operator">=</span>using_attr<span class="token punctuation">(</span>RegexLabeller<span class="token punctuation">(</span><span class="token string">r'(.+)_\d+.jpg$'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'name'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
pets1<span class="token punctuation">.</span>summary<span class="token punctuation">(</span>path<span class="token operator">/</span><span class="token string">"images"</span><span class="token punctuation">)</span>

<span class="token comment"># 可以显示运行时有错误的地方。可以清楚的看到如何收集数据并将其拆分的，如何从一个文件名转换为一个样本的...以及无法在一个batch中处理形状不同的样本</span>
Setting<span class="token operator">-</span>up <span class="token builtin">type</span> transforms pipelines
Collecting items <span class="token keyword">from</span> C<span class="token punctuation">:</span>\Users\<span class="token number">19764</span>\<span class="token punctuation">.</span>fastai\data\oxford<span class="token operator">-</span>iiit<span class="token operator">-</span>pet\images
Found <span class="token number">7390</span> items
<span class="token number">2</span> datasets of sizes <span class="token number">5912</span><span class="token punctuation">,</span><span class="token number">1478</span>
Setting up Pipeline<span class="token punctuation">:</span> PILBase<span class="token punctuation">.</span>create
Setting up Pipeline<span class="token punctuation">:</span> partial <span class="token operator">-</span><span class="token operator">&gt;</span> Categorize <span class="token operator">-</span><span class="token operator">-</span> <span class="token punctuation">{</span><span class="token string">'vocab'</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token string">'sort'</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token string">'add_na'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span>

Building one sample
  Pipeline<span class="token punctuation">:</span> PILBase<span class="token punctuation">.</span>create
    starting <span class="token keyword">from</span>
      C<span class="token punctuation">:</span>\Users\<span class="token number">19764</span>\<span class="token punctuation">.</span>fastai\data\oxford<span class="token operator">-</span>iiit<span class="token operator">-</span>pet\images\saint_bernard_138<span class="token punctuation">.</span>jpg
    applying PILBase<span class="token punctuation">.</span>create gives
      PILImage mode<span class="token operator">=</span>RGB size<span class="token operator">=</span>500x375
  Pipeline<span class="token punctuation">:</span> partial <span class="token operator">-</span><span class="token operator">&gt;</span> Categorize <span class="token operator">-</span><span class="token operator">-</span> <span class="token punctuation">{</span><span class="token string">'vocab'</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token string">'sort'</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token string">'add_na'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span>
    starting <span class="token keyword">from</span>
      C<span class="token punctuation">:</span>\Users\<span class="token number">19764</span>\<span class="token punctuation">.</span>fastai\data\oxford<span class="token operator">-</span>iiit<span class="token operator">-</span>pet\images\saint_bernard_138<span class="token punctuation">.</span>jpg
    applying partial gives
      saint_bernard
    applying Categorize <span class="token operator">-</span><span class="token operator">-</span> <span class="token punctuation">{</span><span class="token string">'vocab'</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token string">'sort'</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token string">'add_na'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span> gives
      TensorCategory<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span>

Final sample<span class="token punctuation">:</span> <span class="token punctuation">(</span>PILImage mode<span class="token operator">=</span>RGB size<span class="token operator">=</span>500x375<span class="token punctuation">,</span> TensorCategory<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


Collecting items <span class="token keyword">from</span> C<span class="token punctuation">:</span>\Users\<span class="token number">19764</span>\<span class="token punctuation">.</span>fastai\data\oxford<span class="token operator">-</span>iiit<span class="token operator">-</span>pet\images
Found <span class="token number">7390</span> items
<span class="token number">2</span> datasets of sizes <span class="token number">5912</span><span class="token punctuation">,</span><span class="token number">1478</span>
Setting up Pipeline<span class="token punctuation">:</span> PILBase<span class="token punctuation">.</span>create
Setting up Pipeline<span class="token punctuation">:</span> partial <span class="token operator">-</span><span class="token operator">&gt;</span> Categorize <span class="token operator">-</span><span class="token operator">-</span> <span class="token punctuation">{</span><span class="token string">'vocab'</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token string">'sort'</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token string">'add_na'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span>
Setting up after_item<span class="token punctuation">:</span> Pipeline<span class="token punctuation">:</span> ToTensor
Setting up before_batch<span class="token punctuation">:</span> Pipeline<span class="token punctuation">:</span> 
Setting up after_batch<span class="token punctuation">:</span> Pipeline<span class="token punctuation">:</span> IntToFloatTensor <span class="token operator">-</span><span class="token operator">-</span> <span class="token punctuation">{</span><span class="token string">'div'</span><span class="token punctuation">:</span> <span class="token number">255.0</span><span class="token punctuation">,</span> <span class="token string">'div_mask'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span>

Building one batch
Applying item_tfms to the first sample<span class="token punctuation">:</span>
  Pipeline<span class="token punctuation">:</span> ToTensor
    starting <span class="token keyword">from</span>
      <span class="token punctuation">(</span>PILImage mode<span class="token operator">=</span>RGB size<span class="token operator">=</span>500x375<span class="token punctuation">,</span> TensorCategory<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    applying ToTensor gives
      <span class="token punctuation">(</span>TensorImage of size 3x375x500<span class="token punctuation">,</span> TensorCategory<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

Adding the <span class="token builtin">next</span> <span class="token number">3</span> samples

No before_batch transform to <span class="token builtin">apply</span>

Collating items <span class="token keyword">in</span> a batch
Error! It's <span class="token keyword">not</span> possible to collate your items <span class="token keyword">in</span> a batch
Could <span class="token keyword">not</span> collate the <span class="token number">0</span><span class="token operator">-</span>th members of your tuples because got the following shapes
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">375</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">199</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">333</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">430</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>开始训练</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn <span class="token operator">=</span> vision_learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> resnet34<span class="token punctuation">,</span> metrics<span class="token operator">=</span>error_rate<span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fine_tune<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405291043548.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">训练结果</div></center><p>DataBlock中添加，再训练</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">item_tfms<span class="token operator">=</span>Resize<span class="token punctuation">(</span><span class="token number">460</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
batch_tfms<span class="token operator">=</span>aug_transforms<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span> min_scale<span class="token operator">=</span><span class="token number">0.75</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405291057018.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">训练结果</div></center><p><em>损失</em>是用来优化参数模型的指标。如果没有告诉fastai使用什么损失函数，fastai将根据数据类型和模型选择适当的损失函数，对于图像分类，fastai默认使用<em>交叉熵损失</em>。</p><h2 id="交叉熵损失"><a href="#交叉熵损失" class="headerlink" title="交叉熵损失"></a>交叉熵损失</h2><p>优势：</p><ul><li>即使因变量有两个以上的类别，它仍然有效</li><li>训练速度更快，更可靠</li></ul><h3 id="查看激活值和标签"><a href="#查看激活值和标签" class="headerlink" title="查看激活值和标签"></a>查看激活值和标签</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">,</span>y <span class="token operator">=</span> dls<span class="token punctuation">.</span>one_batch<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 从数据加载器中获得一批真实数据</span>
preds<span class="token punctuation">,</span>_ <span class="token operator">=</span> learn<span class="token punctuation">.</span>get_preds<span class="token punctuation">(</span>dl<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 查看预测结果（神经网络最后一层的激活值）</span>
<span class="token comment"># preds[0]</span>
<span class="token builtin">len</span><span class="token punctuation">(</span>preds<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>preds<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><code>get_preds</code>可以接收数据集索引，0代表训练集，1代表验证集或批迭代器作为输入。默认返回预测结果和对应的目标类别。</p><p>实际预测结果是0-1之间的37个概率，加起来总和是1。</p><h3 id="交叉熵损失之softmax"><a href="#交叉熵损失之softmax" class="headerlink" title="交叉熵损失之softmax"></a>交叉熵损失之softmax</h3><p>为了将模型的激活值转换成符合上述的预测值，使用softmax的激活函数。</p><p>分类模型中，最后一层使用softmax激活函数来确保激活值在0-1之间，并且总和为1.softmax看起来像sigmoid函数。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">plot_function<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token builtin">max</span><span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405291116678.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">sigmoid</div></center><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>random<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>
acts <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">2</span>
acts<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>acts<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-</span>acts<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>比较两个神经网络激活值之间的差异</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">return</span> exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>softmax是sigmoid的多类别版本，只要有两个或两个以上的类别，并且这些类别的概率加起来必须是1，就用它。</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">sm_acts <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>acts<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>直观地说，softmax 函数确实想从其他类中选择一个类，因此当我们知道每张图片都有明确的标签时，它是训练分类器的理想选择。（请注意，在推理过程中它可能不太理想，因为你可能希望你的模型有时告诉你它无法识别它在训练期间看到的一些类别，并且不因为它的激活值稍大就盲目选择它。在这种情况下，最好对每一列使用二元分类的方法和概念，并且都使用一个sigmoid激活函数来训练模型比较好。）</p><h3 id="交叉熵损失之对数似然"><a href="#交叉熵损失之对数似然" class="headerlink" title="交叉熵损失之对数似然"></a>交叉熵损失之对数似然</h3><ul><li><p>用sigmoid的话，表示这10类互不相关，得到的10个概率值中的每个值代表输入这类的概率和不属于这类的概率，0-1之间的值。比如第4个值，代表输入第4类的值概率和不属于第4类的概率，和其它9个值没关系。经过sigmoid输出的10个值互不影响，只关注某一类的可能性概率是多大，每一类都是二分类，所以加起来也不等于1，可以是第一类得到的值0.9，第二个也是0.9。</p></li><li><p>用softmax就不一样了，它要综合考虑10个类，属于每个类的概率，这10个类相互影响，加起来是等于1的。</p></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">targ <span class="token operator">=</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
sm_acts
idx <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span>
sm_acts<span class="token punctuation">[</span>idx<span class="token punctuation">,</span> targ<span class="token punctuation">]</span>

<span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> HTML
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>sm_acts<span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"3"</span><span class="token punctuation">,</span><span class="token string">"7"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df<span class="token punctuation">[</span><span class="token string">'targ'</span><span class="token punctuation">]</span> <span class="token operator">=</span> targ
df<span class="token punctuation">[</span><span class="token string">'idx'</span><span class="token punctuation">]</span> <span class="token operator">=</span> idx
df<span class="token punctuation">[</span><span class="token string">'result'</span><span class="token punctuation">]</span> <span class="token operator">=</span> sm_acts<span class="token punctuation">[</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> targ<span class="token punctuation">]</span>
t <span class="token operator">=</span> df<span class="token punctuation">.</span>style<span class="token punctuation">.</span>hide_index<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#To have html code compatible with our script</span>
html <span class="token operator">=</span> t<span class="token punctuation">.</span>_repr_html_<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'&lt;/style&gt;'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
html <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'&lt;table id="([^"]+)"\s*&gt;'</span><span class="token punctuation">,</span> <span class="token string">r'&lt;table &gt;'</span><span class="token punctuation">,</span> html<span class="token punctuation">)</span>
display<span class="token punctuation">(</span>HTML<span class="token punctuation">(</span>html<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405291632753.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">数字识别3和7</div></center><p>PyTorch提供和<code>sm_acts</code>功能相同的函数<code>nll_loss</code>。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">-</span>sm_acts<span class="token punctuation">[</span>idx<span class="token punctuation">,</span> targ<span class="token punctuation">]</span>
<span class="token comment"># tensor([-0.6025, -0.4979, -0.1332, -0.0034, -0.4041, -0.3661])</span>
F<span class="token punctuation">.</span>nll_loss<span class="token punctuation">(</span>sm_acts<span class="token punctuation">,</span> targ<span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">)</span>
<span class="token comment"># tensor([-0.6025, -0.4979, -0.1332, -0.0034, -0.4041, -0.3661])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="使用对数函数"><a href="#使用对数函数" class="headerlink" title="使用对数函数"></a>使用对数函数</h3><p>损失中使用的是概率，0-1，如0.99和0.999，尽管很接近，但是后者比前者能有高10倍的信心，所以把0和1之间的数转换成负无穷大和无穷大之间的数。自然而然地使用到对数（torch.log）。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">plot_function<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>log<span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token builtin">max</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ty<span class="token operator">=</span><span class="token string">'log(x)'</span><span class="token punctuation">,</span> tx<span class="token operator">=</span><span class="token string">'x'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405291644857.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">log函数</div></center><p>Python中log使用自然数对数e作为底。</p><p>log(a*b) = log(a)+log(b)。当基础信号以指数或乘法递增时，对于对数是线性增加的。</p><blockquote><p>nll_loss中的”nll“代表”负对数似然“，但它实际根本不取对数。它假设已经取得了对数。PyTorch中有一个名为log_softmax的函数，它以一种快速而准确的方式把对数和softmax结合起来，nll_loss设计为在log_softmax之后使用。</p></blockquote><p>如果我们首先取softmax，然后取它的对数似然，这个组合叫<code>交叉熵损失</code>。PyTorch中为<code>nn.CrossEntropyLoss</code></p><p>（实际上，先做log_softmax，再做nll_loss）。</p><p>则之前</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> HTML
df<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>tensor<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'result'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
t <span class="token operator">=</span> df<span class="token punctuation">.</span>style<span class="token punctuation">.</span>hide_index<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#To have html code compatible with our script</span>
html <span class="token operator">=</span> t<span class="token punctuation">.</span>_repr_html_<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'&lt;/style&gt;'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
html <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'&lt;table id="([^"]+)"\s*&gt;'</span><span class="token punctuation">,</span> <span class="token string">r'&lt;table &gt;'</span><span class="token punctuation">,</span> html<span class="token punctuation">)</span>
display<span class="token punctuation">(</span>HTML<span class="token punctuation">(</span>html<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405291714939.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">数字识别3和7</div></center><p>观察一个数字的对数接近负无穷大，因为该数字接近于零。在本例中，由于结果与正确标签的预测概率相关，我们希望我们的损失函数在预测为“好”（接近 1）时返回一个小值，在预测为“坏”（接近 0）时返回一个大值。我们可以通过取对数的负数来实现这一点：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">plot_function<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token operator">-</span><span class="token number">1</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token builtin">max</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> tx<span class="token operator">=</span><span class="token string">'x'</span><span class="token punctuation">,</span> ty<span class="token operator">=</span><span class="token string">'- log(x)'</span><span class="token punctuation">,</span> title <span class="token operator">=</span> <span class="token string">'Log Loss when true label = 1'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>计算交叉熵损失</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss_func <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
loss_func<span class="token punctuation">(</span>acts<span class="token punctuation">,</span> targ<span class="token punctuation">)</span>
<span class="token comment"># tensor(1.8045)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>类形式（更倾向于使用这个）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>acts<span class="token punctuation">,</span> targ<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>F命名空间中的形式。</p><p>默认情况下，PyTorch损失函数取所有项目损失的平均值，可以更改设定：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>acts<span class="token punctuation">,</span> targ<span class="token punctuation">)</span>
<span class="token comment"># tensor([0.5067, 0.6973, 2.0160, 5.6958, 0.9062, 1.0048])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>当我们考虑交叉熵损失的梯度时，它的一个有趣特征出现了。cross_entropy(a,b)的梯度只是softmax(a)-b。由于softmax(a)是模型的最终激活值，这意味着梯度与预测和目标之间的差异成正比。这与回归中的均方误差相同（假设没有最终激活函数）就直接与y_range相加，因为<code>(a-b)**2</code>的梯度为<code>2*(a-b)</code>。因为梯度是线性的，这意味着我们不会看到梯度的突然跳跃或指数级增长，这应该使得模型的训练过程更平滑。</p><h2 id="模型解释"><a href="#模型解释" class="headerlink" title="模型解释"></a>模型解释</h2><p>可以使用混淆矩阵（confusion_matrix）看模型的效果。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">interp <span class="token operator">=</span> ClassificationInterpretation<span class="token punctuation">.</span>from_learner<span class="token punctuation">(</span>learn<span class="token punctuation">)</span>
interp<span class="token punctuation">.</span>plot_confusion_matrix<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dpi<span class="token operator">=</span><span class="token number">60</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405300940999.png" width="700"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">混淆矩阵</div></center><p>可以使用<code>most_confused</code>只显示混淆矩阵中预测不正确的单元格。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">interp<span class="token punctuation">.</span>most_confused<span class="token punctuation">(</span>min_val<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token comment"># 这里显示至少5个或更多错误类别</span>
<span class="token comment"># [('staffordshire_bull_terrier', 'american_pit_bull_terrier', 6),</span>
<span class="token comment"># ('Birman', 'Ragdoll', 5),</span>
<span class="token comment"># ('Ragdoll', 'Birman', 5)]</span>
<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'Birman'</span><span class="token punctuation">,</span> <span class="token string">'Ragdoll'</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="改进模型"><a href="#改进模型" class="headerlink" title="改进模型"></a>改进模型</h2><p>迁移学习，如何在不破坏预训练权重的情况下尽可能地微调预训练模型。</p><h3 id="学习率查找器"><a href="#学习率查找器" class="headerlink" title="学习率查找器"></a>学习率查找器</h3><p>设置太小，需要多个周期训练模型，并且会记住数据，导致过拟合。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn <span class="token operator">=</span> vision_learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> resnet34<span class="token punctuation">,</span> metrics<span class="token operator">=</span>error_rate<span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fine_tune<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> base_lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span> <span class="token comment"># 设大点试试</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405300942584.png" width="300"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">学习率设为0.1</div></center><p>！不对劲啊🙃</p><p>学习率查找器（learning rate finder）：从一个很小的学习率开始，计算出其损失，然后学习率每次倍增，直到损失更差。然后以下规则二选一</p><ul><li>选择的损失比达到最小损失时少一个数量级（即最小值除以10）</li><li>选择曲线上损失明显减少的最后一点</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn <span class="token operator">=</span> vision_learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> resnet34<span class="token punctuation">,</span> metrics<span class="token operator">=</span>error_rate<span class="token punctuation">)</span>
lr_min<span class="token punctuation">,</span>lr_steep <span class="token operator">=</span> learn<span class="token punctuation">.</span>lr_find<span class="token punctuation">(</span>suggest_funcs<span class="token operator">=</span><span class="token punctuation">(</span>minimum<span class="token punctuation">,</span> steep<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Minimum/10: </span><span class="token interpolation"><span class="token punctuation">{</span>lr_min<span class="token punctuation">:</span><span class="token format-spec">.2e</span><span class="token punctuation">}</span></span><span class="token string">, steepest point: </span><span class="token interpolation"><span class="token punctuation">{</span>lr_steep<span class="token punctuation">:</span><span class="token format-spec">.2e</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token comment"># Minimum/10: 1.00e-02, steepest point: 3.02e-03</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405300945946.png" width="500"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">学习率与损失</div></center><p>上图可以看出，在1e-6到1e-3范围内，模型没有训练，之后损失减少，直到最小值，然后又增加。不希望学习率超过1e-1，因为这会导致训练出现发散的情况。</p><p>看上去似乎3e-3左右的学习率是合适的，试试看</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn <span class="token operator">=</span> vision_learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> resnet34<span class="token punctuation">,</span> metrics<span class="token operator">=</span>error_rate<span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fine_tune<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> base_lr<span class="token operator">=</span><span class="token number">3e-3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405301440994.png" width="300"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">学习率设为3e-3的训练结果</div></center><p><strong>对数范围</strong>，在学习率查找器绘制的图像中，学习率通常是在对数尺度上表示的。这是因为在优化神经网络时，我们通常更关心学习率的数量级，而不是它的精确值。</p><p>例如，1e-3（或0.001）和1e-2（或0.01）之间的中点在线性尺度上是0.0055，但在对数尺度上，它会更接近于1e-3。这是因为在对数尺度上，<strong>每个单位的距离表示的是值的倍数，而不是值的增量</strong>。所以，对数尺度上的中点表示的是两个值的几何平均数，而不是它们的算术平均数。</p><p>在 fastai 中，你可以使用 <code>Learner.lr_find</code> 方法来找到一个好的学习率。这个方法会绘制一个损失与学习率的图像，其中学习率是在对数尺度上表示的。你可以通过查找损失最快下降的学习率来选择一个好的学习率。</p><p>算术平均数和几何平均数是两种不同的计算平均值的方法。</p><ul><li>算术平均数是所有数值的和除以数值的数量。例如，数值 2, 4, 6 的算术平均数是 (2+4+6)/3 = 4。</li><li>几何平均数是所有数值的乘积的 n 次方根，其中 n 是数值的数量。例如，数值 2, 4, 8 的几何平均数是 (2*4*8)^(1/3) ≈ 4.16。</li></ul><p>在对数尺度上，我们通常使用几何平均数，因为它可以给出数值的中间数量级。例如，对于数值 1e-3 和 1e-2，它们的几何平均数是 (1e-3 * 1e-2)^(1/2) = 3.16e-3，这个值在对数尺度上位于 1e-3 和 1e-2 之间。</p><h3 id="解冻与迁移学习"><a href="#解冻与迁移学习" class="headerlink" title="解冻与迁移学习"></a>解冻与迁移学习</h3><p>卷积神经网络由多个线性层组成，每两层之间有一个非线性激活函数，然后是一个或多个最终的线性层，最后有一个激活函数，如softmax。最后一个线性层使用一个列数足够多的矩阵，以便输出的大小与模型中的类别数相同（假设在进行分类）。</p><p>当在迁移学习中进行微调时，最后的线性层用处不大，用新层替换，匹配新的任务。</p><p>新添加的层具有随机权重，在微调之前具有完全随机的输出。前几层网络可以寻找到通用的特征，如边缘和梯度，后几层网络仍能代表一些对我们有用的特征。</p><p>目标：训练的模型能记住预训练模型中具有普适且通用的一些特征，然后使用它们来解决特定任务，并仅根据特定任务的具体情况进行调整。</p><p><strong>微调挑战</strong>：如何用能够正确实现期望任务的权重替换掉添加的线性层中的随机权重，而不破坏经过仔细训练的权重和其他层？</p><p><strong>实现</strong>：告诉优化器只更新那些随机添加的最终层中的权重，不改变神经网络其余部分的权重。（形象说成是把那些预训练层冻结住）</p><p><strong>fastai</strong>：当从预训练网络创建模型时，fastai会自动冻结所有预训练层。当调用微调方法时，fastai做两件事：</p><ul><li>每一周期都只训练随机添加的层，冻结住所有的其他层</li><li>解冻所有层，并根据我们设定好的周期数对其进行训练</li></ul><p>自定义<code>fine_tune</code>训练过程，</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn<span class="token punctuation">.</span>fine_tune?? <span class="token comment"># 查看fine_tune源代码</span>
<span class="token comment">###</span>
Signature<span class="token punctuation">:</span>
learn<span class="token punctuation">.</span>fine_tune<span class="token punctuation">(</span>
    epochs<span class="token punctuation">,</span>
    base_lr<span class="token operator">=</span><span class="token number">0.002</span><span class="token punctuation">,</span>
    freeze_epochs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
    lr_mult<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
    pct_start<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span>
    div<span class="token operator">=</span><span class="token number">5.0</span><span class="token punctuation">,</span>
    <span class="token operator">*</span><span class="token punctuation">,</span>
    lr_max<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    div_final<span class="token operator">=</span><span class="token number">100000.0</span><span class="token punctuation">,</span>
    wd<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    moms<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    cbs<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    reset_opt<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    start_epoch<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
Source<span class="token punctuation">:</span>   
<span class="token decorator annotation punctuation">@patch</span>
<span class="token decorator annotation punctuation">@delegates</span><span class="token punctuation">(</span>Learner<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">fine_tune</span><span class="token punctuation">(</span>self<span class="token punctuation">:</span>Learner<span class="token punctuation">,</span> epochs<span class="token punctuation">,</span> base_lr<span class="token operator">=</span><span class="token number">2e-3</span><span class="token punctuation">,</span> freeze_epochs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> lr_mult<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
              pct_start<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> div<span class="token operator">=</span><span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token string">"Fine tune with `Learner.freeze` for `freeze_epochs`, then with `Learner.unfreeze` for `epochs`, using discriminative LR."</span>
    self<span class="token punctuation">.</span>freeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span>freeze_epochs<span class="token punctuation">,</span> <span class="token builtin">slice</span><span class="token punctuation">(</span>base_lr<span class="token punctuation">)</span><span class="token punctuation">,</span> pct_start<span class="token operator">=</span><span class="token number">0.99</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
    base_lr <span class="token operator">/=</span> <span class="token number">2</span>
    self<span class="token punctuation">.</span>unfreeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span> <span class="token builtin">slice</span><span class="token punctuation">(</span>base_lr<span class="token operator">/</span>lr_mult<span class="token punctuation">,</span> base_lr<span class="token punctuation">)</span><span class="token punctuation">,</span> pct_start<span class="token operator">=</span>pct_start<span class="token punctuation">,</span> div<span class="token operator">=</span>div<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
File<span class="token punctuation">:</span>      f<span class="token punctuation">:</span>\anconda3\envs\pytorch\lib\site<span class="token operator">-</span>packages\fastai\callback\schedule<span class="token punctuation">.</span>py
Type<span class="token punctuation">:</span>      method<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>fine_tune</code> 是 fastai 库中的一个方法，用于对预训练模型进行微调。以下是参数的解释：</p><ul><li><code>epochs</code>：整个数据集的训练次数。</li><li><code>base_lr</code>：训练开始时的学习率。</li><li><code>freeze_epochs</code>：在开始微调之前，冻结预训练层并训练新添加的层的周期数。</li><li><code>lr_mult</code>：最后一层和第一层之间的学习率的比率。</li><li><code>pct_start</code>：学习率调度的上升阶段所占的比例。</li><li><code>div</code>：最大学习率和最小学习率之间的比率。</li><li><code>lr_max</code>：学习率调度的最大学习率。</li><li><code>div_final</code>：最终学习率和最小学习率之间的比率。</li><li><code>wd</code>：权重衰减。</li><li><code>moms</code>：动量。</li><li><code>cbs</code>：要传递给训练器的回调函数。</li><li><code>reset_opt</code>：是否在微调前重置优化器。</li><li><code>start_epoch</code>：开始训练的周期。</li></ul><p>这个方法首先冻结预训练模型的所有层，只训练新添加的层（比如在图像分类任务中的全连接层）。然后，它解冻所有的层，并使用学习率调度进行训练。学习率调度开始时，学习率会逐渐增加，然后再逐渐减小。这种策略可以帮助模型快速收敛，并避免陷入不良的局部最优。</p><p>直接调用底层方法更简单，使用<code>fit_one_cycle</code>对随机添加的层进行几个周期的训练。以较低的学习率开始训练，然后在第一部分的训练中逐渐提高学习率，再在最后一部分的训练中逐渐降低学习率。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn<span class="token punctuation">.</span>fit_one_cycle??
Signature<span class="token punctuation">:</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span>
    n_epoch<span class="token punctuation">,</span>
    lr_max<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    div<span class="token operator">=</span><span class="token number">25.0</span><span class="token punctuation">,</span>
    div_final<span class="token operator">=</span><span class="token number">100000.0</span><span class="token punctuation">,</span>
    pct_start<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">,</span>
    wd<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    moms<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    cbs<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    reset_opt<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    start_epoch<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
Source<span class="token punctuation">:</span>   
<span class="token decorator annotation punctuation">@patch</span>
<span class="token keyword">def</span> <span class="token function">fit_one_cycle</span><span class="token punctuation">(</span>self<span class="token punctuation">:</span>Learner<span class="token punctuation">,</span> n_epoch<span class="token punctuation">,</span> lr_max<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> div<span class="token operator">=</span><span class="token number">25.</span><span class="token punctuation">,</span> div_final<span class="token operator">=</span><span class="token number">1e5</span><span class="token punctuation">,</span> pct_start<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">,</span> wd<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                  moms<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> cbs<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> reset_opt<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> start_epoch<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token string">"Fit `self.model` for `n_epoch` using the 1cycle policy."</span>
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>opt <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>create_opt<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>opt<span class="token punctuation">.</span>set_hyper<span class="token punctuation">(</span><span class="token string">'lr'</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>lr <span class="token keyword">if</span> lr_max <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">else</span> lr_max<span class="token punctuation">)</span>
    lr_max <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>h<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> h <span class="token keyword">in</span> self<span class="token punctuation">.</span>opt<span class="token punctuation">.</span>hypers<span class="token punctuation">]</span><span class="token punctuation">)</span>
    scheds <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'lr'</span><span class="token punctuation">:</span> combined_cos<span class="token punctuation">(</span>pct_start<span class="token punctuation">,</span> lr_max<span class="token operator">/</span>div<span class="token punctuation">,</span> lr_max<span class="token punctuation">,</span> lr_max<span class="token operator">/</span>div_final<span class="token punctuation">)</span><span class="token punctuation">,</span>
              <span class="token string">'mom'</span><span class="token punctuation">:</span> combined_cos<span class="token punctuation">(</span>pct_start<span class="token punctuation">,</span> <span class="token operator">*</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>moms <span class="token keyword">if</span> moms <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">else</span> moms<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
    self<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>n_epoch<span class="token punctuation">,</span> cbs<span class="token operator">=</span>ParamScheduler<span class="token punctuation">(</span>scheds<span class="token punctuation">)</span><span class="token operator">+</span>L<span class="token punctuation">(</span>cbs<span class="token punctuation">)</span><span class="token punctuation">,</span> reset_opt<span class="token operator">=</span>reset_opt<span class="token punctuation">,</span> wd<span class="token operator">=</span>wd<span class="token punctuation">,</span> start_epoch<span class="token operator">=</span>start_epoch<span class="token punctuation">)</span>
File<span class="token punctuation">:</span>      f<span class="token punctuation">:</span>\anconda3\envs\pytorch\lib\site<span class="token operator">-</span>packages\fastai\callback\schedule<span class="token punctuation">.</span>py
Type<span class="token punctuation">:</span>      method<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>fit_one_cycle</code> 方法的参数解释如下：</p><ul><li><code>n_epoch</code>：训练的周期数，即整个数据集的训练次数。</li><li><code>lr_max</code>：学习率调度的最大学习率。</li><li><code>div</code>：初始学习率与 <code>lr_max</code> 的比率，用于计算初始学习率。</li><li><code>div_final</code>：最终学习率与 <code>lr_max</code> 的比率，用于计算最终学习率。</li><li><code>pct_start</code>：在训练周期中，学习率从初始值增加到 <code>lr_max</code> 的部分所占的比例。</li><li><code>wd</code>：权重衰减系数，用于正则化模型参数。</li><li><code>moms</code>：动量的最大值和最小值，用于调整优化器的动量。</li><li><code>cbs</code>：需要添加到训练过程中的回调函数列表。</li><li><code>reset_opt</code>：是否在训练开始时重置优化器。</li><li><code>start_epoch</code>：训练开始的周期数，通常用于继续之前中断的训练。</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn <span class="token operator">=</span> vision_learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> resnet34<span class="token punctuation">,</span> metrics<span class="token operator">=</span>error_rate<span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3e-3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405301451140.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">fit_one_cycle训练</div></center><p>然后解冻所有层：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn<span class="token punctuation">.</span>unfreeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>再次运行<code>lr_find</code>，因为要训练的层数更多，而权重已经训练了三个周期了，这意味着以前找到的学习率已经不再适合当前任务。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn<span class="token punctuation">.</span>lr_find<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># SuggestedLRs(valley=1.0964781722577754e-06)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405301453032.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">查找学习率</div></center><p>该图与之前的完整训练有所不同，训练过程中没有出现损失的急剧下降，因为模型时训练过的。而在损失急剧上升之前，有一个稍微平坦的区域，在此取一个点，1e-6.</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> lr_max<span class="token operator">=</span><span class="token number">1e-6</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405301512752.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">学习率为2e-5开始训练</div></center><p>预训练模型的最深层可能不需要像最后几层那样高的学习率，因此可能应该对不同的层使用不同的学习率，称为<strong>区别学习率</strong>。</p><h3 id="区别学习率"><a href="#区别学习率" class="headerlink" title="区别学习率"></a>区别学习率</h3><p>因为已经经过预训练了，所以不希望预训练参数的学习率像之后添加的那么高，对模型进行微调的过程中，让后面的层比前面的层变化得更快时有意义的。</p><p>fastai默认使用区别学习率：对神经网络靠前的层使用较低的学习率，对靠后的层使用较高的学习率（尤其是添加了随机参数的层）。通过迁移学习，神经网络不同的层次应该以不同的速度被训练。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn <span class="token operator">=</span> vision_learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> resnet34<span class="token punctuation">,</span> metrics<span class="token operator">=</span>error_rate<span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3e-3</span><span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>unfreeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> lr_max<span class="token operator">=</span><span class="token builtin">slice</span><span class="token punctuation">(</span><span class="token number">1e-6</span><span class="token punctuation">,</span><span class="token number">1e-4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>如上，slice传递的第一个参数是神经网络（预训练层之后新加的层）最早一层的学习率，第二个值是最后一层的学习率，中间层的学习率将在该范围内成倍等间距地递增。</p><ul><li><code>n_epoch</code>：训练的周期数，即整个数据集的训练次数。</li><li><code>lr_max</code>：学习率调度的最大学习率。</li></ul><p><code>slice(1e-6,1e-4)</code> 表示学习率在训练过程中从 1e-6 变化到 1e-4。这是一种称为 “学习率切片” 的技术，它可以让不同的层使用不同的学习率，通常情况下，模型的前面几层的学习率会比后面几层的学习率小。这是因为前面的层通常负责提取更通用的特征，而后面的层负责提取更具体的特征，所以我们通常希望在训练过程中更多地更新后面的层。</p><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405301551880.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">区别学习率训练结果</div></center><p>fastai可以通过一张图展现训练和验证过程中的损失变化情况：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn<span class="token punctuation">.</span>recorder<span class="token punctuation">.</span>plot_loss<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405301552777.png" width="500"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">训练和验证过程中的损失变化</div></center><p>训练集上损失变得越来越好，但最终验证集上损失的提升慢，甚至有些糟糕，损失变大的地方，这是模型开始过拟合的预警点。但不影响指标的提高。</p><h3 id="选择训练的周期数"><a href="#选择训练的周期数" class="headerlink" title="选择训练的周期数"></a>选择训练的周期数</h3><p><strong>如何选择训练神经网络的周期数（epochs）：</strong></p><ol><li>训练周期数的选择往往受到时间限制，而不是模型的泛化能力或准确率。因此，首先应选择一个在你愿意等待的时间内可以完成的训练周期数。</li><li>通过观察训练和验证损失图，以及你选择的度量指标，如果你发现在最后的周期中，这些指标仍在改善，那么说明你的训练周期数并未过多。</li><li>另一方面，你可能会发现你选择的度量指标在训练结束时变得更糟。这可能是因为模型过于自信，或者错误地记忆了数据。我们实际关心的是后者。损失函数只是我们用来让优化器可以进行微分和优化的工具，而不是我们实际关心的东西。</li><li>在 1cycle 训练出现之前，通常会在每个周期结束时保存模型，然后从所有周期中选择准确率最高的模型。这被称为 “<strong>早停</strong>“（early stopping）。但这种方法不太可能给出最好的结果，因为中间的周期发生在学习率还未达到可以找到最佳结果的小值之前。因此，如果你发现你的模型过拟合了，你应该从头开始重新训练你的模型，并根据你之前找到的最佳结果来选择总的训练周期数。</li><li>如果你有更多的时间来训练更多的周期，你可能会希望使用这些时间来训练更多的参数，即使用更深的架构。</li></ol><p><strong>fastai中如何使用早停（early stopping）来防止过拟合？</strong></p><p>在 fastai 中，你可以使用 <code>EarlyStoppingCallback</code> 来实现早停。这个回调函数会在训练过程中监控一个指定的度量（如验证损失），并在该度量连续几个周期不再改善时停止训练，以防止模型过拟合。</p><p>以下是如何在 fastai 中使用 <code>EarlyStoppingCallback</code> 的示例：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> fastai<span class="token punctuation">.</span>callback <span class="token keyword">import</span> EarlyStoppingCallback

learn <span class="token operator">=</span> cnn_learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> resnet34<span class="token punctuation">,</span> metrics<span class="token operator">=</span>accuracy<span class="token punctuation">)</span>

learn<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> cbs<span class="token operator">=</span>EarlyStoppingCallback<span class="token punctuation">(</span>monitor<span class="token operator">=</span><span class="token string">'valid_loss'</span><span class="token punctuation">,</span> min_delta<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在这个示例中，<code>EarlyStoppingCallback</code> 会监控验证损失 (<code>monitor='valid_loss'</code>)。如果验证损失在连续 3 个周期 (<code>patience=3</code>) 内的改善都小于 0.01 (<code>min_delta=0.01</code>)，那么训练将会被停止。</p><p>注意，<code>EarlyStoppingCallback</code> 只能在 <code>fit</code> 或 <code>fit_one_cycle</code> 等训练方法中使用，不能在 <code>Learner</code> 的构造函数中使用。</p><h3 id="更深的网络架构"><a href="#更深的网络架构" class="headerlink" title="更深的网络架构"></a>更深的网络架构</h3><p>神经网络模型的大小（参数数量）对模型性能的影响，以及如何处理深度模型训练中可能遇到的问题。</p><ol><li>一般来说，参数更多的模型能更准确地拟合数据，但也更容易过拟合，因为有更多的参数可以用来记住训练数据的特定细节。</li><li>由于我们通常使用预训练的模型，所以我们需要选择已经被预训练过的层数。这就是为什么实践中的神经网络架构通常只有少数几种变体，例如 ResNet 就有 18、34、50、101 和 152 层的变体。</li><li>使用更深的模型需要更多的 GPU 内存，可能会导致内存溢出错误。解决这个问题的方法是减小批次大小，即一次通过模型的图像数量。</li><li>更深的架构需要更长的训练时间。一种可以显著加速训练的技术是<strong>混合准确率训练</strong>，即在可能的情况下使用准确率较低的数字（半准确率浮点，也称fp16）进行训练。张量核这一特殊功能，用更少的内存提高训练速度，在 fastai 中，可以通过在创建 <code>Learner</code> 后添加 <code>to_fp16()</code> 来启用这个功能。</li><li>你无法提前知道哪种架构最适合你的问题，需要通过实际训练来尝试。</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> fastai<span class="token punctuation">.</span>callback<span class="token punctuation">.</span>fp16 <span class="token keyword">import</span> <span class="token operator">*</span>
learn <span class="token operator">=</span> vision_learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> resnet50<span class="token punctuation">,</span> metrics<span class="token operator">=</span>error_rate<span class="token punctuation">)</span><span class="token punctuation">.</span>to_fp16<span class="token punctuation">(</span><span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fine_tune<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> freeze_epochs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405301620596.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">混合准确率训练</div></center><p>更大的模型不一定是更好的模型，在开始扩大模型之前，可以先尝试小模型。</p><blockquote><p><a target="_blank" rel="noopener" href="https://nbviewer.org/github/fastai/fastbook/blob/master/05_pet_breeds.ipynb">https://nbviewer.org/github/fastai/fastbook/blob/master/05_pet_breeds.ipynb</a></p></blockquote><h1 id="多标签分类与回归"><a href="#多标签分类与回归" class="headerlink" title="多标签分类与回归"></a>多标签分类与回归</h1><p>迁移学习要注意更改损失函数，</p><ul><li><p>用于单标签分类的nn.CrossEntrophyLoss</p></li><li><p>用于多标签分类的nn.BCEWithLogitsLoss</p></li><li><p>用于回归的nn.MSELoss</p></li></ul><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css"></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="../../../../about" rel="external nofollow noreferrer">nusqx</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://nusqx.top">https://nusqx.top</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="../../../../about" target="_blank">nusqx</a> !</span></div></div><script async defer>document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="../../../../tags/fastai/"><span class="chip bg-color">fastai</span> </a><a href="../../../../tags/cv/"><span class="chip bg-color">cv</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="../../../../libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="../../../../libs/share/js/social-share.min.js"></script></div></div></div><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close"><i class="fas fa-times"></i></a><h4 class="reward-title">你的赏识是我前进的动力</h4><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><script>$(function(){$(".tabs").tabs()})</script></div></div><style>.valine-card{margin:1.5rem auto}.valine-card .card-content{padding:20px 20px 5px 20px}#vcomments textarea{box-sizing:border-box;background:url(../../../medias/comment_bg.png) 100% 100% no-repeat}#vcomments p{margin:2px 2px 10px;font-size:1.05rem;line-height:1.78rem}#vcomments blockquote p{text-indent:.2rem}#vcomments a{padding:0 2px;color:#4cbf30;font-weight:500;text-decoration:none}#vcomments img{max-width:100%;height:auto;cursor:pointer}#vcomments ol li{list-style-type:decimal}#vcomments ol,ul{display:block;padding-left:2em;word-spacing:.05rem}#vcomments ul li,ol li{display:list-item;line-height:1.8rem;font-size:1rem}#vcomments ul li{list-style-type:disc}#vcomments ul ul li{list-style-type:circle}#vcomments table,td,th{padding:12px 13px;border:1px solid #dfe2e5}#vcomments table,td,th{border:0}table tr:nth-child(2n),thead{background-color:#fafafa}#vcomments table th{background-color:#f2f2f2;min-width:80px}#vcomments table td{min-width:80px}#vcomments h1{font-size:1.85rem;font-weight:700;line-height:2.2rem}#vcomments h2{font-size:1.65rem;font-weight:700;line-height:1.9rem}#vcomments h3{font-size:1.45rem;font-weight:700;line-height:1.7rem}#vcomments h4{font-size:1.25rem;font-weight:700;line-height:1.5rem}#vcomments h5{font-size:1.1rem;font-weight:700;line-height:1.4rem}#vcomments h6{font-size:1rem;line-height:1.3rem}#vcomments p{font-size:1rem;line-height:1.5rem}#vcomments hr{margin:12px 0;border:0;border-top:1px solid #ccc}#vcomments blockquote{margin:15px 0;border-left:5px solid #42b983;padding:1rem .8rem .3rem .8rem;color:#666;background-color:rgba(66,185,131,.1)}#vcomments pre{font-family:monospace,monospace;padding:1.2em;margin:.5em 0;background:#272822;overflow:auto;border-radius:.3em;tab-size:4}#vcomments code{font-family:monospace,monospace;padding:1px 3px;font-size:.92rem;color:#e96900;background-color:#f8f8f8;border-radius:2px}#vcomments pre code{font-family:monospace,monospace;padding:0;color:#e8eaf6;background-color:#272822}#vcomments pre[class*=language-]{padding:1.2em;margin:.5em 0}#vcomments code[class*=language-],pre[class*=language-]{color:#e8eaf6}#vcomments [type=checkbox]:not(:checked),[type=checkbox]:checked{position:inherit;margin-left:-1.3rem;margin-right:.4rem;margin-top:-1px;vertical-align:middle;left:unset;visibility:visible}#vcomments b,strong{font-weight:700}#vcomments dfn{font-style:italic}#vcomments small{font-size:85%}#vcomments cite{font-style:normal}#vcomments mark{background-color:#fcf8e3;padding:.2em}#vcomments table,td,th{padding:12px 13px;border:1px solid #dfe2e5}table tr:nth-child(2n),thead{background-color:#fafafa}#vcomments table th{background-color:#f2f2f2;min-width:80px}#vcomments table td{min-width:80px}#vcomments [type=checkbox]:not(:checked),[type=checkbox]:checked{position:inherit;margin-left:-1.3rem;margin-right:.4rem;margin-top:-1px;vertical-align:middle;left:unset;visibility:visible}</style><div class="card valine-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="vcomments" class="card-content" style="display:grid"></div></div><script src="../../../../libs/valine/av-min.js"></script><script src="../../../../libs/valine/Valine.min.js"></script><script>new Valine({el:"#vcomments",appId:"GOX0XlpzLZat5ANucw5j9zjl-gzGzoHsz",appKey:"fha9hT9W6BxJDz7eBYQEPBvc",serverURLs:"",notify:!0,verify:!0,visitor:!1,avatar:"wavatar",pageSize:"10",lang:"zh-cn",placeholder:"What do you say?"})</script><div id="to_comment" class="comment-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#vcomments" title="直达评论"><i class="fas fa-comments"></i></a></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="../nlp/"><div class="card-image"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/featureimages/30.jpg" class="responsive-img" alt="NLP文本分类器"> <span class="card-title">NLP文本分类器</span></div></a><div class="card-content article-content"><div class="summary block-with-text">文本预处理、训练文本分类器、微调模型</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-06-03 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="../../../../categories/NLP/" class="post-category">NLP</a></span></div></div><div class="card-action article-tags"><a href="../../../../tags/nlp/"><span class="chip bg-color">nlp</span> </a><a href="../../../../tags/%E9%A2%84%E8%AE%AD%E7%BB%83/"><span class="chip bg-color">预训练</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="../../02/regression/"><div class="card-image"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/featureimages/24.jpg" class="responsive-img" alt="回归"> <span class="card-title">回归</span></div></a><div class="card-content article-content"><div class="summary block-with-text">图像回归问题</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-06-02 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="../../../../categories/CV/" class="post-category">CV</a></span></div></div><div class="card-action article-tags"><a href="../../../../tags/CV/"><span class="chip bg-color">CV</span> </a><a href="../../../../tags/%E5%9B%9E%E5%BD%92/"><span class="chip bg-color">回归</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0!==window.getSelection&&((""+(n=window.getSelection())).length<Number.parseInt("240")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"!==n.getRangeAt(0).commonAncestorContainer.nodeName&&"CODE"!==n.getRangeAt(0).commonAncestorContainer.nodeName||(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: SQX BLOG<br />文章作者: NUS QX<br />文章链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200)))})</script><script type="text/javascript" src="../../../../libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="../../../../libs/prism/prism.min.js"></script><script type="text/javascript" src="../../../../libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="../../../../libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="../../../../libs/codeBlock/codeShrink.js"></script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget card" style="background-color:#fff"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="../../../../libs/tocbot/tocbot.min.js"></script><script>$(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });</script></main><script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]]}})</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:15px!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2018-2024</span> <a href="../../../../about" target="_blank">NUS QX</a><br><span id="sitetime"></span><span class="my-face"></span><br>&nbsp;|&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">113.6k</span> <span id="busuanzi_container_site_pv" style="display:none"></span> &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span> <span id="busuanzi_container_site_uv" style="display:none"></span> 次&nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;访客人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span> 人 <span id="busuanzi_value_site_uv" class="white-color"></span></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/nusqx" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:1976490928@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fa-solid fa-envelope"></i> </a><a href="https://gitee.com/nusqx" class="tooltipped" target="_blank" data-tooltip="访问我的Gitee: https://gitee.com/nusqx" data-position="top" data-delay="50"><i class="fa-brands fa-square-git"></i> </a><a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1976490928" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1976490928" data-position="top" data-delay="50"><i class="fab fa-qq"></i></a></div></div></footer><div class="progress-bar"></div><script language="javascript">function siteTime(){window.setTimeout("siteTime()",1e3);var e=36e5,t=24*e,o=new Date,i=o.getFullYear(),a=o.getMonth()+1,n=o.getDate(),r=o.getHours(),l=o.getMinutes(),s=o.getSeconds(),M=Date.UTC(2018,9,24,0,0,0),g=Date.UTC(i,a,n,r,l,s)-M,m=Math.floor(g/31536e6),T=Math.floor(g/t-365*m),f=Math.floor((g-(365*m+T)*t)/e),h=Math.floor((g-(365*m+T)*t-f*e)/6e4),u=Math.floor((g-(365*m+T)*t-f*e-6e4*h)/1e3);document.getElementById("sitetime").innerHTML="本站已运行 "+m+" 年 "+T+" 天 "+f+" 小时 "+h+" 分钟 "+u+" 秒"}siteTime()</script><script>$(document).ready(function(){var e=setInterval(function(){"none"!=document.getElementById("busuanzi_container_site_pv").style.display&&($("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html())+n),clearInterval(e));"none"!=$("#busuanzi_container_site_pv").css("display")&&($("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html())+t),clearInterval(e))},50),n=8e4,t=2e4})</script><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script type="text/javascript">$(function(){!function(t,s,i){"use strict";$.ajax({url:t,dataType:"xml",success:function(t){var e=$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),n=document.getElementById(s),r=document.getElementById(i);n.addEventListener("input",function(){var f='<ul class="search-result-list">',m=this.value.trim().toLowerCase().split(/[\s\-]+/);r.innerHTML="",this.value.trim().length<=0||(e.forEach(function(t){var n,e,r,s,i,l=!0,a=t.title.trim().toLowerCase(),c=t.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),u=0===(u=t.url).indexOf("/")?t.url:"/"+u,o=-1,h=-1;""!==a&&""!==c&&m.forEach(function(t,e){n=a.indexOf(t),o=c.indexOf(t),n<0&&o<0?l=!1:(o<0&&(o=0),0===e&&(h=o))}),l&&(f+="<li><a href='"+u+"' class='search-result-title'>"+a+"</a>",e=t.content.trim().replace(/<[^>]+>/g,""),0<=h&&(s=h+80,(r=h-20)<0&&(r=0),0===r&&(s=100),s>e.length&&(s=e.length),i=e.substr(r,s),m.forEach(function(t){var e=new RegExp(t,"gi");i=i.replace(e,'<em class="search-keyword">'+t+"</em>")}),f+='<p class="search-result">'+i+"...</p>"),f+="</li>")}),f+="</ul>",r.innerHTML=f)})}})}("../../../../search.xml","searchInput","searchResult")})</script><div class="stars-con"><div id="stars"></div><div id="stars2"></div><div id="stars3"></div></div><script>function switchNightMode(){$('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($("body")),setTimeout(function(){$("body").hasClass("DarkMode")?($("body").removeClass("DarkMode"),localStorage.setItem("isDark","0"),$("#sum-moon-icon").removeClass("fa-sun").addClass("fa-moon")):($("body").addClass("DarkMode"),localStorage.setItem("isDark","1"),$("#sum-moon-icon").addClass("fa-sun").removeClass("fa-moon")),setTimeout(function(){$(".Cuteen_DarkSky").fadeOut(1e3,function(){$(this).remove()})},2e3)})}</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="../../../../libs/materialize/materialize.min.js"></script><script src="../../../../libs/masonry/masonry.pkgd.min.js"></script><script src="../../../../libs/aos/aos.js"></script><script src="../../../../libs/scrollprogress/scrollProgress.min.js"></script><script src="../../../../libs/lightGallery/js/lightgallery-all.min.js"></script><script src="../../../../js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="../../../../libs/others/clicklove.js" async></script><script async src="../../../../libs/others/busuanzi.pure.mini.js"></script><script type="text/javascript" src="../../../../libs/background/ribbon-dynamic.js" async></script><script src="../../../../libs/instantpage/instantpage.js" type="module"></script>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a,i=c[o];e=function(){c=c.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(n=new Image,a=t.getAttribute("data-original"),n.onload=function(){t.src=a,t.removeAttribute("data-original"),e&&e()},t.src!==a&&(n.src=a))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this);</script><script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>