<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="随机梯度下降,数字分类器"><meta name="description" content="训练数字分类器"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="baidu-site-verification" content="codeva-fVFbpHJJO8"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="referrer" content="no-referrer"><title>MNIST数字分类器 | SQX BLOG</title><link rel="icon" type="image/png" href="../../../../favicon.png"><link rel="stylesheet" type="text/css" href="../../../../libs/awesome/css/all.min.css"><link rel="stylesheet" type="text/css" href="../../../../libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="../../../../libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="../../../../libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="../../../../libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="../../../../css/matery.css"><link rel="stylesheet" type="text/css" href="../../../../css/my.css"><link rel="stylesheet" type="text/css" href="../../../../css/dark.css" media="none" onload='"all"!=media&&(media="all")'><link rel="stylesheet" href="../../../../libs/tocbot/tocbot.css"><link rel="stylesheet" href="../../../../css/post.css"><link rel="stylesheet" type="text/css" href="../../../../css/reward.css"><script src="../../../../libs/jquery/jquery-3.6.0.min.js"></script><meta name="generator" content="Hexo 6.3.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="../../../../index.html" class="waves-effect waves-light"><div><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">SQX BLOG</span></div></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="../../../../index.html" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="../../../../friends" class="waves-effect waves-light"><i class="fas fa-address-book" style="zoom:.6"></i> <span>友情链接</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li><li><a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式"><i id="sum-moon-icon" class="fas fa-sun" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">SQX BLOG</div><div class="logo-desc">Technical writer | Life adventurer</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="../../../../index.html" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="../../../../tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="../../../../categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="../../../../archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="../../../../about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="../../../../friends" class="waves-effect waves-light"><i class="fa-fw fas fa-address-book"></i> 友情链接</a></li></ul></div></div></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(../../../medias/featureimages/0.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">MNIST数字分类器</h1></div></div></div></div></div><main class="post-container content"><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="../../../../tags/DL/"><span class="chip bg-color">DL</span> </a><a href="../../../../tags/fastiai/"><span class="chip bg-color">fastiai</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2024-02-25</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 3.4k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 14 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><link rel="stylesheet" href="../../../../libs/prism/prism.min.css"><div class="card-content article-card-content"><div id="articleContent"><h1 id="数字分类器"><a href="#数字分类器" class="headerlink" title="数字分类器"></a>数字分类器</h1><h2 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h2><p><code>像素相似度</code>：可以使用平均像素值。训练时将所有数字7的图片堆叠在一起，形成<code>(dim,height,weight)</code>。</p><p><code>平均绝对差/L1范数</code>:先对差取绝对值，再求绝对值的平均值。</p><p><code>均方根误差（RMSE）/L2范数</code>:取差平方的均值，然后取其平方根。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">F<span class="token punctuation">.</span>l1_loss<span class="token punctuation">(</span>a_3<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>mean7<span class="token punctuation">)</span><span class="token punctuation">,</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>a_3<span class="token punctuation">,</span>mean7<span class="token punctuation">)</span><span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#l1范数（平均绝对值） mse均方差</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="广播机制计算指标"><a href="#广播机制计算指标" class="headerlink" title="广播机制计算指标"></a>广播机制计算指标</h2><p>不是遍历数据集中的每一张图片，而是传递一个张量（tensor），广播机制不同张量可以匹配（相同阶数）。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">mnist_distance</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">return</span> <span class="token punctuation">(</span>a<span class="token operator">-</span>b<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># dim*h*w，这里求的后两位</span>

mnist_distance<span class="token punctuation">(</span>a_3<span class="token punctuation">,</span> mean3<span class="token punctuation">)</span>
<span class="token comment"># tensor(0.1114)</span>
valid_3_dist <span class="token operator">=</span> mnist_distance<span class="token punctuation">(</span>valid_3_tens<span class="token punctuation">,</span> mean3<span class="token punctuation">)</span>
valid_3_dist<span class="token punctuation">,</span> valid_3_dist<span class="token punctuation">.</span>shape
<span class="token comment"># (tensor([0.1115, 0.1365, 0.1111,  ..., 0.1170, 0.1276, 0.1176]), torch.Size([1010]))</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="随机梯度下降法"><a href="#随机梯度下降法" class="headerlink" title="随机梯度下降法"></a>随机梯度下降法</h1><p>梯度下降</p><blockquote><ol><li><p>初始化权重</p></li><li><p>对任意一张图像，使用这些权重进行预测，预测其类别是3还是7</p></li><li><p>基于上述预测结果，通过计算损失来表示模型的准确率</p></li><li><p>计算<strong>梯度</strong>，梯度表明了每个权重对于整个损失变化的影响程度</p></li><li><p>根据计算得到的梯度信息对权重进行迭代</p></li><li><p>回到步骤2，并重复整个操作</p></li><li><p>迭代完成，停止训练过程（模型达到足够的准确率或训练时间达到上限）</p></li></ol></blockquote><p>计算梯度</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> tensor<span class="token punctuation">(</span><span class="token number">3.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 想得到x**2函数在3.处的梯度，标记变量</span>

<span class="token comment"># 定义一个函数</span>
y <span class="token operator">=</span> x <span class="token operator">*</span> x

<span class="token comment"># 计算反向传播</span>
y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 打印x的梯度</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>  <span class="token comment"># 输出：tensor(6.)</span>

xt <span class="token operator">=</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.</span><span class="token punctuation">,</span><span class="token number">4.</span><span class="token punctuation">,</span><span class="token number">10.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 以一个向量作为参数</span>
<span class="token keyword">def</span> <span class="token function">f</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">return</span> <span class="token punctuation">(</span>x<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 函数中求和，以便接收一个矢量（即一阶张量）并且能够返回一个标量（即一个0阶张量）</span>
yt <span class="token operator">=</span> f<span class="token punctuation">(</span>xt<span class="token punctuation">)</span>
yt<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
xt<span class="token punctuation">.</span>grad
<span class="token comment"># tensor([ 6.,  8., 20.])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>梯度告诉了函数的斜率但是没有告诉确切的参数调整范围。如果斜率很大，则表明需要做更大的调整，而如果斜率很小，则表明已接近最佳值。</p><h1 id="通过学习率迭代"><a href="#通过学习率迭代" class="headerlink" title="通过学习率迭代"></a>通过学习率迭代</h1><p>基于梯度进行模型参数的修改，从将梯度乘以一些很小的值开始的，而这些很小的值被称为<code>学习率（LR）</code>。学习率通常是一个取值范围在0.001到0.1之间的整数，也可以是其他形式。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">w <span class="token operator">-=</span> gradient<span class="token punctuation">(</span>w<span class="token punctuation">)</span> <span class="token operator">*</span> lr<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405251527919.png" width="300"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">小学习率下的梯度下降</div></center><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405251532977.png" width="300"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">大学习率下的梯度下降</div></center><h2 id="直观的随机梯度下降案例"><a href="#直观的随机梯度下降案例" class="headerlink" title="直观的随机梯度下降案例"></a>直观的随机梯度下降案例</h2><p>模拟圆筒滚过土坡顶峰的速度</p><p>数据</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">time <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
speed <span class="token operator">=</span> speed <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">3</span> <span class="token operator">+</span> <span class="token number">0.75</span><span class="token operator">*</span><span class="token punctuation">(</span>time<span class="token operator">-</span><span class="token number">9.5</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> <span class="token number">1</span> <span class="token comment"># 二次函数上添加噪声</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>time<span class="token punctuation">,</span>speed<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405251555824.png" width="300"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">模拟圆筒滚过土坡顶峰的速度</div></center><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">f</span><span class="token punctuation">(</span>t<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 猜测为二次函数</span>
    a<span class="token punctuation">,</span>b<span class="token punctuation">,</span>c <span class="token operator">=</span> params
    <span class="token keyword">return</span> a<span class="token operator">*</span><span class="token punctuation">(</span>t<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>b<span class="token operator">*</span>t<span class="token punctuation">)</span> <span class="token operator">+</span> c
<span class="token comment"># 参数 a,b,c,</span>

<span class="token keyword">def</span> <span class="token function">mse</span><span class="token punctuation">(</span>preds<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>preds<span class="token operator">-</span>targets<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 损失函数 均方差</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><p>step 1 初始化参数</p><p>将参数初始化为随机值，并通过requires_grad_函数跟踪相关参数的梯度信息</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">params <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>step 2 计算预测值</p><p>计算出函数的结果</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">preds <span class="token operator">=</span> f<span class="token punctuation">(</span>time<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>构建一个距离函数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">show_preds</span><span class="token punctuation">(</span>preds<span class="token punctuation">,</span> ax<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> ax <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span> ax<span class="token operator">=</span>plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    ax<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>time<span class="token punctuation">,</span> speed<span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>time<span class="token punctuation">,</span> to_np<span class="token punctuation">(</span>preds<span class="token punctuation">)</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">300</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span>
    
show_preds<span class="token punctuation">(</span>preds<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个函数的功能是将预测的速度和实际的速度在同一张图上绘制出来，预测的速度用红色表示，实际的速度用默认的颜色表示。这样，你就可以直观地看到预测的准确性了。</p><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405251604380.png" width="300"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">计算预测值</div></center></li><li><p>step 3 计算损失</p><p>计算损失</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss <span class="token operator">=</span> mse<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> speed<span class="token punctuation">)</span>
<span class="token comment"># tensor(25823.8086, grad_fn=&lt;MeanBackward0&gt;)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>step 4 计算梯度</p><p>对修改参数的一个估计</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
params<span class="token punctuation">.</span>grad
params<span class="token punctuation">.</span>grad <span class="token operator">*</span> <span class="token number">1e-5</span>
<span class="token comment"># 用梯度优化参数</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>step 5 迭代权重</p><p>根据得到的梯度对参数更新</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">lr <span class="token operator">=</span> <span class="token number">1e-5</span>
params<span class="token punctuation">.</span>data <span class="token operator">-=</span> lr <span class="token operator">*</span> params<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data
params<span class="token punctuation">.</span>grad <span class="token operator">=</span> <span class="token boolean">None</span>

<span class="token comment">#链式法则计算梯度</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>观察优化结果</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">preds <span class="token operator">=</span> f<span class="token punctuation">(</span>time<span class="token punctuation">,</span>params<span class="token punctuation">)</span>
mse<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> speed<span class="token punctuation">)</span>
show_preds<span class="token punctuation">(</span>preds<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405251615118.png" width="300"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">计算预测值</div></center></li><li><p>step 6 重复以上流程</p><p>定义一个一次迭代的步骤</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">apply_step</span><span class="token punctuation">(</span>params<span class="token punctuation">,</span> prn<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    preds <span class="token operator">=</span> f<span class="token punctuation">(</span>time<span class="token punctuation">,</span> params<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> mse<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> speed<span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    params<span class="token punctuation">.</span>data <span class="token operator">-=</span> lr <span class="token operator">*</span> params<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data
    params<span class="token punctuation">.</span>grad <span class="token operator">=</span> <span class="token boolean">None</span>
    <span class="token keyword">if</span> prn<span class="token punctuation">:</span> <span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> preds

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span> apply_step<span class="token punctuation">(</span>params<span class="token punctuation">)</span>

_<span class="token punctuation">,</span>axs <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> ax <span class="token keyword">in</span> axs<span class="token punctuation">:</span> show_preds<span class="token punctuation">(</span>apply_step<span class="token punctuation">(</span>params<span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ax<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>损失的确下降了</p><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405251621364.png" width="700"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">损失下降</div></center></li><li><p>step 7 停止</p><p>迭代了10个epoch停止</p></li></ul><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405251627602.png" width="700"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">梯度下降总结</div></center><h1 id="MNIST损失函数"><a href="#MNIST损失函数" class="headerlink" title="MNIST损失函数"></a>MNIST损失函数</h1><blockquote><p>batch @ weights + bias</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">init_params</span><span class="token punctuation">(</span>size<span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token operator">*</span>std<span class="token punctuation">)</span><span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token punctuation">)</span>

weights <span class="token operator">=</span> init_params<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
bias <span class="token operator">=</span> init_params<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">mnist_loss</span><span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>targets<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">-</span>predictions<span class="token punctuation">,</span> predictions<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>torch.where(condition, x, y)</code>是PyTorch中的一个函数，它的功能是根据一个条件来从两个张量中选择元素。具体来说，<code>condition</code>是一个布尔类型的张量，<code>x</code>和<code>y</code>是两个形状相同的张量。<code>torch.where(condition, x, y)</code>会返回一个新的张量，这个张量的元素来自<code>x</code>和<code>y</code>。如果<code>condition</code>在某个位置的元素为<code>True</code>，那么结果张量在这个位置的元素就是<code>x</code>在这个位置的元素；否则，结果张量在这个位置的元素就是<code>y</code>在这个位置的元素。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">trgts  <span class="token operator">=</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
prds   <span class="token operator">=</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 假设三张图像，分别是3，7，3 对第一张图像为3具有较高的置信度0.9，第二张图像为7具有较低的置信度0.4，认为是3，第三张图像为3的置信度为0.2，认为是7</span>

torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>trgts<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">-</span>prds<span class="token punctuation">,</span> prds<span class="token punctuation">)</span>
<span class="token comment"># tensor([0.1000, 0.4000, 0.8000])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到，当预测更准确，或者说准确的预测更可靠（绝对值更高），及不准确的预测更不可靠时，此函数返回的数值更小。总是假设损失函数的值越小越好。</p><p>因为需要一个标量作为最终损失，所以mnist_loss会对上一个张量取平均值。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">mnist_loss<span class="token punctuation">(</span>prds<span class="token punctuation">,</span>trgts<span class="token punctuation">)</span>
<span class="token comment"># tensor(0.4333)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果将一个假目标的预测值从0.2改为0.8，损失会下降，表明这是一个更好的预测</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">mnist_loss<span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>trgts<span class="token punctuation">)</span>
<span class="token comment"># tensor(0.2333)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>预测的输出设置在0，1之间</strong></p><h2 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h2><p>$\mathrm{S}(\mathrm{x})=\frac{1}{1+\mathrm{e}^{-\mathrm{x}}}$</p><p>总是输出一个介于0和1之间的数值。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">return</span> <span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
plot_function<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'Sigmoid'</span><span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405251925941.png" width="300"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Sigmoid</div></center><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">mnist_loss</span><span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span>
    predictions <span class="token operator">=</span> predictions<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>targets<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">-</span>predictions<span class="token punctuation">,</span> predictions<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>损失必须是一个有意义的可导函数，不能有大的平坦部分和大的跳跃，而且必须相当平滑。会对置信水平的微小变化做出反应。</p><h2 id="SGD和Mini-Batches"><a href="#SGD和Mini-Batches" class="headerlink" title="SGD和Mini-Batches"></a>SGD和Mini-Batches</h2><p><code>小批次</code>：一次计算几个数据项的平均损失。小批次中数据项的大小称为批次大小。</p><p>为获得更好的通用性，在创建小批次之前，在每个周期中随机地对数据集进行洗牌，而不是按顺序列举。</p><p>Pytorch和fastai提供了类<code>DataLoader</code>，执行洗牌和小批次排序。</p><p>DataLoader可以获得任何的Python集合，并将其转换为多个批次的迭代器。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">coll <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span>
dl <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>coll<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token builtin">list</span><span class="token punctuation">(</span>dl<span class="token punctuation">)</span>
<span class="token comment"># [tensor([ 3, 12,  8, 10,  2]),</span>
<span class="token comment"># tensor([ 9,  4,  7, 14,  5]),</span>
<span class="token comment"># tensor([ 1, 13,  0,  6, 11])]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>还需要包含自变量和因变量（模型的输入和输出）的集合，称为<code>Dataset</code>。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">ds <span class="token operator">=</span> L<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>string<span class="token punctuation">.</span>ascii_lowercase<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>ds<span class="token punctuation">)</span>
<span class="token comment"># (#26) [(0, 'a'),(1, 'b'),(2, 'c'),(3, 'd'),(4, 'e'),(5, 'f'),(6, 'g'),(7, 'h'),(8, 'i'),(9, 'j')...]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>当将Dataset传递给DataLoader时，将得到许多批数据，这些数据本身就可以表示为自变量和因变量的张量元组。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dl <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>ds<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token builtin">list</span><span class="token punctuation">(</span>dl<span class="token punctuation">)</span>
<span class="token comment"># 输出如下</span>
<span class="token punctuation">[</span><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'r'</span><span class="token punctuation">,</span> <span class="token string">'s'</span><span class="token punctuation">,</span> <span class="token string">'k'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> <span class="token string">'i'</span><span class="token punctuation">,</span> <span class="token string">'o'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'u'</span><span class="token punctuation">,</span> <span class="token string">'p'</span><span class="token punctuation">,</span> <span class="token string">'j'</span><span class="token punctuation">,</span> <span class="token string">'n'</span><span class="token punctuation">,</span> <span class="token string">'v'</span><span class="token punctuation">,</span> <span class="token string">'m'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'h'</span><span class="token punctuation">,</span> <span class="token string">'z'</span><span class="token punctuation">,</span> <span class="token string">'g'</span><span class="token punctuation">,</span> <span class="token string">'f'</span><span class="token punctuation">,</span> <span class="token string">'l'</span><span class="token punctuation">,</span> <span class="token string">'x'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'y'</span><span class="token punctuation">,</span> <span class="token string">'t'</span><span class="token punctuation">,</span> <span class="token string">'q'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'e'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="将它们集成在一起"><a href="#将它们集成在一起" class="headerlink" title="将它们集成在一起"></a>将它们集成在一起</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 初始化参数</span>
weights <span class="token operator">=</span> init_params<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
bias <span class="token operator">=</span> init_params<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment"># 从Dataset中创建DataLoader</span>
dl <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">)</span>
xb<span class="token punctuation">,</span>yb <span class="token operator">=</span> first<span class="token punctuation">(</span>dl<span class="token punctuation">)</span>
xb<span class="token punctuation">.</span>shape<span class="token punctuation">,</span>yb<span class="token punctuation">.</span>shape
<span class="token comment"># (torch.Size([256, 784]), torch.Size([256, 1]))</span>

valid_dl <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>valid_dset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">)</span>

<span class="token comment"># 构建大小为4的批数据作为测试</span>
batch <span class="token operator">=</span> train_x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span>
batch<span class="token punctuation">.</span>shape
<span class="token comment"># torch.Size([4, 784])</span>

preds <span class="token operator">=</span> linear1<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>

loss <span class="token operator">=</span> mnist_loss<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> train_y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
weights<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>shape<span class="token punctuation">,</span>weights<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>bias<span class="token punctuation">.</span>grad<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="放在一个函数里"><a href="#放在一个函数里" class="headerlink" title="放在一个函数里"></a>放在一个函数里</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">calc_grad</span><span class="token punctuation">(</span>xb<span class="token punctuation">,</span> yb<span class="token punctuation">,</span> model<span class="token punctuation">)</span><span class="token punctuation">:</span>
    preds <span class="token operator">=</span> model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> mnist_loss<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> yb<span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>并对其测试：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">calc_grad<span class="token punctuation">(</span>batch<span class="token punctuation">,</span> train_y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> linear1<span class="token punctuation">)</span>
weights<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>bias<span class="token punctuation">.</span>grad
<span class="token comment"># (tensor(-0.0098), tensor([-0.0653]))</span>
<span class="token comment"># 再运行一次</span>
<span class="token comment"># (tensor(-0.0148), tensor([-0.0979]))</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>loss.backward</code>函数会对现有损失计算得到的梯度与之前已经保存过的梯度进行相加。因此要重置现有梯度为0：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">weights<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
bias<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>In-Place操作：Pytorch中下划线结尾的方法会直接对对象进行修改。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 一个周期的基本训练函数</span>
<span class="token keyword">def</span> <span class="token function">train_epoch</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> xb<span class="token punctuation">,</span>yb <span class="token keyword">in</span> dl<span class="token punctuation">:</span>
        calc_grad<span class="token punctuation">(</span>xb<span class="token punctuation">,</span> yb<span class="token punctuation">,</span> model<span class="token punctuation">)</span>
        <span class="token keyword">for</span> p <span class="token keyword">in</span> params<span class="token punctuation">:</span>
            p<span class="token punctuation">.</span>data <span class="token operator">-=</span> p<span class="token punctuation">.</span>grad<span class="token operator">*</span>lr
            p<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token punctuation">(</span>preds<span class="token operator">&gt;</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> train_y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span>

<span class="token comment"># 计算验证集的识别准确率            </span>
<span class="token keyword">def</span> <span class="token function">batch_accuracy</span><span class="token punctuation">(</span>xb<span class="token punctuation">,</span> yb<span class="token punctuation">)</span><span class="token punctuation">:</span>
    preds <span class="token operator">=</span> xb<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
    correct <span class="token operator">=</span> <span class="token punctuation">(</span>preds<span class="token operator">&gt;</span><span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">==</span> yb
    <span class="token keyword">return</span> correct<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>

batch_accuracy<span class="token punctuation">(</span>linear1<span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">,</span> train_y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">validate_epoch</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token punctuation">:</span>
    accs <span class="token operator">=</span> <span class="token punctuation">[</span>batch_accuracy<span class="token punctuation">(</span>model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span><span class="token punctuation">,</span> yb<span class="token punctuation">)</span> <span class="token keyword">for</span> xb<span class="token punctuation">,</span>yb <span class="token keyword">in</span> valid_dl<span class="token punctuation">]</span>
    <span class="token keyword">return</span> <span class="token builtin">round</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>accs<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>

validate_epoch<span class="token punctuation">(</span>linear1<span class="token punctuation">)</span>

<span class="token comment"># 训练一周期</span>
lr <span class="token operator">=</span> <span class="token number">1.</span>
params <span class="token operator">=</span> weights<span class="token punctuation">,</span>bias
train_epoch<span class="token punctuation">(</span>linear1<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> params<span class="token punctuation">)</span>
validate_epoch<span class="token punctuation">(</span>linear1<span class="token punctuation">)</span>

<span class="token comment"># 多训练几个周期</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_epoch<span class="token punctuation">(</span>linear1<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> params<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>validate_epoch<span class="token punctuation">(</span>linear1<span class="token punctuation">)</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">)</span>
<span class="token comment"># 0.9477 0.957 0.9599 0.9633 0.9672 0.9682 0.9682 0.9702 0.9706 0.9716 0.9721 0.9721 0.9726 0.9731 0.9726 0.9736 0.9736 0.974 0.9745 0.9745 </span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="创建一个优化器"><a href="#创建一个优化器" class="headerlink" title="创建一个优化器"></a>创建一个优化器</h2><p><code>优化器</code>：在深度学习中，优化器是用来更新和计算模型内部参数以减少模型误差的工具。优化算法决定了如何改变模型的权重以改善其在训练数据上的表现。优化器的目标是找到模型误差函数的最小值。</p><p>PyTorch提供了许多优化器，包括SGD（随机梯度下降）、Adam、RMSProp等。每种优化器都有其特点，适用于不同的情况和需求。</p><p>Pytorch中的<code>nn.Linear</code>模块代替<code>Linear</code>函数。与<code>init_params</code>和<code>linear</code>两个函数做的事情是相同的。它在单独的一个类中同时包含了权重和偏差。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">linear_model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
w<span class="token punctuation">,</span>b <span class="token operator">=</span> linear_model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 优化器</span>
<span class="token keyword">class</span> <span class="token class-name">BasicOptim</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>params<span class="token punctuation">,</span>lr<span class="token punctuation">)</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>params<span class="token punctuation">,</span>self<span class="token punctuation">.</span>lr <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>params<span class="token punctuation">)</span><span class="token punctuation">,</span>lr

    <span class="token keyword">def</span> <span class="token function">step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> p <span class="token keyword">in</span> self<span class="token punctuation">.</span>params<span class="token punctuation">:</span> p<span class="token punctuation">.</span>data <span class="token operator">-=</span> p<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data <span class="token operator">*</span> self<span class="token punctuation">.</span>lr

    <span class="token keyword">def</span> <span class="token function">zero_grad</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> p <span class="token keyword">in</span> self<span class="token punctuation">.</span>params<span class="token punctuation">:</span> p<span class="token punctuation">.</span>grad <span class="token operator">=</span> <span class="token boolean">None</span>

opt <span class="token operator">=</span> BasicOptim<span class="token punctuation">(</span>linear_model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token punctuation">)</span>

<span class="token comment"># 训练循环</span>
<span class="token keyword">def</span> <span class="token function">train_epoch</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> xb<span class="token punctuation">,</span>yb <span class="token keyword">in</span> dl<span class="token punctuation">:</span>
        calc_grad<span class="token punctuation">(</span>xb<span class="token punctuation">,</span> yb<span class="token punctuation">,</span> model<span class="token punctuation">)</span>
        opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
validate_epoch<span class="token punctuation">(</span>linear_model<span class="token punctuation">)</span> <span class="token comment"># 验证函数</span>


<span class="token keyword">def</span> <span class="token function">train_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        train_epoch<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>validate_epoch<span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">)</span>
        
train_model<span class="token punctuation">(</span>linear_model<span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>
<span class="token comment"># 0.4932 0.5356 0.665 0.874 0.9189 0.937 0.9512 0.9575 0.9638 0.9663 0.9673 0.9702 0.9717 0.9736 0.9751 0.9761 0.9765 0.9775 0.978 0.978 </span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>fastai</code>提供的默认的SGD优化器类可以做到和我们的BasicOptim相同的事情。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">linear_model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
opt <span class="token operator">=</span> SGD<span class="token punctuation">(</span>linear_model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token punctuation">)</span>
train_model<span class="token punctuation">(</span>linear_model<span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>可以用fastai提供的<code>Learner.fit</code>来代替<code>train_model</code>。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dls <span class="token operator">=</span> DataLoaders<span class="token punctuation">(</span>dl<span class="token punctuation">,</span> valid_dl<span class="token punctuation">)</span>
learn <span class="token operator">=</span> Learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> opt_func<span class="token operator">=</span>SGD<span class="token punctuation">,</span>
                loss_func<span class="token operator">=</span>mnist_loss<span class="token punctuation">,</span> metrics<span class="token operator">=</span>batch_accuracy<span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405252047726.png" width="300"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">训练结果</div></center><h2 id="增加一个非线性特征"><a href="#增加一个非线性特征" class="headerlink" title="增加一个非线性特征"></a>增加一个非线性特征</h2><p>在线性分类器上进行了函数参数的优化，下面在两个线性分类器之间添加一些非线性的东西，成为神经网络。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">simple_net</span><span class="token punctuation">(</span>xb<span class="token punctuation">)</span><span class="token punctuation">:</span> 
    res <span class="token operator">=</span> xb@w1 <span class="token operator">+</span> b1 <span class="token comment"># @操作符，矩阵乘</span>
    res <span class="token operator">=</span> res<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    res <span class="token operator">=</span> res@w2 <span class="token operator">+</span> b2
    <span class="token keyword">return</span> res

<span class="token comment"># 初始化参数</span>
w1 <span class="token operator">=</span> init_params<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#w1的激活值输出30，w2的激活值输入30，要匹配</span>
b1 <span class="token operator">=</span> init_params<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span>
w2 <span class="token operator">=</span> init_params<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
b2 <span class="token operator">=</span> init_params<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>res.max(tensor(0.0))</code>被称为<strong>线性修正单元</strong>，也成<code>ReLU</code>，把所有的负数替换成0。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">plot_function<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">)</span> <span class="token comment">#PyTorch中这样用 </span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405252100126.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">ReLU</div></center><p>线性层堆叠相当于一个线性层，在其中加上非线性层才有意义。</p><blockquote><p>数学上，两个线性函数的组合是另一个线性函数</p><p>如果能找到w1和w2的正确参数并且把这些矩阵做的足够大，那么这个小函数就可以在数学上证明它可以以任意高的准确率解决任何可计算的问题。对于任意的wiggly(波动)函数，可以把它近似为一组连接在一起的直线；为了使它更接近wiggly函数，只需要使用更短的线就好了，这就是近似逼近定理。</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">simple_net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

learn <span class="token operator">=</span> Learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> simple_net<span class="token punctuation">,</span> opt_func<span class="token operator">=</span>SGD<span class="token punctuation">,</span>
                loss_func<span class="token operator">=</span>mnist_loss<span class="token punctuation">,</span> metrics<span class="token operator">=</span>batch_accuracy<span class="token punctuation">)</span>

learn<span class="token punctuation">.</span>fit<span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>                <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405252115324.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">训练结果</div></center><p>训练过程记录在<code>learn.recorder</code>，输出的表格存储在<code>values</code>属性中。</p><p>绘制训练的准确率：</p><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405252118405.png" width="400"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">训练准确率</div></center><p><code>learn.recorder</code>不是存储在本地文件系统中的一个文件，而是FastAI<code>Learner</code>对象的一个属性。它在内存中保存了训练过程中的一些信息，如每个epoch的损失和度量。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">learn <span class="token operator">=</span> cnn_learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span> resnet34<span class="token punctuation">,</span> metrics<span class="token operator">=</span>accuracy<span class="token punctuation">)</span>
learn<span class="token punctuation">.</span>fit<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token comment"># 打印每个epoch的损失和度量</span>
<span class="token keyword">for</span> epoch<span class="token punctuation">,</span> values <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>learn<span class="token punctuation">.</span>recorder<span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Epoch </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>values<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    
<span class="token comment"># 把learn.recorder的内容保存到本地，可以使用Python的标准库pickle</span>
<span class="token keyword">import</span> pickle
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'recorder.pkl'</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    pickle<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>learn<span class="token punctuation">.</span>recorder<span class="token punctuation">,</span> f<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Going-Deeper"><a href="#Going-Deeper" class="headerlink" title="Going Deeper"></a>Going Deeper</h2><p>事实证明，使用更小的矩阵和更多的层，得到的结果比使用更大的矩阵和少量神经层的结果要好，所以要使用更深层的模型。</p><h1 id="术语回顾"><a href="#术语回顾" class="headerlink" title="术语回顾"></a>术语回顾</h1><center><img src="/themes/matery/source/medias/loading.gif" data-original="https://gitee.com/nusqx/picgo/raw/master/blog/202405252133892.png" width="800"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">术语回顾</div></center><blockquote><p><a target="_blank" rel="noopener" href="https://nbviewer.org/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb">https://nbviewer.org/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb</a></p></blockquote><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css"></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="../../../../about" rel="external nofollow noreferrer">nusqx</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://nusqx.top">https://nusqx.top</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="../../../../about" target="_blank">nusqx</a> !</span></div></div><script async defer>document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="../../../../tags/DL/"><span class="chip bg-color">DL</span> </a><a href="../../../../tags/fastiai/"><span class="chip bg-color">fastiai</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="../../../../libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="../../../../libs/share/js/social-share.min.js"></script></div></div></div><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close"><i class="fas fa-times"></i></a><h4 class="reward-title">你的赏识是我前进的动力</h4><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><script>$(function(){$(".tabs").tabs()})</script></div></div><style>.valine-card{margin:1.5rem auto}.valine-card .card-content{padding:20px 20px 5px 20px}#vcomments textarea{box-sizing:border-box;background:url(../../../medias/comment_bg.png) 100% 100% no-repeat}#vcomments p{margin:2px 2px 10px;font-size:1.05rem;line-height:1.78rem}#vcomments blockquote p{text-indent:.2rem}#vcomments a{padding:0 2px;color:#4cbf30;font-weight:500;text-decoration:none}#vcomments img{max-width:100%;height:auto;cursor:pointer}#vcomments ol li{list-style-type:decimal}#vcomments ol,ul{display:block;padding-left:2em;word-spacing:.05rem}#vcomments ul li,ol li{display:list-item;line-height:1.8rem;font-size:1rem}#vcomments ul li{list-style-type:disc}#vcomments ul ul li{list-style-type:circle}#vcomments table,td,th{padding:12px 13px;border:1px solid #dfe2e5}#vcomments table,td,th{border:0}table tr:nth-child(2n),thead{background-color:#fafafa}#vcomments table th{background-color:#f2f2f2;min-width:80px}#vcomments table td{min-width:80px}#vcomments h1{font-size:1.85rem;font-weight:700;line-height:2.2rem}#vcomments h2{font-size:1.65rem;font-weight:700;line-height:1.9rem}#vcomments h3{font-size:1.45rem;font-weight:700;line-height:1.7rem}#vcomments h4{font-size:1.25rem;font-weight:700;line-height:1.5rem}#vcomments h5{font-size:1.1rem;font-weight:700;line-height:1.4rem}#vcomments h6{font-size:1rem;line-height:1.3rem}#vcomments p{font-size:1rem;line-height:1.5rem}#vcomments hr{margin:12px 0;border:0;border-top:1px solid #ccc}#vcomments blockquote{margin:15px 0;border-left:5px solid #42b983;padding:1rem .8rem .3rem .8rem;color:#666;background-color:rgba(66,185,131,.1)}#vcomments pre{font-family:monospace,monospace;padding:1.2em;margin:.5em 0;background:#272822;overflow:auto;border-radius:.3em;tab-size:4}#vcomments code{font-family:monospace,monospace;padding:1px 3px;font-size:.92rem;color:#e96900;background-color:#f8f8f8;border-radius:2px}#vcomments pre code{font-family:monospace,monospace;padding:0;color:#e8eaf6;background-color:#272822}#vcomments pre[class*=language-]{padding:1.2em;margin:.5em 0}#vcomments code[class*=language-],pre[class*=language-]{color:#e8eaf6}#vcomments [type=checkbox]:not(:checked),[type=checkbox]:checked{position:inherit;margin-left:-1.3rem;margin-right:.4rem;margin-top:-1px;vertical-align:middle;left:unset;visibility:visible}#vcomments b,strong{font-weight:700}#vcomments dfn{font-style:italic}#vcomments small{font-size:85%}#vcomments cite{font-style:normal}#vcomments mark{background-color:#fcf8e3;padding:.2em}#vcomments table,td,th{padding:12px 13px;border:1px solid #dfe2e5}table tr:nth-child(2n),thead{background-color:#fafafa}#vcomments table th{background-color:#f2f2f2;min-width:80px}#vcomments table td{min-width:80px}#vcomments [type=checkbox]:not(:checked),[type=checkbox]:checked{position:inherit;margin-left:-1.3rem;margin-right:.4rem;margin-top:-1px;vertical-align:middle;left:unset;visibility:visible}</style><div class="card valine-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="vcomments" class="card-content" style="display:grid"></div></div><script src="../../../../libs/valine/av-min.js"></script><script src="../../../../libs/valine/Valine.min.js"></script><script>new Valine({el:"#vcomments",appId:"GOX0XlpzLZat5ANucw5j9zjl-gzGzoHsz",appKey:"fha9hT9W6BxJDz7eBYQEPBvc",serverURLs:"",notify:!0,verify:!0,visitor:!1,avatar:"wavatar",pageSize:"10",lang:"zh-cn",placeholder:"What do you say?"})</script><div id="to_comment" class="comment-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#vcomments" title="直达评论"><i class="fas fa-comments"></i></a></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="../../26/ner/"><div class="card-image"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/featureimages/32.jpg" class="responsive-img" alt="NER"> <span class="card-title">NER</span></div></a><div class="card-content article-content"><div class="summary block-with-text">命名实体识别</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-02-26 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="../../../../categories/NLP/" class="post-category">NLP</a></span></div></div><div class="card-action article-tags"><a href="../../../../tags/DL/"><span class="chip bg-color">DL</span> </a><a href="../../../../tags/NLP/"><span class="chip bg-color">NLP</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="../../../01/28/production/"><div class="card-image"><img src="/themes/matery/source/medias/loading.gif" data-original="../../../../medias/featureimages/31.jpg" class="responsive-img" alt="从模型到输出"> <span class="card-title">从模型到输出</span></div></a><div class="card-content article-content"><div class="summary block-with-text">数据清洗、转换、增强、混淆矩阵</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-01-28 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="../../../../tags/DL/"><span class="chip bg-color">DL</span> </a><a href="../../../../tags/fastai/"><span class="chip bg-color">fastai</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0!==window.getSelection&&((""+(n=window.getSelection())).length<Number.parseInt("240")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"!==n.getRangeAt(0).commonAncestorContainer.nodeName&&"CODE"!==n.getRangeAt(0).commonAncestorContainer.nodeName||(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: SQX BLOG<br />文章作者: NUS QX<br />文章链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200)))})</script><script type="text/javascript" src="../../../../libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="../../../../libs/prism/prism.min.js"></script><script type="text/javascript" src="../../../../libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="../../../../libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="../../../../libs/codeBlock/codeShrink.js"></script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget card" style="background-color:#fff"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="../../../../libs/tocbot/tocbot.min.js"></script><script>$(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });</script></main><script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]]}})</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:15px!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2018-2024</span> <a href="../../../../about" target="_blank">NUS QX</a><br><span id="sitetime"></span><span class="my-face"></span><br>&nbsp;|&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">113.6k</span> <span id="busuanzi_container_site_pv" style="display:none"></span> &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span> <span id="busuanzi_container_site_uv" style="display:none"></span> 次&nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;访客人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span> 人 <span id="busuanzi_value_site_uv" class="white-color"></span></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/nusqx" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:1976490928@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fa-solid fa-envelope"></i> </a><a href="https://gitee.com/nusqx" class="tooltipped" target="_blank" data-tooltip="访问我的Gitee: https://gitee.com/nusqx" data-position="top" data-delay="50"><i class="fa-brands fa-square-git"></i> </a><a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1976490928" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1976490928" data-position="top" data-delay="50"><i class="fab fa-qq"></i></a></div></div></footer><div class="progress-bar"></div><script language="javascript">function siteTime(){window.setTimeout("siteTime()",1e3);var e=36e5,t=24*e,o=new Date,i=o.getFullYear(),a=o.getMonth()+1,n=o.getDate(),r=o.getHours(),l=o.getMinutes(),s=o.getSeconds(),M=Date.UTC(2018,9,24,0,0,0),g=Date.UTC(i,a,n,r,l,s)-M,m=Math.floor(g/31536e6),T=Math.floor(g/t-365*m),f=Math.floor((g-(365*m+T)*t)/e),h=Math.floor((g-(365*m+T)*t-f*e)/6e4),u=Math.floor((g-(365*m+T)*t-f*e-6e4*h)/1e3);document.getElementById("sitetime").innerHTML="本站已运行 "+m+" 年 "+T+" 天 "+f+" 小时 "+h+" 分钟 "+u+" 秒"}siteTime()</script><script>$(document).ready(function(){var e=setInterval(function(){"none"!=document.getElementById("busuanzi_container_site_pv").style.display&&($("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html())+n),clearInterval(e));"none"!=$("#busuanzi_container_site_pv").css("display")&&($("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html())+t),clearInterval(e))},50),n=8e4,t=2e4})</script><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script type="text/javascript">$(function(){!function(t,s,i){"use strict";$.ajax({url:t,dataType:"xml",success:function(t){var e=$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),n=document.getElementById(s),r=document.getElementById(i);n.addEventListener("input",function(){var f='<ul class="search-result-list">',m=this.value.trim().toLowerCase().split(/[\s\-]+/);r.innerHTML="",this.value.trim().length<=0||(e.forEach(function(t){var n,e,r,s,i,l=!0,a=t.title.trim().toLowerCase(),c=t.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),u=0===(u=t.url).indexOf("/")?t.url:"/"+u,o=-1,h=-1;""!==a&&""!==c&&m.forEach(function(t,e){n=a.indexOf(t),o=c.indexOf(t),n<0&&o<0?l=!1:(o<0&&(o=0),0===e&&(h=o))}),l&&(f+="<li><a href='"+u+"' class='search-result-title'>"+a+"</a>",e=t.content.trim().replace(/<[^>]+>/g,""),0<=h&&(s=h+80,(r=h-20)<0&&(r=0),0===r&&(s=100),s>e.length&&(s=e.length),i=e.substr(r,s),m.forEach(function(t){var e=new RegExp(t,"gi");i=i.replace(e,'<em class="search-keyword">'+t+"</em>")}),f+='<p class="search-result">'+i+"...</p>"),f+="</li>")}),f+="</ul>",r.innerHTML=f)})}})}("../../../../search.xml","searchInput","searchResult")})</script><div class="stars-con"><div id="stars"></div><div id="stars2"></div><div id="stars3"></div></div><script>function switchNightMode(){$('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($("body")),setTimeout(function(){$("body").hasClass("DarkMode")?($("body").removeClass("DarkMode"),localStorage.setItem("isDark","0"),$("#sum-moon-icon").removeClass("fa-sun").addClass("fa-moon")):($("body").addClass("DarkMode"),localStorage.setItem("isDark","1"),$("#sum-moon-icon").addClass("fa-sun").removeClass("fa-moon")),setTimeout(function(){$(".Cuteen_DarkSky").fadeOut(1e3,function(){$(this).remove()})},2e3)})}</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="../../../../libs/materialize/materialize.min.js"></script><script src="../../../../libs/masonry/masonry.pkgd.min.js"></script><script src="../../../../libs/aos/aos.js"></script><script src="../../../../libs/scrollprogress/scrollProgress.min.js"></script><script src="../../../../libs/lightGallery/js/lightgallery-all.min.js"></script><script src="../../../../js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="../../../../libs/others/clicklove.js" async></script><script async src="../../../../libs/others/busuanzi.pure.mini.js"></script><script type="text/javascript" src="../../../../libs/background/ribbon-dynamic.js" async></script><script src="../../../../libs/instantpage/instantpage.js" type="module"></script>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a,i=c[o];e=function(){c=c.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(n=new Image,a=t.getAttribute("data-original"),n.onload=function(){t.src=a,t.removeAttribute("data-original"),e&&e()},t.src!==a&&(n.src=a))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this);</script><script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>